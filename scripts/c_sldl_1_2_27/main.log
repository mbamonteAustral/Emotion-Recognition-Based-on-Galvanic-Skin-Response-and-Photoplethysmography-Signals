2024-05-02 02:38:15.104249: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-05-02 02:38:16.014008: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-05-02 02:38:17.899520: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
    
    
-------------------------------
participant:  1
-------------------------------
    
    
participant:  1
corriendo en PC gamer:
Window size (sec):  9.0
step (sec):  6.75
overlap:  True
perc. of overlap:  25.0
overlap duration (sec):  2.25
Nearest multiple of 16 to 9000 is: 8992
Nearest multiple of 16 to 6750 is: 6752
['gsr_chunks', 'ppg_chunks', 'val_chunks', 'aro_chunks', 'time_chunks', 'tag_chunks', 'video']
C:\Users\Javier\Dropbox\c_sldl_1_2_27\functions.py:880: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!
You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.
A typical example is when you are setting values in a column of a DataFrame, like:
1m1s[0m 8ms/step - loss: 0.0200 - mean_squared_error: 0.0200 - val_loss: 0.0208 - val_mean_squared_error: 0.0208
(8992, 1, 5)
Model: "sequential_1199"
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer (type)                    â”‚ Output Shape           â”‚       Param # â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1stConvL (Conv1D)               â”‚ (None, 8992, 5)        â”‚           105 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1stPoolL (AveragePooling1D)     â”‚ (None, 2248, 5)        â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2ndConvL (Conv1D)               â”‚ (None, 2248, 6)        â”‚           306 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2ndPoolL (AveragePooling1D)     â”‚ (None, 562, 6)         â”‚             0 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 2,209 (8.63 KB)
 Trainable params: 411 (1.61 KB)
 Non-trainable params: 0 (0.00 B)
 Optimizer params: 1,798 (7.03 KB)
Model: "valence_NN"
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer (type)        â”‚ Output Shape      â”‚    Param # â”‚ Connected to      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ inputGSR            â”‚ (None, 8992, 1)   â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ inputPPG            â”‚ (None, 8992, 1)   â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ sequential_1198     â”‚ (None, 562, 6)    â”‚        411 â”‚ inputGSR[0][0]    â”‚
â”‚ (Sequential)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ sequential_1199     â”‚ (None, 562, 6)    â”‚        411 â”‚ inputPPG[0][0]    â”‚
â”‚ (Sequential)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ concatenate_599     â”‚ (None, 562, 12)   â”‚          0 â”‚ sequential_1198[â€¦ â”‚
â”‚ (Concatenate)       â”‚                   â”‚            â”‚ sequential_1199[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ permute_599         â”‚ (None, 12, 562)   â”‚          0 â”‚ concatenate_599[â€¦ â”‚
â”‚ (Permute)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ flatten_599         â”‚ (None, 6744)      â”‚          0 â”‚ permute_599[0][0] â”‚
â”‚ (Flatten)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout_599         â”‚ (None, 6744)      â”‚          0 â”‚ flatten_599[0][0] â”‚
â”‚ (Dropout)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_599 (Dense)   â”‚ (None, 1)         â”‚      6,745 â”‚ dropout_599[0][0] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 7,567 (29.56 KB)
 Trainable params: 7,567 (29.56 KB)
 Non-trainable params: 0 (0.00 B)
Epoch 1/10

[1m  1/130[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2:47[0m 1s/step - binary_accuracy: 1.0000 - loss: 0.6573
[1m 10/130[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.6560 - loss: 0.7091 
[1m 18/130[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.6091 - loss: 0.7081
[1m 27/130[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.5973 - loss: 0.7023
[1m 34/130[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.5951 - loss: 0.7030
[1m 43/130[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.5923 - loss: 0.7084
[1m 51/130[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.5929 - loss: 0.7089
[1m 60/130[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.5977 - loss: 0.7068
[1m 68/130[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.6015 - loss: 0.7043
[1m 77/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.6049 - loss: 0.7009
[1m 86/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.6060 - loss: 0.7007
[1m 94/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.6069 - loss: 0.7013
[1m104/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.6090 - loss: 0.7016
[1m113/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.6108 - loss: 0.7019
[1m121/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.6125 - loss: 0.7016
[1m129/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.6146 - loss: 0.7012
[1m130/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m2s[0m 9ms/step - binary_accuracy: 0.6151 - loss: 0.7012 - val_binary_accuracy: 0.9333 - val_loss: 0.3802
Epoch 2/10

[1m  1/130[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 32ms/step - binary_accuracy: 1.0000 - loss: 0.4165
[1m  9/130[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.6595 - loss: 0.7248 
[1m 18/130[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.6447 - loss: 0.7174
[1m 26/130[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.6650 - loss: 0.6924
[1m 35/130[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.6692 - loss: 0.6841
[1m 43/130[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.6701 - loss: 0.6799
[1m 52/130[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.6621 - loss: 0.6797
[1m 60/130[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.6531 - loss: 0.6794
[1m 68/130[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.6495 - loss: 0.6772
[1m 77/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.6451 - loss: 0.6751
[1m 85/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.6423 - loss: 0.6729
[1m 94/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.6402 - loss: 0.6704
[1m102/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.6395 - loss: 0.6682
[1m111/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.6386 - loss: 0.6662
[1m119/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.6384 - loss: 0.6643
[1m127/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.6393 - loss: 0.6618
[1m130/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 8ms/step - binary_accuracy: 0.6396 - loss: 0.6607 - val_binary_accuracy: 0.9333 - val_loss: 0.3455
Epoch 3/10

[1m  1/130[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 31ms/step - binary_accuracy: 0.0000e+00 - loss: 1.1377
[1m  9/130[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.5160 - loss: 0.7528     
[1m 17/130[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.5642 - loss: 0.7600
[1m 26/130[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.5999 - loss: 0.7346
[1m 34/130[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.6225 - loss: 0.7089
[1m 42/130[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.6314 - loss: 0.6923
[1m 50/130[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.6324 - loss: 0.6831
[1m 57/130[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.6314 - loss: 0.6768
[1m 66/130[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.6331 - loss: 0.6699
[1m 75/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.6320 - loss: 0.6659
[1m 83/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.6302 - loss: 0.6639
[1m 90/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.6276 - loss: 0.6631
[1m 98/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.6252 - loss: 0.6626
[1m107/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.6237 - loss: 0.6622
[1m116/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.6232 - loss: 0.6614
[1m124/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.6224 - loss: 0.6607
[1m130/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 8ms/step - binary_accuracy: 0.6222 - loss: 0.6598 - val_binary_accuracy: 0.9333 - val_loss: 0.2922
Epoch 4/10

[1m  1/130[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 31ms/step - binary_accuracy: 0.0000e+00 - loss: 1.1188
[1m  9/130[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.4552 - loss: 0.7347     
[1m 18/130[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.5755 - loss: 0.6599
[1m 26/130[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.5940 - loss: 0.6544
[1m 35/130[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.5755 - loss: 0.6643
[1m 44/130[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.5600 - loss: 0.6679
[1m 53/130[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.5548 - loss: 0.6652
[1m 61/130[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.5525 - loss: 0.6630
[1m 70/130[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.5524 - loss: 0.6590
[1m 78/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.5556 - loss: 0.6550
[1m 87/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.5588 - loss: 0.6518
[1m 96/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.5617 - loss: 0.6498
[1m103/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.5648 - loss: 0.6483
[1m110/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.5675 - loss: 0.6471
[1m119/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.5706 - loss: 0.6457
[1m128/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.5745 - loss: 0.6439
[1m130/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 8ms/step - binary_accuracy: 0.5759 - loss: 0.6432 - val_binary_accuracy: 0.9333 - val_loss: 0.3607
Epoch 5/10

[1m  1/130[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 31ms/step - binary_accuracy: 1.0000 - loss: 0.3625
[1m 10/130[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.9054 - loss: 0.4131 
[1m 18/130[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8500 - loss: 0.4595
[1m 26/130[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8346 - loss: 0.4686
[1m 35/130[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.8142 - loss: 0.4927
[1m 43/130[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.7952 - loss: 0.5164
[1m 52/130[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.7790 - loss: 0.5334
[1m 59/130[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.7713 - loss: 0.5422
[1m 66/130[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.7646 - loss: 0.5486
[1m 75/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.7553 - loss: 0.5576
[1m 83/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.7473 - loss: 0.5646
[1m 92/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.7403 - loss: 0.5715
[1m100/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.7347 - loss: 0.5770
[1m109/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.7285 - loss: 0.5821
[1m118/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.7228 - loss: 0.5857
[1m127/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.7182 - loss: 0.5885
[1m130/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 8ms/step - binary_accuracy: 0.7163 - loss: 0.5896 - val_binary_accuracy: 1.0000 - val_loss: 0.3063
Epoch 6/10

[1m  1/130[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 31ms/step - binary_accuracy: 0.0000e+00 - loss: 1.6480
[1m  9/130[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.3348 - loss: 1.0452     
[1m 18/130[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.5249 - loss: 0.8329
[1m 26/130[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.6128 - loss: 0.7417
[1m 34/130[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.6502 - loss: 0.7035
[1m 43/130[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.6704 - loss: 0.6797
[1m 52/130[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.6795 - loss: 0.6666
[1m 61/130[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.6834 - loss: 0.6587
[1m 70/130[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.6860 - loss: 0.6523
[1m 78/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.6888 - loss: 0.6469
[1m 86/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.6897 - loss: 0.6430
[1m 93/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.6888 - loss: 0.6406
[1m101/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.6873 - loss: 0.6383
[1m108/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.6871 - loss: 0.6361
[1m117/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.6865 - loss: 0.6346
[1m125/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.6866 - loss: 0.6330
[1m130/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 8ms/step - binary_accuracy: 0.6874 - loss: 0.6315 - val_binary_accuracy: 0.8667 - val_loss: 0.4070
Epoch 7/10

[1m  1/130[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 31ms/step - binary_accuracy: 1.0000 - loss: 0.2248
[1m  9/130[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8523 - loss: 0.4080 
[1m 18/130[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.8693 - loss: 0.3817
[1m 27/130[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.8495 - loss: 0.4255
[1m 35/130[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.8266 - loss: 0.4651
[1m 43/130[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.8135 - loss: 0.4859
[1m 50/130[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.8009 - loss: 0.5008
[1m 58/130[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.7845 - loss: 0.5167
[1m 67/130[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.7667 - loss: 0.5319
[1m 75/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.7579 - loss: 0.5413
[1m 84/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.7499 - loss: 0.5495
[1m 91/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.7441 - loss: 0.5545
[1m 99/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.7396 - loss: 0.5582
[1m108/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.7352 - loss: 0.5613
[1m116/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.7321 - loss: 0.5631
[1m125/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.7305 - loss: 0.5637
[1m130/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 8ms/step - binary_accuracy: 0.7295 - loss: 0.5648 - val_binary_accuracy: 1.0000 - val_loss: 0.2399
Epoch 8/10

[1m  1/130[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 31ms/step - binary_accuracy: 1.0000 - loss: 0.0473
[1m  9/130[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.9172 - loss: 0.1870 
[1m 17/130[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.9050 - loss: 0.2509
[1m 25/130[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8863 - loss: 0.2909
[1m 33/130[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8505 - loss: 0.3415
[1m 40/130[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8287 - loss: 0.3753
[1m 49/130[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8073 - loss: 0.4076
[1m 58/130[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.7862 - loss: 0.4324
[1m 66/130[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.7699 - loss: 0.4495
[1m 74/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7591 - loss: 0.4612
[1m 83/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.7510 - loss: 0.4699
[1m 92/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.7444 - loss: 0.4781
[1m 99/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7391 - loss: 0.4866
[1m108/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.7326 - loss: 0.4962
[1m116/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7276 - loss: 0.5034
[1m125/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.7218 - loss: 0.5104
[1m130/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 8ms/step - binary_accuracy: 0.7192 - loss: 0.5139 - val_binary_accuracy: 0.8667 - val_loss: 0.4287
Epoch 9/10

[1m  1/130[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 31ms/step - binary_accuracy: 1.0000 - loss: 0.0909
[1m  8/130[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 9ms/step - binary_accuracy: 0.6330 - loss: 0.3552 
[1m 15/130[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.6750 - loss: 0.3918
[1m 22/130[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.6682 - loss: 0.4620
[1m 31/130[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.6805 - loss: 0.4889
[1m 39/130[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.6927 - loss: 0.4958
[1m 48/130[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.6965 - loss: 0.5051
[1m 55/130[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.6983 - loss: 0.5123
[1m 62/130[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7001 - loss: 0.5171
[1m 71/130[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7022 - loss: 0.5233
[1m 79/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7055 - loss: 0.5266
[1m 87/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7078 - loss: 0.5294
[1m 95/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7086 - loss: 0.5320
[1m102/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7099 - loss: 0.5333
[1m111/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7122 - loss: 0.5340
[1m120/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7136 - loss: 0.5357
[1m129/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.7144 - loss: 0.5372
[1m130/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 8ms/step - binary_accuracy: 0.7145 - loss: 0.5376 - val_binary_accuracy: 0.8000 - val_loss: 0.4325
Epoch 10/10

[1m  1/130[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 31ms/step - binary_accuracy: 0.0000e+00 - loss: 0.9379
[1m  9/130[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.5988 - loss: 0.5182     
[1m 18/130[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.6635 - loss: 0.5052
[1m 26/130[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.6933 - loss: 0.5081
[1m 35/130[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.7105 - loss: 0.5097
[1m 44/130[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.7137 - loss: 0.5119
[1m 51/130[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.7129 - loss: 0.5136
[1m 59/130[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.7091 - loss: 0.5174
[1m 67/130[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.7076 - loss: 0.5195
[1m 76/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.7059 - loss: 0.5226
[1m 85/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.7046 - loss: 0.5249
[1m 93/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.7046 - loss: 0.5255
[1m100/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.7043 - loss: 0.5261
[1m109/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.7051 - loss: 0.5259
[1m117/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.7069 - loss: 0.5249
[1m125/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.7093 - loss: 0.5232
[1m130/130[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 8ms/step - binary_accuracy: 0.7109 - loss: 0.5222 - val_binary_accuracy: 1.0000 - val_loss: 0.2319

[1m1/2[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 109ms/step
[1m2/2[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 94ms/step 
[1m2/2[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 94ms/step
predicted [0.9390124  0.9192013  0.01982773 0.87614655 0.8520057  0.01269823
 0.0905537  0.89192116 0.80938256 0.6091523  0.31678987 0.01681482
 0.01403153 0.83158875 0.8413611  0.273194   0.6303075  0.8267412
 0.91367495 0.93868804 0.84541357 0.60003126 0.73502934 0.94601923
 0.92713845 0.8693731  0.810068   0.05241582 0.7768623  0.7165972
 0.89399433 0.8465047  0.922494   0.72854215 0.5051458  0.91270983
 0.6807275 ]
predicted [1 1 0 1 1 0 0 1 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1]
expected [ True  True False False  True False False  True  True  True False False
 False False False  True  True False  True  True False  True  True  True
  True  True  True  True  True False  True  True False  True  True False
  True]
accuracy: 0.7297297297297297
confusion matrix: 
[[ 6  8]
 [ 2 21]]
              precision    recall  f1-score   support

       False       0.75      0.43      0.55        14
        True       0.72      0.91      0.81        23

    accuracy                           0.73        37
   macro avg       0.74      0.67      0.68        37
weighted avg       0.73      0.73      0.71        37

macro avg f1-score: 0.6765734265734266
macro avg (UAR): 0.670807453416149
Sensitivity:  0.42857142857142855
Specificity:  0.9130434782608695
g-mean:  0.6255432421712243
-------- Model Performance ----------: 
accuracy:  [0.67567568 0.72972973 0.78378378 0.59459459 0.78378378 0.81081081
 0.7027027  0.75675676 0.64864865 0.72972973]
gmean:  [0.62554324 0.62554324 0.65465367 0.6104677  0.72231512 0.80564777
 0.6104677  0.70490738 0.57914051 0.62554324]
f1_score:  [0.64423077 0.67657343 0.72592593 0.59340659 0.75333333 0.80153257
 0.65302643 0.72816327 0.60734694 0.67657343]
UAR:  [0.64130435 0.67080745 0.71428571 0.61801242 0.74223602 0.80590062
 0.64906832 0.72049689 0.60559006 0.67080745]
Cohen Kappa score:  [0.29073482 0.37288136 0.48251748 0.21499293 0.51315789 0.60336907
 0.32053422 0.46029173 0.22042139 0.37288136]
arousal and valece = ok
------------- Evaluating model --------------
-------------------------------------
-------------------------------------
participant:  30
-------------------------------------
----- RESULTS ------
-------------------------------------
Window size (sec):  8.992
step (sec):  6.752
overlap:  True
perc. of overlap:  24.91103202846975
overlap duration (sec):  2.24
Number of windows / instances:  182
-rows: alg : KNN = 0; DT = 1; RF = 2; SVM = 3; GBM = 4; BDDAE = 5; DUMMY = 5
columns:
'val_cohen','val_uar', 'val_acc', 'val_gm',  'val_f1',  'aro_cohen','aro_uar', 'aro_acc', 'aro_gm',  'aro_f1'
-------------------------------------------------------------
  v_c   v_u   v_a   v_g   v_f1  a_c   a_u   a_a   a_g   a_f1
[[0.716 0.867 0.863 0.863 0.857 0.373 0.691 0.714 0.672 0.683]
 [0.505 0.766 0.774 0.744 0.76  0.527 0.806 0.818 0.754 0.803]
 [0.661 0.827 0.84  0.829 0.828 0.545 0.693 0.736 0.677 0.692]
 [0.582 0.783 0.812 0.758 0.784 0.168 0.574 0.67  0.419 0.546]
 [0.602 0.793 0.807 0.793 0.788 0.42  0.705 0.774 0.607 0.709]
 [0.385 0.684 0.722 0.656 0.686 0.016 0.508 0.624 0.236 0.455]
 [0.    0.5   0.615 0.    0.381 0.    0.5   0.637 0.    0.389]]
participant performance loaded
    
    
-------------------------------
LAST participant's saved data: 
30
-------------------------------
    
    
---------------------------
KNN performance:
[[ 0.53502859  0.76614899  0.77339181  0.75613497  0.76485525  0.29019999
   0.64142857  0.76461988  0.51176958  0.6351782 ]
 [ 0.47423794  0.73916667  0.73684211  0.73049058  0.73328013  0.49498877
   0.74264069  0.7751462   0.71815887  0.74270817]
 [ 0.54506924  0.76845779  0.78070175  0.75312876  0.76754305  0.47390206
   0.73763889  0.73654971  0.73094208  0.73375166]
 [ 0.30816434  0.65361111  0.65906433  0.62100726  0.64016119  0.31060749
   0.64576923  0.73099415  0.60514456  0.65291253]
 [ 0.52425749  0.74837662  0.78596491  0.72455294  0.75702901  0.43716704
   0.71819444  0.71929825  0.71392429  0.71713124]
 [ 0.44957483  0.72333333  0.72631579  0.71636008  0.72233354  0.54125242
   0.76902778  0.7748538   0.75399396  0.76559619]
 [ 0.22757494  0.61306818  0.64415205  0.56785251  0.60119503  0.39333523
   0.69638889  0.69766082  0.69147859  0.69470961]
 [ 0.8587804   0.92564103  0.93976608  0.91890643  0.9281594   0.59367708
   0.80275974  0.80292398  0.79710991  0.79485277]
 [ 0.20720474  0.59724359  0.69210526  0.48698913  0.58494921  0.13231288
   0.56544872  0.65906433  0.44111921  0.55213772]
 [ 0.33707998  0.66847222  0.66988304  0.65660447  0.66352768  0.33757293
   0.66944444  0.67105263  0.66489638  0.66733803]
 [ 0.1342195   0.56694805  0.59415205  0.53479402  0.56054519  0.40830939
   0.70248377  0.71374269  0.68532414  0.69725012]
 [ 0.57815428  0.79085498  0.80701754  0.77359265  0.78517597  0.59563974
   0.78603896  0.81929825  0.76332377  0.79284007]
 [ 0.36834047  0.67902597  0.69561404  0.66296654  0.68027579  0.205446
   0.60272727  0.60964912  0.57912207  0.59364204]
 [ 0.21257399  0.60178571  0.6748538   0.51143539  0.59351617  0.35224485
   0.67652778  0.68128655  0.66122065  0.67091564]
 [ 0.26912633  0.63511905  0.67719298  0.5871548   0.62252138  0.21956281
   0.61341991  0.62631579  0.60240453  0.6074591 ]
 [ 0.29620317  0.64350649  0.66959064  0.6190091   0.64130817  0.41035079
   0.69702381  0.75350877  0.65140296  0.69627202]
 [ 0.61227785  0.80141234  0.81900585  0.78687002  0.8026454   0.46134727
   0.72459416  0.75175439  0.70215713  0.72647158]
 [ 0.25304071  0.6325      0.84678363  0.38159796  0.61500032  0.35867947
   0.67714286  0.69736842  0.66046535  0.6752803 ]
 [ 0.32409448  0.64641026  0.74795322  0.5683011   0.64802259  0.3162457
   0.65847222  0.66461988  0.64251542  0.65269949]
 [ 0.22237087  0.60673077  0.69093567  0.47839519  0.58707717  0.26089507
   0.62445887  0.67076023  0.59117816  0.62496608]
 [-0.09211035  0.46043956  0.67602339  0.09225771  0.43251063 -0.09919021
   0.45069444  0.45175439  0.42645381  0.4393035 ]
 [ 0.40486656  0.70319444  0.70233918  0.69483286  0.69852379  0.22889688
   0.61239177  0.66520468  0.57078057  0.6074357 ]
 [ 0.07712452  0.53626623  0.57076023  0.47142548  0.51905846  0.29008579
   0.63049451  0.76315789  0.52578596  0.63509898]
 [ 0.30957082  0.65555556  0.65350877  0.64566106  0.64933364  0.54191574
   0.77104798  0.7745614   0.76654817  0.76964259]
 [ 0.40001869  0.69856061  0.70409357  0.68304267  0.69336715  0.69286158
   0.84611111  0.84678363  0.84335982  0.84571527]
 [ 0.32655666  0.66194444  0.66520468  0.64966305  0.65795339  0.42250374
   0.71363636  0.71549708  0.69968907  0.705557  ]
 [ 0.47412966  0.73903846  0.78040936  0.71860359  0.73376629  0.58375153
   0.79208333  0.79181287  0.78705899  0.78998274]
 [-0.0167097   0.49058442  0.56461988  0.39914832  0.48335715  0.42438585
   0.70933442  0.73654971  0.67628295  0.70323756]
 [ 0.16807923  0.583171    0.61520468  0.55403527  0.58040995  0.3583016
   0.67958333  0.68216374  0.66649305  0.67413799]
 [ 0.7163206   0.86709957  0.8625731   0.86316449  0.85689211  0.37335662
   0.69107143  0.71403509  0.67228976  0.68307467]]
KNN mean:
[0.35017403 0.67345558 0.71420078 0.62026595 0.66680981 0.38035354
 0.68826932 0.71539961 0.66007979 0.68490995]
---------------------------
---------------------------
DT performance:
[[ 0.47869925  0.74070707  0.74678363  0.71560689  0.73741122  0.44824525
   0.6906044   0.76578947  0.65500416  0.68000668]
 [ 0.40102333  0.66277778  0.66432749  0.67248096  0.65524302  0.5245812
   0.73674242  0.75818713  0.72363969  0.73537373]
 [ 0.39953829  0.67053571  0.67631579  0.68879541  0.66580876  0.35020056
   0.66527778  0.66491228  0.70567174  0.65750876]
 [ 0.26941924  0.64597222  0.64883041  0.64367804  0.63986403  0.26875201
   0.64224359  0.7254386   0.56356054  0.6361917 ]
 [ 0.40838941  0.69629329  0.71929825  0.69924934  0.69456933  0.43985209
   0.69069444  0.69239766  0.70976969  0.68949656]
 [ 0.30447243  0.67361111  0.67602339  0.64758123  0.66909282  0.42728117
   0.69569444  0.69853801  0.68445228  0.69199019]
 [ 0.24524889  0.61241883  0.62807018  0.67545755  0.60563925  0.2220077
   0.62875     0.62660819  0.61806153  0.62168865]
 [ 0.78869568  0.87557692  0.88450292  0.89158045  0.86823183  0.60385437
   0.78977273  0.80292398  0.79055827  0.78923674]
 [ 0.30980929  0.65596154  0.69736842  0.59691808  0.64388185  0.13768878
   0.59179487  0.66491228  0.51809232  0.5943915 ]
 [ 0.29541168  0.63666667  0.6371345   0.61738343  0.63139918  0.39110195
   0.69263889  0.69269006  0.66714619  0.68769018]
 [ 0.03707217  0.57176948  0.59415205  0.55500093  0.56310907  0.38891083
   0.68714286  0.69269006  0.68049511  0.68171443]
 [ 0.50270368  0.74155844  0.75350877  0.73183209  0.73984921  0.34955677
   0.68119589  0.68216374  0.67357973  0.66850396]
 [ 0.2752598   0.60561688  0.60877193  0.62459546  0.60083676  0.1117
   0.56625     0.57222222  0.54466716  0.56100927]
 [ 0.09235869  0.53630952  0.57076023  0.5239098   0.53073498  0.34043578
   0.6825      0.68216374  0.64791557  0.67495469]
 [ 0.17776336  0.54404762  0.60964912  0.47010905  0.54310442  0.29380165
   0.6737013   0.68128655  0.61644634  0.66389539]
 [ 0.31742497  0.66818182  0.68157895  0.64373284  0.66194287  0.20759197
   0.64047619  0.6877193   0.60721652  0.64036992]
 [ 0.63275043  0.78590909  0.79152047  0.74937434  0.78289842  0.3585182
   0.69099026  0.7125731   0.70897504  0.68979158]
 [ 0.30100254  0.62041667  0.78596491  0.43292392  0.61905739  0.4069802
   0.68125     0.70321637  0.67407003  0.67494379]
 [ 0.34991352  0.70679487  0.74824561  0.6607664   0.70287985  0.52923011
   0.76763889  0.77426901  0.75357084  0.76678493]
 [ 0.34279152  0.6650641   0.72309942  0.62234227  0.666366    0.34952603
   0.67272727  0.6874269   0.67334824  0.66284885]
 [ 0.17072662  0.55142857  0.67748538  0.43964156  0.5445872  -0.06025984
   0.44194444  0.44415205  0.45264815  0.43416177]
 [ 0.33849186  0.61583333  0.61520468  0.62994487  0.61115214  0.29869302
   0.66044372  0.68596491  0.647825    0.65641171]
 [ 0.2813792   0.65930195  0.66403509  0.64398917  0.6536755   0.27977333
   0.63730769  0.70847953  0.58882889  0.62694747]
 [ 0.34783053  0.69291667  0.69239766  0.68477422  0.6868808   0.38501897
   0.71775253  0.71988304  0.67246154  0.71471312]
 [ 0.41259246  0.68709596  0.68157895  0.69835669  0.67727136  0.63753264
   0.80722222  0.80789474  0.81285641  0.80634892]
 [ 0.37024177  0.66833333  0.66929825  0.65633742  0.66272389  0.38242677
   0.6875      0.68859649  0.66540182  0.68185915]
 [ 0.53562574  0.74448718  0.77426901  0.72543629  0.73383087  0.43696107
   0.72847222  0.73128655  0.7239437   0.72654292]
 [ 0.03102571  0.49393939  0.54269006  0.41020236  0.47967216  0.4256859
   0.74748377  0.76315789  0.71955561  0.74624914]
 [ 0.23630856  0.63538961  0.65321637  0.62695339  0.62327667  0.36259241
   0.63138889  0.62719298  0.61212818  0.62173826]
 [ 0.50463507  0.76617965  0.77397661  0.74355624  0.75955274  0.52672905
   0.80573593  0.81783626  0.75405641  0.80327621]]
DT mean:
[0.33862019 0.66103651 0.68633528 0.63741702 0.65515145 0.36083233
 0.68111125 0.69875244 0.66219822 0.67622134]
---------------------------
---------------------------
RF performance:
[[ 0.54227524  0.78525253  0.79093567  0.79156419  0.78330728  0.50429914
   0.66928571  0.79795322  0.5345921   0.66534367]
 [ 0.52282548  0.74597222  0.74707602  0.75634944  0.7420605   0.47948497
   0.74924242  0.76871345  0.75557997  0.75004279]
 [ 0.44131289  0.74800325  0.75789474  0.69899782  0.7483951   0.48242063
   0.73111111  0.73157895  0.65744761  0.72768145]
 [ 0.43767809  0.67916667  0.67602339  0.66016226  0.67390234  0.26538817
   0.58487179  0.67690058  0.47565844  0.58076439]
 [ 0.44478812  0.75995671  0.78508772  0.76852358  0.76621525  0.42519577
   0.69597222  0.69678363  0.70651164  0.69236763]
 [ 0.36206779  0.70916667  0.70818713  0.7113166   0.70574604  0.5139407
   0.78291667  0.78654971  0.76356593  0.77923503]
 [ 0.27438797  0.74391234  0.75935673  0.6271837   0.74398716  0.37520442
   0.60916667  0.60906433  0.67778235  0.60021424]
 [ 0.79691431  0.92429487  0.93947368  0.90677329  0.92621042  0.58771842
   0.79545455  0.81403509  0.74055225  0.7971719 ]
 [ 0.45320777  0.64115385  0.70321637  0.6338851   0.63684968  0.2041807
   0.55032051  0.64795322  0.62239996  0.54557774]
 [ 0.23982876  0.62458333  0.6254386   0.69856357  0.61945654  0.33308716
   0.71916667  0.71988304  0.69908509  0.71289629]
 [ 0.16418411  0.55167208  0.57748538  0.53698859  0.54801087  0.6054642
   0.76688312  0.78011696  0.70847509  0.76652008]
 [ 0.51700375  0.77862554  0.79093567  0.80572219  0.7767196   0.3516371
   0.70573593  0.72105263  0.70481131  0.70403292]
 [ 0.36854626  0.6887013   0.69649123  0.62561204  0.68585833  0.15299039
   0.63659091  0.6377193   0.56453773  0.62849771]
 [ 0.13758     0.55833333  0.60818713  0.50805775  0.55423641  0.38811365
   0.67305556  0.67631579  0.65741046  0.66621686]
 [ 0.27619771  0.5922619   0.64415205  0.48181542  0.58650279  0.25811746
   0.66255411  0.68011696  0.57972992  0.65828315]
 [ 0.33164363  0.64756494  0.68538012  0.66365953  0.63784534  0.4314144
   0.67083333  0.7254386   0.64632944  0.66887696]
 [ 0.67105539  0.87050325  0.87426901  0.83599842  0.86998259  0.50567428
   0.72435065  0.74649123  0.75655839  0.72488327]
 [ 0.46476527  0.69125     0.84649123  0.38169907  0.67427898  0.43191119
   0.71337662  0.73070175  0.74259986  0.71068962]
 [ 0.43713836  0.74121795  0.79152047  0.65110307  0.74174286  0.45398492
   0.82027778  0.82426901  0.71337832  0.82133159]
 [ 0.31173141  0.71705128  0.7628655   0.62992026  0.71818337  0.29043192
   0.63679654  0.66491228  0.62313544  0.62870216]
 [-0.09165294  0.45436813  0.64356725  0.24155821  0.44184061  0.06418851
   0.50777778  0.50906433  0.41384125  0.49678491]
 [ 0.43414528  0.62958333  0.63070175  0.65766429  0.61914768  0.25855402
   0.6504329   0.69649123  0.6709863   0.6478464 ]
 [ 0.29340503  0.67467532  0.68625731  0.60609794  0.66527216  0.40082552
   0.61741758  0.73567251  0.64746987  0.62328353]
 [ 0.31880446  0.64416667  0.64766082  0.6731143   0.63283957  0.38470711
   0.72060606  0.72631579  0.69740363  0.71874723]
 [ 0.3391706   0.65719697  0.66491228  0.6725573   0.65075146  0.74812769
   0.84722222  0.84707602  0.81066103  0.84644608]
 [ 0.20461828  0.62305556  0.62602339  0.63431815  0.61935178  0.48626011
   0.73897727  0.74181287  0.72102245  0.73514773]
 [ 0.46975111  0.78173077  0.81871345  0.71395662  0.77466625  0.48372648
   0.7625      0.76345029  0.73308739  0.76131346]
 [ 0.07983914  0.55091991  0.59795322  0.46345727  0.54655096  0.44677637
   0.72418831  0.74152047  0.6875746   0.72441119]
 [ 0.26338296  0.6603355   0.68070175  0.63853496  0.65917605  0.29963289
   0.63027778  0.63187135  0.68739738  0.61052202]
 [ 0.66083237  0.82738095  0.84005848  0.82902142  0.82839394  0.54528175
   0.69301948  0.73596491  0.67697567  0.69194638]]
RF mean:
[0.37224762 0.69006857 0.72023392 0.65013921 0.68591606 0.40529133
 0.69301274 0.71885965 0.6692187  0.68952595]
---------------------------
---------------------------
SVM performance:
[[ 0.11669484  0.55375     0.59912281  0.30009276  0.47436895  0.
   0.5         0.75292398  0.          0.42940494]
 [ 0.3815861   0.68888889  0.69736842  0.66841353  0.68359248  0.23928217
   0.60822511  0.69239766  0.43996689  0.57924508]
 [ 0.49905017  0.7350974   0.76929825  0.68824454  0.73465951  0.44607592
   0.72263889  0.7251462   0.71462822  0.72039258]
 [ 0.25844122  0.62388889  0.64269006  0.53757832  0.60126708  0.
   0.5         0.70906433  0.          0.41479839]
 [ 0.51449103  0.73887987  0.78567251  0.7018969   0.74815718  0.46049818
   0.72930556  0.73099415  0.70929548  0.72208618]
 [ 0.30978293  0.65166667  0.65906433  0.61271248  0.6378632   0.480199
   0.74125     0.74269006  0.7268327   0.73453336]
 [-0.01076923  0.49545455  0.59912281  0.          0.37456486  0.2717667
   0.63527778  0.6371345   0.61644628  0.62724771]
 [ 0.75509422  0.86628205  0.89649123  0.85413829  0.87515873  0.47007338
   0.73003247  0.75789474  0.70235125  0.72867071]
 [ 0.          0.5         0.68684211  0.          0.40705645  0.
   0.5         0.69239766  0.          0.40899194]
 [ 0.2968254   0.64902778  0.64736842  0.62677707  0.63803582  0.08845484
   0.54222222  0.57105263  0.29891643  0.46057283]
 [ 0.          0.5         0.59912281  0.          0.37456486  0.04823957
   0.5213474   0.60964912  0.14386246  0.42117086]
 [ 0.06350835  0.52700216  0.63654971  0.16684159  0.44504242  0.03158485
   0.51339286  0.62046784  0.07315179  0.40499042]
 [ 0.1846774   0.58464286  0.63157895  0.45920965  0.54603855  0.
   0.5         0.56023392  0.          0.35904762]
 [ 0.          0.5         0.65964912  0.          0.39741935  0.3788153
   0.68847222  0.69298246  0.67659507  0.68475911]
 [ 0.          0.5         0.65964912  0.          0.39741935  0.
   0.5         0.61520468  0.          0.38086763]
 [ 0.          0.5         0.60467836  0.          0.37678161  0.
   0.5         0.65964912  0.          0.39741935]
 [ 0.24719088  0.60982143  0.67631579  0.4316977   0.56272385  0.
   0.5         0.60467836  0.          0.37678161]
 [ 0.          0.5         0.84619883  0.          0.45827349  0.01692308
   0.50714286  0.60467836  0.03779645  0.38841954]
 [ 0.          0.5         0.68684211  0.          0.40705645  0.01369863
   0.50625     0.55526316  0.03535534  0.36711367]
 [ 0.          0.5         0.68128655  0.          0.40512097  0.
   0.5         0.62631579  0.          0.38500556]
 [ 0.          0.5         0.76403509  0.          0.43303397  0.
   0.5         0.51081871  0.          0.33801314]
 [ 0.31045955  0.65597222  0.65263158  0.62109092  0.63757922  0.
   0.5         0.64853801  0.          0.39328142]
 [ 0.          0.5         0.57690058  0.          0.36569787  0.
   0.5         0.73625731  0.          0.42396139]
 [ 0.          0.5         0.52748538  0.          0.34515599  0.36607772
   0.67406566  0.70380117  0.59984593  0.65462913]
 [ 0.02702703  0.5125      0.56608187  0.05        0.37961096  0.48644274
   0.74388889  0.74269006  0.72919646  0.73732691]
 [-0.0109589   0.495       0.52748538  0.          0.34515599  0.41897561
   0.70681818  0.72046784  0.68571798  0.70290582]
 [ 0.19931743  0.57948718  0.73684211  0.33503985  0.54950123  0.5592443
   0.77875     0.78011696  0.76356193  0.77280986]
 [ 0.          0.5         0.65409357  0.          0.39535039  0.06496278
   0.52767857  0.62660819  0.14874468  0.43072113]
 [ 0.          0.5         0.61520468  0.          0.38086763  0.26309539
   0.62611111  0.64853801  0.54616711  0.59888611]
 [ 0.58205328  0.78311688  0.8122807   0.75772616  0.78431377  0.16832636
   0.57364719  0.67046784  0.41876334  0.54563328]]
SVM mean:
[0.15748239 0.57501596 0.66993177 0.26038199 0.50538107 0.17575788
 0.5858839  0.66497076 0.30223986 0.51965624]
---------------------------
---------------------------
GBM performance:
[[ 0.47741471  0.73229798  0.75263158  0.68504306  0.72729398  0.2948465
   0.625       0.81403509  0.34801844  0.60790585]
 [ 0.46353954  0.73055556  0.73625731  0.68801524  0.7259778   0.40182953
   0.691829    0.74152047  0.6377789   0.68775285]
 [ 0.47589354  0.71465909  0.74707602  0.67699719  0.71478219  0.33507673
   0.66652778  0.67017544  0.65218521  0.66140487]
 [ 0.3356588   0.66763889  0.67076023  0.66374134  0.66477093  0.16059314
   0.57064103  0.74239766  0.26793394  0.53191412]
 [ 0.53351058  0.76136364  0.80760234  0.70891754  0.77109936  0.48285582
   0.75652778  0.75847953  0.72199636  0.75055974]
 [ 0.40807935  0.70513889  0.70350877  0.69964223  0.69886841  0.53171958
   0.75805556  0.76461988  0.74839898  0.75510064]
 [ 0.39111668  0.68993506  0.72573099  0.64087677  0.68037903  0.40952075
   0.70611111  0.70350877  0.69904187  0.70111596]
 [ 0.7660134   0.8874359   0.90701754  0.88004958  0.88921312  0.54311764
   0.77508117  0.80263158  0.74726408  0.78202945]
 [ 0.11053431  0.55025641  0.69824561  0.24888785  0.50547683 -0.05491586
   0.47628205  0.65438596  0.04082483  0.4078436 ]
 [ 0.22452559  0.60666667  0.60789474  0.58782807  0.59421293  0.24903896
   0.62666667  0.63830409  0.59345091  0.61693716]
 [ 0.25301387  0.62345779  0.66081871  0.5421977   0.60422088  0.43619357
   0.7124026   0.7371345   0.68766485  0.71405352]
 [ 0.6162928   0.79556277  0.82982456  0.7746463   0.80406074  0.42493328
   0.70600649  0.7371345   0.68886871  0.70856355]
 [ 0.35468675  0.66582792  0.69093567  0.61013868  0.65082192  0.18635055
   0.59068182  0.61023392  0.54925649  0.5762551 ]
 [ 0.08923813  0.53690476  0.68070175  0.18855415  0.4742474   0.35631891
   0.68208333  0.69181287  0.65363397  0.67378394]
 [ 0.0309077   0.51666667  0.65964912  0.15982325  0.4481829   0.14543234
   0.55037879  0.63157895  0.37902582  0.50738294]
 [ 0.14697564  0.56850649  0.65409357  0.34850259  0.51486714  0.27676185
   0.62202381  0.7254386   0.46906707  0.60979103]
 [ 0.65497156  0.83194805  0.84093567  0.82833556  0.83325654  0.28515855
   0.62970779  0.69210526  0.55533394  0.61723534]
 [-0.02566234  0.49041667  0.82982456  0.          0.45336803  0.43415429
   0.70397727  0.73099415  0.69062289  0.70557947]
 [ 0.16905049  0.56557692  0.69766082  0.40090746  0.54333535  0.43396346
   0.71972222  0.73040936  0.69169366  0.71725259]
 [ 0.43596801  0.69961538  0.78976608  0.60523466  0.70093768  0.27659314
   0.62516234  0.69766082  0.53432829  0.61288464]
 [ 0.          0.5         0.76403509  0.          0.43303397  0.01906715
   0.50944444  0.51140351  0.49800679  0.50574753]
 [ 0.33025189  0.67097222  0.66959064  0.65843798  0.66486904  0.1137771
   0.55059524  0.66520468  0.28830508  0.50087365]
 [ 0.33310544  0.65021104  0.69269006  0.59942368  0.63775603  0.07700348
   0.52865385  0.74736842  0.13944272  0.47956623]
 [ 0.33578683  0.65611111  0.65877193  0.66154554  0.65049202  0.41060774
   0.70150253  0.71432749  0.69574418  0.70166243]
 [ 0.32341378  0.66267677  0.6871345   0.60118075  0.64490548  0.60625153
   0.82        0.81929825  0.80764041  0.81753194]
 [ 0.36320935  0.67152778  0.6871345   0.61671357  0.65045641  0.3838165
   0.69102273  0.70438596  0.66403658  0.6830526 ]
 [ 0.44129065  0.70108974  0.79122807  0.62176148  0.70854508  0.59174617
   0.78972222  0.79122807  0.78152806  0.78541975]
 [ 0.02153481  0.50995671  0.62631579  0.258617    0.4662192   0.45359916
   0.70413961  0.75877193  0.62834637  0.69470688]
 [ 0.27739142  0.62256494  0.68625731  0.54787167  0.60420598  0.38247156
   0.68375     0.69239766  0.65558695  0.67756306]
 [ 0.60212539  0.79307359  0.80730994  0.79318267  0.78808095  0.42002676
   0.70541126  0.77426901  0.60699077  0.70922755]]
GBM mean:
[0.33132796 0.65928718 0.72538012 0.54323578 0.64159791 0.335597
 0.66263702 0.71510721 0.5707339  0.65002327]
---------------------------
---------------------------
BDDAE performance:
[[-0.08301855  0.45803571  0.48108108  0.41546041  0.44694157 -0.00517742
   0.49702381  0.73513514  0.09939935  0.45186084]
 [ 0.36748467  0.68544118  0.68378378  0.67976997  0.68095773  0.55292941
   0.76708075  0.7972973   0.7495815   0.77275333]
 [-0.042221    0.4796131   0.50810811  0.41801346  0.46432869  0.27364078
   0.63581871  0.64054054  0.58627728  0.61566456]
 [ 0.07605508  0.53764706  0.54594595  0.51574283  0.53043594  0.19959995
   0.58968531  0.71081081  0.48202076  0.5821875 ]
 [ 0.37107159  0.67950311  0.71621622  0.6540813   0.68068996  0.32060295
   0.66067251  0.65945946  0.65527193  0.65741831]
 [ 0.59318656  0.79605263  0.7972973   0.7896873   0.7944084  -0.05546396
   0.47323529  0.48108108  0.43335125  0.45752828]
 [-0.08616239  0.45939394  0.49459459  0.34611579  0.42942827 -0.03450524
   0.48274854  0.48378378  0.47127349  0.47751733]
 [ 0.34390656  0.65133333  0.75135135  0.57525278  0.6581013  -0.02306448
   0.48863636  0.54324324  0.37025983  0.45599116]
 [ 0.31630911  0.646       0.73243243  0.57528199  0.64587316  0.48445664
   0.70524476  0.82162162  0.63561213  0.72882461]
 [ 0.01564312  0.50789474  0.50810811  0.49780322  0.50295499  0.22488828
   0.61132353  0.61891892  0.60076845  0.60946242]
 [-0.04578875  0.47848485  0.53243243  0.34032644  0.45158213  0.230387
   0.60651515  0.65945946  0.52047308  0.58817116]
 [ 0.07281028  0.53291925  0.6         0.4147017   0.51178931  0.41274396
   0.71568323  0.71081081  0.71018014  0.70174788]
 [ 0.14855782  0.57247024  0.58648649  0.54520503  0.56428438  0.32235629
   0.66235119  0.66486486  0.65784697  0.65910141]
 [ 0.15338662  0.56939103  0.65405405  0.47418615  0.55577865  0.34114598
   0.67058824  0.67297297  0.66490587  0.66843026]
 [ 0.01571564  0.50737179  0.62162162  0.28133174  0.4622975   0.1955638
   0.59534161  0.63243243  0.56659508  0.59269564]
 [ 0.11429878  0.55484848  0.58918919  0.50912543  0.54517203  0.23006018
   0.59551282  0.71081081  0.44342212  0.57243785]
 [ 0.51017756  0.76287879  0.76216216  0.74079117  0.74697979  0.15292258
   0.56818182  0.63783784  0.41698371  0.52712178]
 [ 0.19895538  0.59623656  0.81891892  0.42644179  0.58968193  0.0065344
   0.5030303   0.55405405  0.40775238  0.47870159]
 [ 0.22364026  0.60883333  0.66756757  0.57361596  0.60614149  0.24755979
   0.62279412  0.62702703  0.59685634  0.61189759]
 [ 0.23007052  0.60933333  0.69459459  0.52500548  0.5981842  -0.00312484
   0.49813665  0.58108108  0.33304985  0.46211171]
 [-0.00587333  0.49742063  0.72432432  0.12000089  0.45402643  0.15352301
   0.57646199  0.57837838  0.56676701  0.5725962 ]
 [ 0.06767344  0.53406433  0.53243243  0.52014118  0.52625077 -0.02838434
   0.48830128  0.59459459  0.26928685  0.45158366]
 [ 0.03001233  0.51488095  0.52702703  0.47846748  0.50215965  0.5061643
   0.72148148  0.83243243  0.67279278  0.74606272]
 [ 0.20971378  0.60485294  0.60810811  0.59724436  0.60214035  0.29586541
   0.64702381  0.65675676  0.64078172  0.6467718 ]
 [ 0.07872603  0.53928571  0.55135135  0.5227644   0.53548984  0.12815345
   0.56418129  0.56486486  0.5524643   0.55869946]
 [ 0.29046314  0.6425      0.65405405  0.62132305  0.63834101  0.08727703
   0.54241071  0.55405405  0.53027349  0.5406271 ]
 [ 0.45752376  0.72027972  0.78378378  0.69785866  0.72687683  0.56960524
   0.78289474  0.78648649  0.76870537  0.78003301]
 [ 0.00750703  0.5036859   0.57567568  0.42891833  0.49482881  0.4001847
   0.69090909  0.72702703  0.65584619  0.69153234]
 [ 0.10181326  0.55062112  0.58378378  0.52400284  0.54661752  0.437095
   0.71397059  0.72702703  0.68943     0.70997505]
 [ 0.38517823  0.68385093  0.72162162  0.65642296  0.68601127  0.01584563
   0.50769231  0.62432432  0.23645952  0.45469183]]
BDDAE mean:
[0.17056055 0.58283749 0.6336036  0.5155028  0.57262513 0.22131285
 0.6061644  0.65297297 0.53282296 0.59413995]
---------------------------
---------------------------
DUMMY performance:
[[0.         0.5        0.55497076 0.         0.35686371 0.
  0.5        0.75292398 0.         0.42940494]
 [0.         0.5        0.52748538 0.         0.34515599 0.
  0.5        0.62631579 0.         0.38500556]
 [0.         0.5        0.57134503 0.         0.36348112 0.
  0.5        0.52192982 0.         0.34277504]
 [0.         0.5        0.53859649 0.         0.3499179  0.
  0.5        0.70906433 0.         0.41479839]
 [0.         0.5        0.60994152 0.         0.37882462 0.
  0.5        0.51081871 0.         0.33801314]
 [0.         0.5        0.51637427 0.         0.34039409 0.
  0.5        0.53304094 0.         0.34753695]
 [0.         0.5        0.60467836 0.         0.37678161 0.
  0.5        0.51637427 0.         0.34039409]
 [0.         0.5        0.68128655 0.         0.40512097 0.
  0.5        0.60467836 0.         0.37678161]
 [0.         0.5        0.68684211 0.         0.40705645 0.
  0.5        0.69239766 0.         0.40899194]
 [0.         0.5        0.51637427 0.         0.34039409 0.
  0.5        0.53859649 0.         0.3499179 ]
 [0.         0.5        0.59912281 0.         0.37456486 0.
  0.5        0.59356725 0.         0.37234811]
 [0.         0.5        0.62076023 0.         0.3829366  0.
  0.5        0.60994152 0.         0.37882462]
 [0.         0.5        0.56578947 0.         0.36126437 0.
  0.5        0.56023392 0.         0.35904762]
 [0.         0.5        0.65964912 0.         0.39741935 0.
  0.5        0.53304094 0.         0.34753695]
 [0.         0.5        0.65964912 0.         0.39741935 0.
  0.5        0.61520468 0.         0.38086763]
 [0.         0.5        0.60467836 0.         0.37678161 0.
  0.5        0.65964912 0.         0.39741935]
 [0.         0.5        0.5880117  0.         0.37013136 0.
  0.5        0.60467836 0.         0.37678161]
 [0.         0.5        0.84619883 0.         0.45827349 0.
  0.5        0.59912281 0.         0.37456486]
 [0.         0.5        0.68684211 0.         0.40705645 0.
  0.5        0.5497076  0.         0.3546798 ]
 [0.         0.5        0.68128655 0.         0.40512097 0.
  0.5        0.62631579 0.         0.38500556]
 [0.         0.5        0.76403509 0.         0.43303397 0.
  0.5        0.51081871 0.         0.33801314]
 [0.         0.5        0.51081871 0.         0.33801314 0.
  0.5        0.64853801 0.         0.39328142]
 [0.         0.5        0.57690058 0.         0.36569787 0.
  0.5        0.73625731 0.         0.42396139]
 [0.         0.5        0.52748538 0.         0.34515599 0.
  0.5        0.55497076 0.         0.35686371]
 [0.         0.5        0.55497076 0.         0.35686371 0.
  0.5        0.50526316 0.         0.33563218]
 [0.         0.5        0.53304094 0.         0.34753695 0.
  0.5        0.56023392 0.         0.35904762]
 [0.         0.5        0.69239766 0.         0.40899194 0.
  0.5        0.51081871 0.         0.33801314]
 [0.         0.5        0.65409357 0.         0.39535039 0.
  0.5        0.60467836 0.         0.37678161]
 [0.         0.5        0.61520468 0.         0.38086763 0.
  0.5        0.53859649 0.         0.3499179 ]
 [0.         0.5        0.61520468 0.         0.38086763 0.
  0.5        0.6374269  0.         0.38914349]]
DUMMY mean:
[0.         0.5        0.6121345  0.         0.37824461 0.
 0.5        0.59217349 0.         0.37071171]
---------------------------
Current folder: C:\Users\Javier\Dropbox\c_sldl_1_2_27
-------------------------------------
----- RESULTS from .csv files ------
-------------------------------------
---------------------------
ALG Means: 
-rows: alg : KNN = 0; DT = 1; RF = 2; SVM = 3; GBM = 4; BDDAE = 5; DUMMY = 5
columns:
'val_cohen','val_uar', 'val_acc', 'val_gm',  'val_f1',  'aro_cohen','aro_uar', 'aro_acc', 'aro_gm',  'aro_f1'
-------------------------------------------------------------
  v_c   v_u   v_a   v_g   v_f1  a_c   a_u   a_a   a_g   a_f1
[[0.35  0.673 0.714 0.62  0.667 0.38  0.688 0.715 0.66  0.685]
 [0.339 0.661 0.686 0.637 0.655 0.361 0.681 0.699 0.662 0.676]
 [0.372 0.69  0.72  0.65  0.686 0.405 0.693 0.719 0.669 0.69 ]
 [0.157 0.575 0.67  0.26  0.505 0.176 0.586 0.665 0.302 0.52 ]
 [0.331 0.659 0.725 0.543 0.642 0.336 0.663 0.715 0.571 0.65 ]
 [0.171 0.583 0.634 0.516 0.573 0.221 0.606 0.653 0.533 0.594]
 [0.    0.5   0.612 0.    0.378 0.    0.5   0.592 0.    0.371]]
-------------------------------------------------------------
Standard Deviation of each metric:
[[0.203 0.101 0.086 0.16  0.106 0.156 0.078 0.074 0.097 0.08 ]
 [0.159 0.079 0.073 0.102 0.079 0.142 0.071 0.071 0.077 0.073]
 [0.179 0.099 0.089 0.136 0.101 0.14  0.076 0.069 0.085 0.078]
 [0.21  0.101 0.087 0.303 0.148 0.199 0.099 0.068 0.31  0.147]
 [0.2   0.099 0.071 0.23  0.118 0.163 0.084 0.064 0.188 0.099]
 [0.18  0.088 0.098 0.138 0.096 0.185 0.089 0.09  0.157 0.102]
 [0.    0.    0.077 0.    0.029 0.    0.    0.068 0.    0.026]]
-------------------------------------------------------------
std_dev/mean [percentage]:
[[ 58.  15.  12.  26.  16.  41.  11.  10.  15.  12.]
 [ 47.  12.  11.  16.  12.  39.  10.  10.  12.  11.]
 [ 48.  14.  12.  21.  15.  35.  11.  10.  13.  11.]
 [133.  18.  13. 116.  29. 113.  17.  10. 103.  28.]
 [ 60.  15.  10.  42.  18.  49.  13.   9.  33.  15.]
 [106.  15.  15.  27.  17.  84.  15.  14.  29.  17.]
 [  0.   0.  13.   0.   8.   0.   0.  11.   0.   7.]]
-------------------------------------
Current folder: C:\Users\Javier\Dropbox\c_sldl_1_2_27
-------------------------------------
----- RESULTS ------
-------------------------------------
Window size (sec):  8.992
step (sec):  6.752
overlap:  True
perc. of overlap:  24.91103202846975
overlap duration (sec):  2.24
Number of windows / instances:  182
Elapsed time: 538.4249179522196 minutes
Elapsed time: 8.973748632536994 hours
