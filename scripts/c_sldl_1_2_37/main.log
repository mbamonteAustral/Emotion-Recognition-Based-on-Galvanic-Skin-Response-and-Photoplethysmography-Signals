2024-05-06 05:36:19.489850: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-05-06 05:36:23.201202: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-05-06 05:36:32.727242: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
    
    
-------------------------------
participant:  1
-------------------------------
    
    
participant:  1
corriendo en PC gamer:
Window size (sec):  13.0
step (sec):  6.5
overlap:  True
perc. of overlap:  50.0
overlap duration (sec):  6.5
['gsr_chunks', 'ppg_chunks', 'val_chunks', 'aro_chunks', 'time_chunks', 'tag_chunks', 'video']
C:\Users\Javier\Dropbox\c_sldl_1_2_37\functions.py:880: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!
You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.
A typical example is when you are setting values in a column of a DataFrame, like:

3 - val_loss: 13.9787 - val_mean_squared_error: 13.9787
(147, 812, 6)
Model: "sequential_1198"
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer (type)                    â”‚ Output Shape           â”‚       Param # â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1stConvL (Conv1D)               â”‚ (None, 12992, 5)       â”‚           105 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1stPoolL (AveragePooling1D)     â”‚ (None, 3248, 5)        â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2ndConvL (Conv1D)               â”‚ (None, 3248, 6)        â”‚           306 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2ndPoolL (AveragePooling1D)     â”‚ (None, 812, 6)         â”‚             0 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 2,209 (8.63 KB)
 Trainable params: 411 (1.61 KB)
 Non-trainable params: 0 (0.00 B)
 Optimizer params: 1,798 (7.03 KB)
----- train_PPG_AE -------
Model: "sequential_1199"
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer (type)                    â”‚ Output Shape           â”‚       Param # â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1stConvL (Conv1D)               â”‚ (None, 12992, 5)       â”‚           105 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1stPoolL (AveragePooling1D)     â”‚ (None, 3248, 5)        â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2ndConvL (Conv1D)               â”‚ (None, 3248, 6)        â”‚           306 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2ndPoolL (AveragePooling1D)     â”‚ (None, 812, 6)         â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling1d_2398              â”‚ (None, 3248, 6)        â”‚             0 â”‚
â”‚ (UpSampling1D)                  â”‚                        â”‚               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv1d_transpose_2398           â”‚ (None, 3248, 6)        â”‚           366 â”‚
â”‚ (Conv1DTranspose)               â”‚                        â”‚               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling1d_2399              â”‚ (None, 12992, 6)       â”‚             0 â”‚
â”‚ (UpSampling1D)                  â”‚                        â”‚               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv1d_transpose_2399           â”‚ (None, 12992, 1)       â”‚           121 â”‚
â”‚ (Conv1DTranspose)               â”‚                        â”‚               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 898 (3.51 KB)
 Trainable params: 898 (3.51 KB)
 Non-trainable params: 0 (0.00 B)
Epoch 1/5

[1m  1/132[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2:30[0m 1s/step - loss: 0.0886 - mean_squared_error: 0.0886
[1m  6/132[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 11ms/step - loss: 0.0929 - mean_squared_error: 0.0929
[1m 11/132[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 11ms/step - loss: 0.0804 - mean_squared_error: 0.0804
[1m 16/132[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 11ms/step - loss: 0.0741 - mean_squared_error: 0.0741
[1m 22/132[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - loss: 0.0681 - mean_squared_error: 0.0681
[1m 28/132[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - loss: 0.0633 - mean_squared_error: 0.0633
[1m 33/132[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - loss: 0.0601 - mean_squared_error: 0.0601
[1m 38/132[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0574 - mean_squared_error: 0.0574
[1m 44/132[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0546 - mean_squared_error: 0.0546
[1m 49/132[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0526 - mean_squared_error: 0.0526
[1m 55/132[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0504 - mean_squared_error: 0.0504
[1m 61/132[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0485 - mean_squared_error: 0.0485
[1m 67/132[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0467 - mean_squared_error: 0.0467
[1m 72/132[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0454 - mean_squared_error: 0.0454
[1m 79/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0439 - mean_squared_error: 0.0439
[1m 85/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0429 - mean_squared_error: 0.0429
[1m 91/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0420 - mean_squared_error: 0.0420
[1m 97/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0412 - mean_squared_error: 0.0412
[1m103/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0404 - mean_squared_error: 0.0404
[1m109/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0397 - mean_squared_error: 0.0397
[1m115/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0391 - mean_squared_error: 0.0391
[1m122/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 10ms/step - loss: 0.0384 - mean_squared_error: 0.0384
[1m128/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 10ms/step - loss: 0.0378 - mean_squared_error: 0.0378
[1m132/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m3s[0m 12ms/step - loss: 0.0373 - mean_squared_error: 0.0373 - val_loss: 0.0171 - val_mean_squared_error: 0.0171
Epoch 2/5

[1m  1/132[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 32ms/step - loss: 0.0072 - mean_squared_error: 0.0072
[1m  7/132[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - loss: 0.0079 - mean_squared_error: 0.0079
[1m 13/132[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - loss: 0.0094 - mean_squared_error: 0.0094
[1m 20/132[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - loss: 0.0109 - mean_squared_error: 0.0109
[1m 26/132[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - loss: 0.0115 - mean_squared_error: 0.0115
[1m 32/132[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0118 - mean_squared_error: 0.0118
[1m 38/132[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0120 - mean_squared_error: 0.0120
[1m 44/132[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0124 - mean_squared_error: 0.0124
[1m 50/132[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0127 - mean_squared_error: 0.0127
[1m 56/132[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0130 - mean_squared_error: 0.0130
[1m 61/132[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0133 - mean_squared_error: 0.0133
[1m 67/132[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0136 - mean_squared_error: 0.0136
[1m 73/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0138 - mean_squared_error: 0.0138
[1m 80/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0141 - mean_squared_error: 0.0141
[1m 86/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0143 - mean_squared_error: 0.0143
[1m 92/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0145 - mean_squared_error: 0.0145
[1m 97/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0146 - mean_squared_error: 0.0146
[1m103/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0147 - mean_squared_error: 0.0147
[1m109/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0148 - mean_squared_error: 0.0148
[1m115/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0149 - mean_squared_error: 0.0149
[1m121/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 10ms/step - loss: 0.0150 - mean_squared_error: 0.0150
[1m127/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 10ms/step - loss: 0.0151 - mean_squared_error: 0.0151
[1m132/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 10ms/step - loss: 0.0152 - mean_squared_error: 0.0152 - val_loss: 0.0157 - val_mean_squared_error: 0.0157
Epoch 3/5

[1m  1/132[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 31ms/step - loss: 0.0066 - mean_squared_error: 0.0066
[1m  7/132[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - loss: 0.0100 - mean_squared_error: 0.0100
[1m 13/132[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - loss: 0.0108 - mean_squared_error: 0.0108
[1m 19/132[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - loss: 0.0114 - mean_squared_error: 0.0114
[1m 25/132[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - loss: 0.0125 - mean_squared_error: 0.0125
[1m 31/132[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - loss: 0.0130 - mean_squared_error: 0.0130
[1m 38/132[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0139 - mean_squared_error: 0.0139
[1m 44/132[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0146 - mean_squared_error: 0.0146
[1m 51/132[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0153 - mean_squared_error: 0.0153
[1m 57/132[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0156 - mean_squared_error: 0.0156
[1m 63/132[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0159 - mean_squared_error: 0.0159
[1m 70/132[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0162 - mean_squared_error: 0.0162
[1m 76/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0164 - mean_squared_error: 0.0164
[1m 82/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0165 - mean_squared_error: 0.0165
[1m 89/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0167 - mean_squared_error: 0.0167
[1m 95/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0168 - mean_squared_error: 0.0168
[1m102/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0169 - mean_squared_error: 0.0169
[1m108/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0169 - mean_squared_error: 0.0169
[1m114/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0169 - mean_squared_error: 0.0169
[1m120/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 10ms/step - loss: 0.0169 - mean_squared_error: 0.0169
[1m125/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 10ms/step - loss: 0.0169 - mean_squared_error: 0.0169
[1m132/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 10ms/step - loss: 0.0169 - mean_squared_error: 0.0169
[1m132/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 10ms/step - loss: 0.0168 - mean_squared_error: 0.0168 - val_loss: 0.0144 - val_mean_squared_error: 0.0144
Epoch 4/5

[1m  1/132[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 31ms/step - loss: 0.0079 - mean_squared_error: 0.0079
[1m  6/132[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 13ms/step - loss: 0.0095 - mean_squared_error: 0.0095
[1m 12/132[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 11ms/step - loss: 0.0095 - mean_squared_error: 0.0095
[1m 18/132[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 11ms/step - loss: 0.0103 - mean_squared_error: 0.0103
[1m 24/132[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 11ms/step - loss: 0.0108 - mean_squared_error: 0.0108
[1m 29/132[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 11ms/step - loss: 0.0111 - mean_squared_error: 0.0111
[1m 36/132[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0117 - mean_squared_error: 0.0117
[1m 42/132[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0122 - mean_squared_error: 0.0122
[1m 48/132[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0125 - mean_squared_error: 0.0125
[1m 55/132[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0128 - mean_squared_error: 0.0128
[1m 62/132[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0130 - mean_squared_error: 0.0130
[1m 68/132[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0131 - mean_squared_error: 0.0131
[1m 74/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0132 - mean_squared_error: 0.0132
[1m 80/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0133 - mean_squared_error: 0.0133
[1m 87/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0135 - mean_squared_error: 0.0135
[1m 93/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0136 - mean_squared_error: 0.0136
[1m100/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0137 - mean_squared_error: 0.0137
[1m105/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0138 - mean_squared_error: 0.0138
[1m112/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0138 - mean_squared_error: 0.0138
[1m119/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 10ms/step - loss: 0.0139 - mean_squared_error: 0.0139
[1m125/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 10ms/step - loss: 0.0140 - mean_squared_error: 0.0140
[1m131/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 10ms/step - loss: 0.0141 - mean_squared_error: 0.0141
[1m132/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 10ms/step - loss: 0.0141 - mean_squared_error: 0.0141 - val_loss: 0.0140 - val_mean_squared_error: 0.0140
Epoch 5/5

[1m  1/132[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 16ms/step - loss: 0.0668 - mean_squared_error: 0.0668
[1m  6/132[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 12ms/step - loss: 0.0360 - mean_squared_error: 0.0360
[1m 13/132[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - loss: 0.0246 - mean_squared_error: 0.0246
[1m 20/132[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - loss: 0.0204 - mean_squared_error: 0.0204
[1m 26/132[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - loss: 0.0186 - mean_squared_error: 0.0186
[1m 32/132[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - loss: 0.0180 - mean_squared_error: 0.0180
[1m 37/132[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0176 - mean_squared_error: 0.0176
[1m 43/132[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0172 - mean_squared_error: 0.0172
[1m 48/132[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0168 - mean_squared_error: 0.0168
[1m 53/132[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0165 - mean_squared_error: 0.0165
[1m 60/132[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0161 - mean_squared_error: 0.0161
[1m 67/132[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0158 - mean_squared_error: 0.0158
[1m 73/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0155 - mean_squared_error: 0.0155
[1m 79/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0154 - mean_squared_error: 0.0154
[1m 85/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0152 - mean_squared_error: 0.0152
[1m 90/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0151 - mean_squared_error: 0.0151
[1m 97/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0151 - mean_squared_error: 0.0151
[1m102/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0150 - mean_squared_error: 0.0150
[1m108/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0150 - mean_squared_error: 0.0150
[1m114/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0150 - mean_squared_error: 0.0150
[1m120/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 10ms/step - loss: 0.0150 - mean_squared_error: 0.0150
[1m126/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 10ms/step - loss: 0.0150 - mean_squared_error: 0.0150
[1m132/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 10ms/step - loss: 0.0150 - mean_squared_error: 0.0150
[1m132/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 11ms/step - loss: 0.0150 - mean_squared_error: 0.0150 - val_loss: 0.0145 - val_mean_squared_error: 0.0145
(12992, 1, 5)
Model: "sequential_1199"
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer (type)                    â”‚ Output Shape           â”‚       Param # â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1stConvL (Conv1D)               â”‚ (None, 12992, 5)       â”‚           105 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1stPoolL (AveragePooling1D)     â”‚ (None, 3248, 5)        â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2ndConvL (Conv1D)               â”‚ (None, 3248, 6)        â”‚           306 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2ndPoolL (AveragePooling1D)     â”‚ (None, 812, 6)         â”‚             0 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 2,209 (8.63 KB)
 Trainable params: 411 (1.61 KB)
 Non-trainable params: 0 (0.00 B)
 Optimizer params: 1,798 (7.03 KB)
Model: "valence_NN"
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer (type)        â”‚ Output Shape      â”‚    Param # â”‚ Connected to      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ inputGSR            â”‚ (None, 12992, 1)  â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ inputPPG            â”‚ (None, 12992, 1)  â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ sequential_1198     â”‚ (None, 812, 6)    â”‚        411 â”‚ inputGSR[0][0]    â”‚
â”‚ (Sequential)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ sequential_1199     â”‚ (None, 812, 6)    â”‚        411 â”‚ inputPPG[0][0]    â”‚
â”‚ (Sequential)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ concatenate_599     â”‚ (None, 812, 12)   â”‚          0 â”‚ sequential_1198[â€¦ â”‚
â”‚ (Concatenate)       â”‚                   â”‚            â”‚ sequential_1199[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ permute_599         â”‚ (None, 12, 812)   â”‚          0 â”‚ concatenate_599[â€¦ â”‚
â”‚ (Permute)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ flatten_599         â”‚ (None, 9744)      â”‚          0 â”‚ permute_599[0][0] â”‚
â”‚ (Flatten)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout_599         â”‚ (None, 9744)      â”‚          0 â”‚ flatten_599[0][0] â”‚
â”‚ (Dropout)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_599 (Dense)   â”‚ (None, 1)         â”‚      9,745 â”‚ dropout_599[0][0] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 10,567 (41.28 KB)
 Trainable params: 10,567 (41.28 KB)
 Non-trainable params: 0 (0.00 B)
Epoch 1/10

[1m  1/132[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2:58[0m 1s/step - binary_accuracy: 0.0000e+00 - loss: 0.7479
[1m  7/132[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 9ms/step - binary_accuracy: 0.1289 - loss: 0.8358     
[1m 13/132[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 9ms/step - binary_accuracy: 0.2868 - loss: 0.7894
[1m 19/132[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 9ms/step - binary_accuracy: 0.3526 - loss: 0.7565
[1m 25/132[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 9ms/step - binary_accuracy: 0.3919 - loss: 0.7407
[1m 31/132[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.4336 - loss: 0.7249
[1m 37/132[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.4659 - loss: 0.7118
[1m 43/132[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.4921 - loss: 0.7011
[1m 49/132[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.5156 - loss: 0.6909 
[1m 55/132[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.5373 - loss: 0.6795
[1m 61/132[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.5559 - loss: 0.6705 
[1m 67/132[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.5714 - loss: 0.6633
[1m 73/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.5837 - loss: 0.6594
[1m 79/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.5926 - loss: 0.6585
[1m 85/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.5990 - loss: 0.6577
[1m 91/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.6036 - loss: 0.6570
[1m 97/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.6081 - loss: 0.6558
[1m103/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.6119 - loss: 0.6552
[1m109/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.6156 - loss: 0.6543
[1m115/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.6184 - loss: 0.6537
[1m121/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.6202 - loss: 0.6537
[1m127/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.6211 - loss: 0.6539
[1m132/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m3s[0m 11ms/step - binary_accuracy: 0.6217 - loss: 0.6542 - val_binary_accuracy: 0.6667 - val_loss: 0.6267
Epoch 2/10

[1m  1/132[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 32ms/step - binary_accuracy: 0.0000e+00 - loss: 0.8149
[1m  7/132[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - binary_accuracy: 0.5007 - loss: 0.6371    
[1m 14/132[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - binary_accuracy: 0.5303 - loss: 0.6154
[1m 21/132[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 9ms/step - binary_accuracy: 0.5519 - loss: 0.6062 
[1m 28/132[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.5681 - loss: 0.6059
[1m 35/132[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.5829 - loss: 0.6070
[1m 42/132[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.5884 - loss: 0.6099
[1m 49/132[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.5970 - loss: 0.6101
[1m 55/132[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.6035 - loss: 0.6090
[1m 61/132[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.6106 - loss: 0.6072
[1m 68/132[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.6133 - loss: 0.6085
[1m 75/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.6141 - loss: 0.6105
[1m 82/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.6122 - loss: 0.6130
[1m 88/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.6115 - loss: 0.6141
[1m 94/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.6114 - loss: 0.6149
[1m100/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.6112 - loss: 0.6167
[1m108/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.6114 - loss: 0.6188
[1m115/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.6108 - loss: 0.6209
[1m121/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.6107 - loss: 0.6223
[1m128/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.6105 - loss: 0.6237
[1m132/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 9ms/step - binary_accuracy: 0.6108 - loss: 0.6243 - val_binary_accuracy: 0.8000 - val_loss: 0.4794
Epoch 3/10

[1m  1/132[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 31ms/step - binary_accuracy: 1.0000 - loss: 0.2425
[1m  7/132[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - binary_accuracy: 0.8473 - loss: 0.4008
[1m 14/132[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - binary_accuracy: 0.7994 - loss: 0.5001
[1m 21/132[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 9ms/step - binary_accuracy: 0.8100 - loss: 0.4907 
[1m 28/132[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.8152 - loss: 0.4904
[1m 35/132[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.8076 - loss: 0.5115
[1m 41/132[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.8003 - loss: 0.5263
[1m 46/132[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7944 - loss: 0.5355
[1m 53/132[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7883 - loss: 0.5435
[1m 60/132[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7852 - loss: 0.5486
[1m 66/132[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7847 - loss: 0.5510
[1m 73/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7840 - loss: 0.5542
[1m 79/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7826 - loss: 0.5585
[1m 85/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7805 - loss: 0.5635
[1m 92/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7778 - loss: 0.5682
[1m 98/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7756 - loss: 0.5717
[1m104/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7732 - loss: 0.5750
[1m110/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7706 - loss: 0.5781
[1m116/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7683 - loss: 0.5805
[1m123/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7663 - loss: 0.5825
[1m129/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7646 - loss: 0.5840
[1m132/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 10ms/step - binary_accuracy: 0.7633 - loss: 0.5849 - val_binary_accuracy: 0.8000 - val_loss: 0.4862
Epoch 4/10

[1m  1/132[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 31ms/step - binary_accuracy: 1.0000 - loss: 0.4817
[1m  6/132[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 13ms/step - binary_accuracy: 0.7111 - loss: 0.6714
[1m 12/132[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 12ms/step - binary_accuracy: 0.6549 - loss: 0.6665
[1m 18/132[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 11ms/step - binary_accuracy: 0.6611 - loss: 0.6460
[1m 25/132[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - binary_accuracy: 0.6868 - loss: 0.6198
[1m 31/132[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - binary_accuracy: 0.7012 - loss: 0.6041
[1m 39/132[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7079 - loss: 0.5971
[1m 44/132[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7080 - loss: 0.5991
[1m 51/132[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7109 - loss: 0.5984
[1m 58/132[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7153 - loss: 0.5951
[1m 65/132[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7160 - loss: 0.5950
[1m 71/132[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7143 - loss: 0.5967
[1m 78/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7121 - loss: 0.5988 
[1m 84/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7102 - loss: 0.6000
[1m 91/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7070 - loss: 0.6015
[1m 98/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7039 - loss: 0.6032
[1m104/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7025 - loss: 0.6038
[1m110/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7010 - loss: 0.6046
[1m116/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7002 - loss: 0.6046
[1m122/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.6996 - loss: 0.6041
[1m129/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.6994 - loss: 0.6030
[1m132/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 10ms/step - binary_accuracy: 0.6995 - loss: 0.6020 - val_binary_accuracy: 0.8000 - val_loss: 0.4696
Epoch 5/10

[1m  1/132[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 31ms/step - binary_accuracy: 1.0000 - loss: 0.4604
[1m  8/132[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 9ms/step - binary_accuracy: 0.6591 - loss: 0.7690 
[1m 15/132[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 9ms/step - binary_accuracy: 0.6844 - loss: 0.6487
[1m 22/132[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7002 - loss: 0.5995
[1m 29/132[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7258 - loss: 0.5572
[1m 35/132[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7405 - loss: 0.5334
[1m 42/132[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7520 - loss: 0.5163
[1m 49/132[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7577 - loss: 0.5068
[1m 56/132[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7608 - loss: 0.5029
[1m 63/132[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7594 - loss: 0.5043
[1m 70/132[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7561 - loss: 0.5067
[1m 77/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7518 - loss: 0.5104
[1m 83/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7492 - loss: 0.5132
[1m 90/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7470 - loss: 0.5162
[1m 97/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7460 - loss: 0.5176
[1m103/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7450 - loss: 0.5188
[1m109/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7432 - loss: 0.5205
[1m116/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7406 - loss: 0.5227
[1m121/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7383 - loss: 0.5247
[1m128/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7355 - loss: 0.5269
[1m132/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 10ms/step - binary_accuracy: 0.7330 - loss: 0.5291 - val_binary_accuracy: 0.6000 - val_loss: 0.6498
Epoch 6/10

[1m  1/132[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 31ms/step - binary_accuracy: 1.0000 - loss: 0.4711
[1m  8/132[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 9ms/step - binary_accuracy: 0.7362 - loss: 0.6475 
[1m 14/132[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 9ms/step - binary_accuracy: 0.7183 - loss: 0.6221
[1m 20/132[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 9ms/step - binary_accuracy: 0.7336 - loss: 0.5965
[1m 26/132[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7427 - loss: 0.5791
[1m 33/132[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7498 - loss: 0.5624
[1m 40/132[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7531 - loss: 0.5505
[1m 46/132[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7522 - loss: 0.5441
[1m 51/132[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7521 - loss: 0.5391
[1m 58/132[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7497 - loss: 0.5337
[1m 65/132[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7474 - loss: 0.5300
[1m 72/132[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7480 - loss: 0.5255
[1m 79/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7500 - loss: 0.5207
[1m 86/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7498 - loss: 0.5190
[1m 93/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7482 - loss: 0.5191
[1m100/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7460 - loss: 0.5201
[1m107/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7439 - loss: 0.5214
[1m114/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7419 - loss: 0.5226
[1m121/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7400 - loss: 0.5237
[1m128/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7384 - loss: 0.5247
[1m132/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 9ms/step - binary_accuracy: 0.7376 - loss: 0.5253 - val_binary_accuracy: 0.8667 - val_loss: 0.5232
Epoch 7/10

[1m  1/132[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 31ms/step - binary_accuracy: 1.0000 - loss: 0.4498
[1m  5/132[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 13ms/step - binary_accuracy: 0.9100 - loss: 0.3540
[1m 12/132[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - binary_accuracy: 0.8113 - loss: 0.3932
[1m 18/132[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - binary_accuracy: 0.7954 - loss: 0.4094
[1m 25/132[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - binary_accuracy: 0.7945 - loss: 0.4127
[1m 32/132[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7876 - loss: 0.4202
[1m 37/132[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7885 - loss: 0.4222
[1m 43/132[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7888 - loss: 0.4252
[1m 50/132[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7844 - loss: 0.4322
[1m 57/132[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7806 - loss: 0.4375
[1m 64/132[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7760 - loss: 0.4437 
[1m 70/132[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7725 - loss: 0.4492
[1m 76/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7702 - loss: 0.4536
[1m 83/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7682 - loss: 0.4579
[1m 90/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7658 - loss: 0.4623
[1m 97/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7651 - loss: 0.4653
[1m102/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7646 - loss: 0.4669
[1m108/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7638 - loss: 0.4687
[1m114/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7635 - loss: 0.4698
[1m121/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7631 - loss: 0.4711
[1m128/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7624 - loss: 0.4726
[1m132/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 10ms/step - binary_accuracy: 0.7614 - loss: 0.4739 - val_binary_accuracy: 0.6000 - val_loss: 0.6514
Epoch 8/10

[1m  1/132[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 47ms/step - binary_accuracy: 1.0000 - loss: 0.6122
[1m  8/132[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 9ms/step - binary_accuracy: 0.7518 - loss: 0.5977 
[1m 15/132[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 9ms/step - binary_accuracy: 0.7876 - loss: 0.5144
[1m 22/132[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.8171 - loss: 0.4812
[1m 29/132[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.8164 - loss: 0.4769
[1m 36/132[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.8084 - loss: 0.4779
[1m 42/132[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.8027 - loss: 0.4785
[1m 49/132[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7941 - loss: 0.4815
[1m 56/132[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7871 - loss: 0.4846
[1m 62/132[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7847 - loss: 0.4846
[1m 69/132[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7823 - loss: 0.4851
[1m 76/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7818 - loss: 0.4848
[1m 82/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7812 - loss: 0.4851
[1m 89/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7798 - loss: 0.4854
[1m 96/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7764 - loss: 0.4873
[1m103/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7720 - loss: 0.4904
[1m110/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7681 - loss: 0.4934
[1m117/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7647 - loss: 0.4961
[1m124/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7614 - loss: 0.4988
[1m130/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7593 - loss: 0.5007
[1m132/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 10ms/step - binary_accuracy: 0.7583 - loss: 0.5016 - val_binary_accuracy: 0.6667 - val_loss: 0.6020
Epoch 9/10

[1m  1/132[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 31ms/step - binary_accuracy: 0.0000e+00 - loss: 0.7068
[1m  6/132[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 13ms/step - binary_accuracy: 0.5917 - loss: 0.4165    
[1m 13/132[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - binary_accuracy: 0.7554 - loss: 0.3403
[1m 20/132[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - binary_accuracy: 0.8201 - loss: 0.3154
[1m 27/132[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - binary_accuracy: 0.8352 - loss: 0.3267
[1m 34/132[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.8291 - loss: 0.3544
[1m 41/132[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.8312 - loss: 0.3675 
[1m 48/132[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.8286 - loss: 0.3796
[1m 55/132[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.8232 - loss: 0.3884
[1m 60/132[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.8195 - loss: 0.3948
[1m 67/132[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.8133 - loss: 0.4043
[1m 74/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.8069 - loss: 0.4130
[1m 80/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.8037 - loss: 0.4181
[1m 87/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.8000 - loss: 0.4229
[1m 93/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7970 - loss: 0.4265
[1m 99/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7949 - loss: 0.4293
[1m106/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7937 - loss: 0.4311
[1m113/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7929 - loss: 0.4324
[1m120/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7923 - loss: 0.4339
[1m126/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7914 - loss: 0.4360
[1m132/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 10ms/step - binary_accuracy: 0.7901 - loss: 0.4389 - val_binary_accuracy: 0.6000 - val_loss: 0.6243
Epoch 10/10

[1m  1/132[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 31ms/step - binary_accuracy: 1.0000 - loss: 0.5538
[1m  7/132[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 11ms/step - binary_accuracy: 1.0000 - loss: 0.4078
[1m 13/132[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - binary_accuracy: 0.9941 - loss: 0.3894
[1m 20/132[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - binary_accuracy: 0.9753 - loss: 0.3781
[1m 27/132[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - binary_accuracy: 0.9634 - loss: 0.3689
[1m 34/132[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.9522 - loss: 0.3652
[1m 40/132[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.9427 - loss: 0.3664
[1m 47/132[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.9324 - loss: 0.3702
[1m 55/132[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.9177 - loss: 0.3798 
[1m 62/132[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.9078 - loss: 0.3873
[1m 69/132[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.9002 - loss: 0.3924
[1m 76/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.8943 - loss: 0.3952
[1m 83/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.8865 - loss: 0.4002
[1m 89/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.8792 - loss: 0.4053
[1m 95/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.8723 - loss: 0.4100
[1m101/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.8666 - loss: 0.4137
[1m108/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.8611 - loss: 0.4171
[1m115/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.8562 - loss: 0.4200
[1m122/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.8524 - loss: 0.4220
[1m128/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.8493 - loss: 0.4239
[1m132/132[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 10ms/step - binary_accuracy: 0.8464 - loss: 0.4261 - val_binary_accuracy: 0.6000 - val_loss: 0.5443

[1m1/2[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 110ms/step
[1m2/2[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 94ms/step 
[1m2/2[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 94ms/step
predicted [0.8031677  0.8358485  0.87049997 0.76393616 0.9444749  0.9007436
 0.11530109 0.44521913 0.48968297 0.66290665 0.85765976 0.24350326
 0.92169356 0.10312957 0.73305535 0.03394367 0.78522336 0.79595983
 0.46089965 0.23715816 0.7252616  0.24952117 0.36496988 0.46417493
 0.67049885 0.24097154 0.50807273 0.7527243  0.75349784 0.41588688
 0.5028747  0.04923781 0.71277714 0.5761611  0.63623875 0.5864638
 0.47807738]
predicted [1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0 1 1 0 0 1 0 0 0 1 0 1 1 1 0 1 0 1 1 1 1 0]
expected [ True  True  True  True  True  True False  True False False  True False
  True False  True False  True  True False False  True  True  True  True
  True False False  True  True  True False False False False  True  True
  True]
accuracy: 0.7027027027027027
confusion matrix: 
[[ 9  5]
 [ 6 17]]
              precision    recall  f1-score   support

       False       0.60      0.64      0.62        14
        True       0.77      0.74      0.76        23

    accuracy                           0.70        37
   macro avg       0.69      0.69      0.69        37
weighted avg       0.71      0.70      0.70        37

macro avg f1-score: 0.6881226053639846
macro avg (UAR): 0.6909937888198758
Sensitivity:  0.6428571428571429
Specificity:  0.7391304347826086
g-mean:  0.6893150799910776
-------- Model Performance ----------: 
accuracy:  [0.62162162 0.72972973 0.67567568 0.7027027  0.72972973 0.72972973
 0.67567568 0.67567568 0.64864865 0.7027027 ]
gmean:  [0.56282341 0.70929937 0.59501031 0.5227733  0.73931309 0.72660189
 0.59501031 0.64989249 0.54316761 0.68931508]
f1_score:  [0.5849359  0.71273292 0.63       0.61052632 0.72470238 0.71969697
 0.63       0.6552795  0.58994032 0.68812261]
UAR:  [0.58385093 0.71273292 0.62732919 0.62111801 0.74068323 0.72670807
 0.62732919 0.6552795  0.59161491 0.69099379]
Cohen Kappa score:  [0.17252396 0.42546584 0.26973684 0.27708703 0.45588235 0.44108761
 0.26973684 0.31055901 0.19699499 0.37672282]
arousal and valece = ok
------------- Evaluating model --------------
-------------------------------------
-------------------------------------
participant:  30
-------------------------------------
----- RESULTS ------
-------------------------------------
Window size (sec):  12.992
step (sec):  6.496
overlap:  True
perc. of overlap:  50.0
overlap duration (sec):  6.496
Number of windows / instances:  184
-rows: alg : KNN = 0; DT = 1; RF = 2; SVM = 3; GBM = 4; BDDAE = 5; DUMMY = 5
columns:
'val_cohen','val_uar', 'val_acc', 'val_gm',  'val_f1',  'aro_cohen','aro_uar', 'aro_acc', 'aro_gm',  'aro_f1'
-------------------------------------------------------------
  v_c   v_u   v_a   v_g   v_f1  a_c   a_u   a_a   a_g   a_f1
[[0.809 0.908 0.908 0.906 0.904 0.577 0.799 0.808 0.785 0.785]
 [0.666 0.825 0.847 0.82  0.833 0.619 0.751 0.783 0.771 0.752]
 [0.743 0.85  0.864 0.88  0.85  0.598 0.771 0.798 0.773 0.763]
 [0.784 0.893 0.897 0.891 0.892 0.235 0.603 0.706 0.434 0.58 ]
 [0.644 0.812 0.831 0.802 0.815 0.349 0.657 0.74  0.575 0.654]
 [0.32  0.658 0.689 0.633 0.655 0.245 0.612 0.689 0.541 0.608]
 [0.    0.5   0.609 0.    0.378 0.    0.5   0.653 0.    0.395]]
last participant performance loaded in numpy array
    
    
-------------------------------
LAST participant's saved data: 
30
-------------------------------
    
    
Saving performance metrics in csv files...
Performance metrics already saved in csv files
---------------------------
KNN performance:
[[0.57867065 0.78993687 0.79239766 0.7862124  0.78851983 0.40104745
  0.70453297 0.79444444 0.62508493 0.69091275]
 [0.47085187 0.7390404  0.73421053 0.73248758 0.73164019 0.47150969
  0.7316829  0.75467836 0.71656687 0.73247747]
 [0.60766411 0.79576299 0.81461988 0.77938892 0.79961588 0.51906037
  0.75930556 0.75994152 0.75160578 0.75662523]
 [0.45201887 0.72402778 0.72923977 0.71387905 0.72259898 0.18989742
  0.59342491 0.6997076  0.47347981 0.58401795]
 [0.52862545 0.75606061 0.79385965 0.69557726 0.75135368 0.54250927
  0.77055556 0.77222222 0.76398869 0.76921973]
 [0.44221455 0.72055556 0.72251462 0.71274236 0.71854041 0.63653204
  0.81708333 0.82017544 0.80913691 0.81576084]
 [0.36653103 0.6775974  0.70116959 0.65480745 0.67606987 0.46625342
  0.73333333 0.73304094 0.72564161 0.72971571]
 [0.83498492 0.91314103 0.92923977 0.90888417 0.91701128 0.64516614
  0.82394481 0.83187135 0.81540669 0.82041186]
 [0.37845354 0.68570513 0.7619883  0.59799499 0.67501757 0.13348938
  0.55858974 0.65380117 0.49396956 0.55945424]
 [0.40032514 0.70138889 0.7005848  0.68461188 0.6925371  0.42020368
  0.71069444 0.71140351 0.69978569 0.7054893 ]
 [0.3188641  0.65435606 0.69181287 0.61969618 0.65304574 0.4472937
  0.71904762 0.73274854 0.70246028 0.71614246]
 [0.6340761  0.81461039 0.83187135 0.802859   0.81475324 0.61557586
  0.79853896 0.82602339 0.78493505 0.80554292]
 [0.48319766 0.73785714 0.75526316 0.72214436 0.73746099 0.15758176
  0.57853896 0.59064327 0.55244944 0.56853893]
 [0.27495727 0.63582251 0.67719298 0.60593547 0.63430108 0.36441173
  0.68069444 0.68596491 0.66605944 0.67667566]
 [0.35644435 0.67333333 0.74093567 0.62911486 0.67134211 0.38503129
  0.69339827 0.7128655  0.67953275 0.6883051 ]
 [0.47325578 0.73279221 0.75584795 0.71304441 0.73220583 0.47935722
  0.73452381 0.77134503 0.70791187 0.73322408]
 [0.49081585 0.74462662 0.75438596 0.74077337 0.74450912 0.43176237
  0.70741883 0.73859649 0.67461172 0.70711336]
 [0.08203114 0.533125   0.8374269  0.18049419 0.52456    0.51295554
  0.75211039 0.76666667 0.7371882  0.75103484]
 [0.51291295 0.74948718 0.79385965 0.72960032 0.75223829 0.47518818
  0.7375     0.73918129 0.72740906 0.73354651]
 [0.32655651 0.65819597 0.72748538 0.59183104 0.64932215 0.27896464
  0.63744589 0.67923977 0.60533108 0.63381363]
 [0.19963618 0.6025     0.73421053 0.47508539 0.59001426 0.03087788
  0.51555556 0.51637427 0.48930797 0.50427554]
 [0.3472788  0.67388889 0.6748538  0.65528009 0.66542598 0.41827586
  0.70681818 0.74356725 0.67326901 0.70081631]
 [0.34554571 0.6711039  0.68508772 0.65638687 0.66935364 0.35241541
  0.66909341 0.78274854 0.54581073 0.66049062]
 [0.2451915  0.62138889 0.62573099 0.60208044 0.61414106 0.55515278
  0.77332071 0.78362573 0.76470004 0.7753658 ]
 [0.45903058 0.72753788 0.73421053 0.7098381  0.72270867 0.7296996
  0.86555556 0.86461988 0.8621083  0.86388182]
 [0.38527198 0.69111111 0.69824561 0.67931214 0.68942139 0.40427276
  0.70191919 0.70672515 0.68229461 0.69431001]
 [0.51394453 0.75615385 0.79298246 0.7364206  0.75155922 0.66516913
  0.83277778 0.83274854 0.8289012  0.83143828]
 [0.20990144 0.60254329 0.63625731 0.57399098 0.5985299  0.41124005
  0.70497835 0.71842105 0.69366787 0.7026443 ]
 [0.20789979 0.59886364 0.64678363 0.54421986 0.59270473 0.38318363
  0.69125    0.69649123 0.67573071 0.68560149]
 [0.80898338 0.90760281 0.90789474 0.90591668 0.90419039 0.57725102
  0.79940476 0.80818713 0.7854716  0.78502102]]
KNN mean:
[0.42453786 0.70967058 0.74607212 0.67135368 0.70615642 0.43671098
 0.71676794 0.74093567 0.69046058 0.71272893]
---------------------------
---------------------------
DT performance:
[[0.55464192 0.77698232 0.78099415 0.79403751 0.77541607 0.34037259
  0.6706044  0.75701754 0.63173448 0.66602893]
 [0.5565339  0.80598485 0.80409357 0.78862382 0.80165104 0.54361383
  0.76847944 0.78157895 0.74018689 0.76842892]
 [0.45783003 0.71805195 0.72602339 0.71236008 0.71732185 0.48738711
  0.75805556 0.76111111 0.75201813 0.75722181]
 [0.39152471 0.65527778 0.65292398 0.68469337 0.64785061 0.36261474
  0.6453663  0.72836257 0.54894177 0.64103018]
 [0.4730721  0.76390693 0.77280702 0.74845366 0.75866366 0.51264525
  0.76777778 0.76695906 0.76098728 0.76512095]
 [0.37877575 0.73236111 0.73333333 0.6863989  0.73183234 0.60658605
  0.81222222 0.81520468 0.78484567 0.81207438]
 [0.36556309 0.68628247 0.70204678 0.65294611 0.68403289 0.30275152
  0.68333333 0.68362573 0.66105246 0.68058585]
 [0.80170002 0.90512821 0.91842105 0.89840822 0.90642569 0.62155091
  0.80871212 0.82134503 0.78766374 0.80721762]
 [0.38552325 0.67980769 0.74035088 0.63547283 0.66973757 0.25080069
  0.63333333 0.66988304 0.59400274 0.62279641]
 [0.2211254  0.61291667 0.61345029 0.58555416 0.60410526 0.39682729
  0.6925     0.69005848 0.67193468 0.68413429]
 [0.11479621 0.57675866 0.59824561 0.54628045 0.57152058 0.49202878
  0.76041667 0.76637427 0.72242925 0.75576325]
 [0.64671382 0.77278139 0.79356725 0.79835061 0.77184727 0.45944788
  0.74848485 0.76081871 0.70754725 0.74327939]
 [0.37798464 0.66595779 0.68421053 0.69380742 0.66076132 0.12592867
  0.5900974  0.59883041 0.56843445 0.58040642]
 [0.19481349 0.60633117 0.63508772 0.55261143 0.60083883 0.23348317
  0.62458333 0.62982456 0.59227489 0.61546761]
 [0.17529366 0.61557692 0.66871345 0.56738073 0.60453768 0.32746134
  0.68322511 0.69736842 0.65357401 0.66605852]
 [0.37557076 0.6762987  0.68479532 0.65626254 0.66882357 0.49543194
  0.775      0.78859649 0.758279   0.76955522]
 [0.70580772 0.85839286 0.86432749 0.86399562 0.85743902 0.58884386
  0.78336039 0.79298246 0.79979978 0.78395646]
 [0.26843226 0.66666667 0.8374269  0.52021923 0.66070748 0.61558083
  0.79387987 0.79824561 0.78379035 0.79134134]
 [0.43076824 0.72179487 0.76081871 0.72557782 0.72353182 0.51790505
  0.74625    0.74883041 0.73461738 0.74025118]
 [0.52925734 0.7334707  0.76111111 0.72079736 0.7252131  0.22142381
  0.5991342  0.63625731 0.59839039 0.59490333]
 [0.16706213 0.58119048 0.68391813 0.50342423 0.56258243 0.19077588
  0.60222222 0.60409357 0.61371966 0.60026751]
 [0.36760871 0.67722222 0.68040936 0.65413018 0.67099009 0.43658825
  0.71650433 0.73947368 0.71482025 0.71398212]
 [0.24962784 0.63212662 0.64269006 0.5625143  0.61929714 0.26484044
  0.61700549 0.72192982 0.59164314 0.61194804]
 [0.35757359 0.68986111 0.68976608 0.69098029 0.68187343 0.5267624
  0.77472222 0.77368421 0.76133524 0.7679128 ]
 [0.51124064 0.77762626 0.78245614 0.74713418 0.7748749  0.56235776
  0.76444444 0.76578947 0.75721466 0.759226  ]
 [0.3211341  0.65986111 0.65701754 0.65695441 0.65243219 0.4548359
  0.72213384 0.72280702 0.71917158 0.71648659]
 [0.59628053 0.79935897 0.8254386  0.79681929 0.78770582 0.58554778
  0.79277778 0.79356725 0.79692051 0.791252  ]
 [0.17659462 0.56369048 0.60760234 0.5533067  0.56020597 0.49092493
  0.77602814 0.79005848 0.77082438 0.77847453]
 [0.28043274 0.66780303 0.68421053 0.63801356 0.66385138 0.22812138
  0.63125    0.63187135 0.63065781 0.62800442]
 [0.66620172 0.82472944 0.84736842 0.8202629  0.83260311 0.61927477
  0.75119048 0.78304094 0.77095804 0.75206303]]
DT mean:
[0.40331616 0.70347331 0.72778752 0.68185906 0.69828914 0.42875716
 0.71643651 0.73398635 0.69932566 0.71217464]
---------------------------
---------------------------
RF performance:
[[0.67541176 0.83628788 0.84181287 0.83186908 0.83845416 0.42433372
  0.6639011  0.78304094 0.66042803 0.66842008]
 [0.59238495 0.80108586 0.80409357 0.80238484 0.80079588 0.61460861
  0.77205087 0.77660819 0.81012988 0.76385116]
 [0.52366616 0.7337013  0.74502924 0.75462623 0.73354703 0.4465516
  0.70972222 0.71140351 0.73026684 0.70788755]
 [0.50067469 0.72291667 0.72339181 0.7025664  0.72040102 0.25084946
  0.65587912 0.73859649 0.57023911 0.65640837]
 [0.62188331 0.7655303  0.78187135 0.78675666 0.76618169 0.5450218
  0.75166667 0.75116959 0.78756368 0.74837592]
 [0.47377085 0.72611111 0.72719298 0.70089974 0.7220712  0.59196785
  0.83013889 0.83157895 0.79979846 0.82820177]
 [0.41791125 0.70251623 0.71812865 0.6859343  0.69644301 0.39039303
  0.72777778 0.72807018 0.72231391 0.72579433]
 [0.90075795 0.91346154 0.92368421 0.90053923 0.91155299 0.6299649
  0.79626623 0.80467836 0.78440348 0.79351179]
 [0.44718965 0.67846154 0.74035088 0.62541135 0.67325895 0.33297227
  0.62358974 0.68040936 0.5841668  0.60634512]
 [0.33584063 0.69819444 0.69561404 0.67897247 0.69242844 0.41172469
  0.68305556 0.68625731 0.68764526 0.6767162 ]
 [0.2092371  0.65757576 0.6748538  0.572264   0.65216466 0.49902724
  0.78925866 0.80292398 0.75513515 0.78866552]
 [0.71438991 0.83566017 0.84707602 0.81066812 0.82973822 0.55789369
  0.75124459 0.77076023 0.7519807  0.75319776]
 [0.54948643 0.74936688 0.77134503 0.69089771 0.74979015 0.1765633
  0.63253247 0.64122807 0.61704412 0.62612474]
 [0.24347396 0.61401515 0.66695906 0.60572962 0.61415876 0.3522178
  0.66083333 0.6622807  0.69773416 0.65699389]
 [0.32949678 0.63621795 0.68654971 0.54202406 0.62729928 0.22608714
  0.66580087 0.69649123 0.58031509 0.65711556]
 [0.41008608 0.70722403 0.72280702 0.6888372  0.70633611 0.46004726
  0.77619048 0.81052632 0.77718063 0.78429835]
 [0.70784711 0.86017857 0.86345029 0.88176828 0.85677737 0.7093023
  0.81128247 0.82046784 0.78666739 0.81177755]
 [0.22499085 0.63520833 0.85380117 0.20554495 0.63646859 0.5106356
  0.79551948 0.81520468 0.78935244 0.80047977]
 [0.54554852 0.73519231 0.78216374 0.78261072 0.73567044 0.6020121
  0.77       0.77748538 0.8068089  0.7680791 ]
 [0.39345894 0.71680403 0.76023392 0.68562322 0.71116331 0.28857362
  0.63544372 0.67368421 0.65809888 0.62734343]
 [0.04419045 0.5875     0.71754386 0.51304604 0.58834037 0.09990631
  0.60722222 0.60818713 0.49858738 0.60130399]
 [0.41278932 0.67944444 0.68040936 0.71156125 0.67524048 0.35295054
  0.68057359 0.73391813 0.707847   0.67871585]
 [0.34848406 0.62654221 0.64035088 0.60669137 0.62283498 0.46508856
  0.68736264 0.77719298 0.65037602 0.69175363]
 [0.42978103 0.69430556 0.69415205 0.65102653 0.68756568 0.51215467
  0.80401515 0.80526316 0.77303433 0.80106349]
 [0.48555927 0.7519697  0.76023392 0.77264578 0.74481455 0.6531636
  0.77944444 0.77865497 0.78610894 0.7764572 ]
 [0.38294154 0.70222222 0.70964912 0.69488287 0.70101957 0.52351572
  0.73066919 0.74502924 0.70707672 0.72879342]
 [0.57541543 0.74153846 0.79181287 0.81786753 0.74147089 0.60885237
  0.805      0.80380117 0.75716747 0.80037315]
 [0.14694713 0.60584416 0.64064327 0.57794157 0.599854   0.65464421
  0.74862013 0.7619883  0.74498504 0.749472  ]
 [0.44329364 0.69264069 0.72836257 0.67076735 0.69215508 0.39508075
  0.68430556 0.68625731 0.68216775 0.6799885 ]
 [0.74278056 0.84994589 0.86374269 0.8797992  0.84993768 0.59818823
  0.77142857 0.79824561 0.77281255 0.76267805]]
RF mean:
[0.46098964 0.72192211 0.75191033 0.69440526 0.71926448 0.46280977
 0.72669319 0.74871345 0.7145812  0.72400624]
---------------------------
---------------------------
SVM performance:
[[ 0.2408039   0.61375     0.64649123  0.50099005  0.57581879  0.
   0.5         0.7502924   0.          0.42856794]
 [ 0.42494133  0.70751263  0.72280702  0.68515515  0.70561045  0.34485902
   0.66160714  0.70614035  0.61872347  0.66153207]
 [ 0.51918582  0.74285714  0.78187135  0.69210747  0.74377145  0.41957312
   0.70958333  0.71111111  0.70385353  0.70785096]
 [ 0.36261087  0.67847222  0.69005848  0.63735025  0.66533845  0.
   0.5         0.72280702  0.          0.41951063]
 [ 0.55421653  0.7629329   0.80555556  0.72692259  0.76763827  0.49775391
   0.74777778  0.7505848   0.73376373  0.74431829]
 [ 0.31666344  0.6575      0.66520468  0.62195859  0.6446518   0.57352987
   0.78652778  0.78859649  0.77856856  0.78410343]
 [ 0.06773634  0.53027597  0.62017544  0.13557056  0.42982473  0.33751728
   0.66833333  0.66842105  0.64853165  0.65884055]
 [ 0.7371343   0.85512821  0.89122807  0.84209661  0.86666639  0.50023366
   0.73536255  0.77748538  0.70771804  0.74420789]
 [ 0.          0.5         0.69035088  0.          0.40830645  0.
   0.5         0.69035088  0.          0.40830645]
 [ 0.36688487  0.68444444  0.68333333  0.67679989  0.67967152  0.19671618
   0.59416667  0.61900585  0.5142164   0.56848753]
 [-0.01032258  0.49545455  0.60350877  0.          0.37615499  0.21534682
   0.59448052  0.67397661  0.41587597  0.55089993]
 [ 0.41481732  0.68971861  0.75497076  0.61232658  0.68496687  0.0677543
   0.5280303   0.63011696  0.23357779  0.45905665]
 [ 0.17490316  0.58022727  0.63596491  0.39840032  0.53266861  0.
   0.5         0.5871345   0.          0.36981938]
 [ 0.          0.5         0.64152047  0.          0.39070078  0.37743315
   0.68791667  0.69093567  0.66488715  0.67832665]
 [ 0.          0.5         0.69035088  0.          0.40830645  0.
   0.5         0.64152047  0.          0.39070078]
 [ 0.          0.5         0.60350877  0.          0.37629588  0.01777269
   0.50714286  0.65263158  0.07862128  0.42018208]
 [ 0.01692308  0.50714286  0.59824561  0.03779645  0.3858908   0.
   0.5         0.59269006  0.          0.37203612]
 [ 0.          0.5         0.86461988  0.          0.46360581  0.09600247
   0.54261364  0.62046784  0.22268639  0.4586653 ]
 [ 0.          0.5         0.68479532  0.          0.40637097  0.04453433
   0.52097222  0.56023392  0.16812752  0.41307907]
 [ 0.          0.5         0.66842105  0.          0.40058468  0.0792831
   0.5327381   0.65789474  0.19040151  0.45612899]
 [ 0.          0.5         0.76666667  0.          0.43389037  0.14014337
   0.57        0.56169591  0.44251953  0.5196638 ]
 [ 0.35003685  0.67666667  0.6745614   0.64523638  0.66171962  0.
   0.5         0.64152047  0.          0.39070078]
 [ 0.          0.5         0.57046784  0.          0.36316913  0.
   0.5         0.73918129  0.          0.42493891]
 [ 0.          0.5         0.53274854  0.          0.34745484  0.43249004
   0.70517677  0.73421053  0.66112582  0.70216627]
 [ 0.03865493  0.51805556  0.57602339  0.08333333  0.39274725  0.46945295
   0.735       0.73508772  0.71658048  0.72787676]
 [ 0.03695444  0.51736111  0.55438596  0.13344897  0.39249029  0.37735005
   0.68491162  0.70263158  0.65340681  0.67810185]
 [ 0.35249052  0.64448718  0.77777778  0.53372371  0.65126834  0.62864973
   0.81388889  0.81461988  0.80705821  0.811725  ]
 [ 0.          0.5         0.64152047  0.          0.39070078  0.3427629
   0.65503247  0.71812865  0.56290945  0.64220023]
 [ 0.          0.5         0.61929825  0.          0.38242492  0.32187654
   0.65555556  0.6754386   0.57325228  0.63492926]
 [ 0.783869    0.89280303  0.89678363  0.89067252  0.89155918  0.23474764
   0.60297619  0.70614035  0.43393791  0.5803151 ]]
SVM mean:
[0.1916168  0.59182634 0.68510721 0.29512965 0.5273423  0.22385944
 0.60799315 0.68403509 0.38434478 0.56024129]
---------------------------
---------------------------
GBM performance:
[[ 0.62901782  0.80708333  0.82426901  0.7795627   0.80546776  0.29038783
   0.62        0.81111111  0.36812031  0.60775358]
 [ 0.44604043  0.72376263  0.73888889  0.70832071  0.72239905  0.48223764
   0.72800325  0.77251462  0.67884379  0.72719599]
 [ 0.46977638  0.71662338  0.75380117  0.66224021  0.71134097  0.39887979
   0.70458333  0.70526316  0.68462703  0.70103865]
 [ 0.51171817  0.75527778  0.75643275  0.74583412  0.75221732  0.00572512
   0.50258242  0.71725146  0.04309458  0.4313721 ]
 [ 0.57653018  0.7702381   0.82134503  0.69787738  0.77211178  0.45463083
   0.72722222  0.72865497  0.70840953  0.7202697 ]
 [ 0.46481983  0.72722222  0.72748538  0.72611822  0.72193879  0.57784185
   0.78        0.78918129  0.75874117  0.77679102]
 [ 0.37951247  0.67767857  0.72222222  0.62477897  0.67434991  0.43561255
   0.72888889  0.72777778  0.71951219  0.72431417]
 [ 0.83209505  0.90480769  0.92953216  0.89949497  0.91559389  0.60013076
   0.79199134  0.82134503  0.76580824  0.79278534]
 [ 0.21383348  0.58025641  0.71812865  0.42605552  0.56301101  0.08789088
   0.53512821  0.69590643  0.22528277  0.48960304]
 [ 0.18895435  0.59902778  0.60321637  0.55044959  0.58393576  0.34029123
   0.66111111  0.67426901  0.63630493  0.65820589]
 [ 0.23005185  0.604329    0.66871345  0.44742827  0.57400713  0.53077098
   0.75543831  0.78830409  0.72469899  0.75674679]
 [ 0.62215488  0.80205628  0.83654971  0.79214014  0.81278941  0.50140382
   0.74864719  0.77076023  0.7353606   0.74869522]
 [ 0.41759349  0.70550325  0.73918129  0.66372375  0.70293373  0.07095792
   0.53568182  0.58128655  0.43099879  0.51146069]
 [ 0.1625114   0.57959957  0.68421053  0.35417269  0.54626696  0.3128821
   0.64930556  0.65818713  0.61362078  0.63550959]
 [-0.04027838  0.48429487  0.66345029  0.0372678   0.40863967  0.0543559
   0.52164502  0.63157895  0.26147586  0.47034403]
 [ 0.03368102  0.51601732  0.59736842  0.24860395  0.45277358  0.33775965
   0.64702381  0.73391813  0.5547604   0.63976569]
 [ 0.71199423  0.85149351  0.86403509  0.84402565  0.85459025  0.38622718
   0.68644481  0.72163743  0.65254751  0.68951055]
 [ 0.10171429  0.53854167  0.86988304  0.12844571  0.52310542  0.57440725
   0.78144481  0.79883041  0.76565235  0.78346052]
 [ 0.3244033   0.65461538  0.77192982  0.51237402  0.64347589  0.48993999
   0.7475      0.75994152  0.71231788  0.74331806]
 [ 0.28992257  0.63754579  0.7380117   0.45936484  0.61622937  0.29574135
   0.62564935  0.7125731   0.51522463  0.60902361]
 [ 0.03414634  0.5125      0.77222222  0.05        0.45530166  0.20993955
   0.61055556  0.60964912  0.60604365  0.60781377]
 [ 0.26116761  0.62555556  0.62660819  0.62018597  0.62142262  0.35111969
   0.65974026  0.73421053  0.56393048  0.65584902]
 [ 0.30770388  0.64780844  0.68508772  0.56634735  0.62981962  0.14391873
   0.56071429  0.75526316  0.25778734  0.52418242]
 [ 0.39189686  0.68388889  0.68976608  0.66438592  0.67995315  0.51585585
   0.76016414  0.76812865  0.74891981  0.76036796]
 [ 0.44747298  0.71515152  0.73859649  0.67810013  0.71091488  0.57761292
   0.79444444  0.79444444  0.78889812  0.79250475]
 [ 0.38313998  0.68708333  0.70526316  0.62117889  0.66932646  0.49731179
   0.74396465  0.75584795  0.73143337  0.74506975]
 [ 0.41352673  0.70192308  0.79356725  0.65249775  0.71032353  0.58559522
   0.78722222  0.78830409  0.78079292  0.78544874]
 [ 0.12689237  0.55714286  0.65730994  0.31708807  0.52266116  0.50809726
   0.73998918  0.77923977  0.70290822  0.74526589]
 [ 0.32803534  0.6482684   0.71842105  0.56640509  0.64202443  0.38137072
   0.69888889  0.70847953  0.68685057  0.69671371]
 [ 0.64448784  0.81228355  0.83099415  0.80203968  0.81498106  0.34921271
   0.65714286  0.74035088  0.57465575  0.65444116]]
GBM mean:
[0.36348389 0.67425267 0.74154971 0.56155027 0.66046354 0.3782703
 0.68303726 0.73447368 0.59992075 0.67282738]
---------------------------
---------------------------
BDDAE performance:
[[ 0.03573414  0.51794118  0.52702703  0.46257764  0.50260053  0.11095837
   0.54761905  0.74324324  0.3335395   0.531333  ]
 [ 0.21246327  0.60720588  0.60540541  0.60568288  0.60460797  0.3984697
   0.69177019  0.72972973  0.6663654   0.69459451]
 [ 0.22489751  0.61056548  0.62972973  0.58047961  0.60340026  0.12476855
   0.5619883   0.56486486  0.54300028  0.55413648]
 [ 0.11525058  0.55764706  0.55945946  0.54660077  0.55252171  0.0882476
   0.53944444  0.7         0.35231179  0.52295016]
 [ 0.42826138  0.70822981  0.74324324  0.68017122  0.70780493  0.33731822
   0.66929825  0.66756757  0.65942629  0.66379093]
 [ 0.5876894   0.79298246  0.79459459  0.78576153  0.79145028 -0.09374756
   0.45323529  0.45945946  0.42617743  0.44263557]
 [-0.08912847  0.45772727  0.5027027   0.33833168  0.4289015  -0.06239618
   0.46871345  0.46756757  0.45789672  0.46272176]
 [ 0.36276866  0.662       0.75405405  0.59716351  0.66866312  0.11278837
   0.55947205  0.57567568  0.53443619  0.5482662 ]
 [ 0.47387363  0.7034965   0.80810811  0.65172711  0.72839712  0.54557951
   0.74108392  0.83513514  0.69384264  0.76441549]
 [ 0.00917164  0.50453216  0.50540541  0.49591466  0.50064341  0.26286561
   0.63073529  0.63513514  0.62475098  0.62945958]
 [ 0.05591609  0.52406832  0.58378378  0.45172129  0.51159414  0.2658107
   0.62863636  0.65675676  0.58536477  0.61811756]
 [ 0.18113866  0.58509317  0.64054054  0.53004224  0.57987002  0.39394156
   0.70232919  0.70810811  0.69915469  0.69540482]
 [-0.12087456  0.43787879  0.45135135  0.42718481  0.43594318  0.22535782
   0.61409091  0.62432432  0.60206131  0.60872224]
 [ 0.18019773  0.58205128  0.65675676  0.51575812  0.57857836  0.36141803
   0.68055556  0.68108108  0.67689174  0.67914665]
 [ 0.03608596  0.51311189  0.62162162  0.42555611  0.51004381  0.07918127
   0.54214744  0.6027027   0.46447966  0.52661457]
 [-0.06894003  0.46742424  0.52432432  0.34582912  0.43529509  0.36895348
   0.66378205  0.75135135  0.57573155  0.66120538]
 [ 0.53737161  0.77909091  0.76756757  0.76745195  0.76240571  0.20824914
   0.59454545  0.65405405  0.49492892  0.57305118]
 [ 0.33743712  0.655625    0.85675676  0.58415434  0.66712176  0.10966833
   0.55378788  0.58918919  0.50851022  0.54580757]
 [ 0.14539936  0.56433333  0.65135135  0.50194033  0.5642451   0.30746533
   0.65338235  0.65675676  0.6417902   0.64918591]
 [ 0.20745011  0.59716667  0.68108108  0.53179135  0.59519039  0.00765884
   0.5036859   0.60540541  0.33898174  0.47430362]
 [-0.00926377  0.49583333  0.71621622  0.15144486  0.4602112   0.20026358
   0.6002924   0.6         0.59251801  0.59632699]
 [ 0.04266897  0.52134503  0.52162162  0.51782658  0.51973058 -0.01144716
   0.49391026  0.5972973   0.28864006  0.4529242 ]
 [-0.01763748  0.49122024  0.5027027   0.47468683  0.4870714   0.47256321
   0.71037037  0.81621622  0.66743086  0.73143002]
 [ 0.05117809  0.52514706  0.53243243  0.50894309  0.52002288  0.1640574
   0.58035714  0.59459459  0.56767128  0.57933498]
 [-0.08265474  0.46026786  0.48108108  0.41937386  0.44955498  0.08726199
   0.54371345  0.54324324  0.53729588  0.5402052 ]
 [ 0.22165959  0.60852941  0.62162162  0.56841887  0.59522841  0.27061926
   0.63452381  0.64594595  0.61840921  0.63046909]
 [ 0.42967604  0.70874126  0.76756757  0.68736753  0.71262327  0.62970692
   0.81315789  0.81621622  0.80179835  0.81109628]
 [ 0.04584343  0.52019231  0.58108108  0.46960728  0.51560488  0.5141774
   0.75272727  0.77027027  0.74141867  0.75459719]
 [ 0.04313572  0.52173913  0.57567568  0.4341777   0.50707731  0.42690237
   0.70941176  0.72162162  0.68632986  0.7056359 ]
 [ 0.31957973  0.65776398  0.68918919  0.63332069  0.65459369  0.24479777
   0.61233974  0.68918919  0.54125941  0.6084465 ]]
BDDAE mean:
[0.16321165 0.57796503 0.62846847 0.52303358 0.5716999  0.23838198
 0.61503691 0.65675676 0.56408045 0.60854432]
---------------------------
---------------------------
DUMMY performance:
[[0.         0.5        0.54912281 0.         0.35440066 0.
  0.5        0.7502924  0.         0.42856794]
 [0.         0.5        0.54912281 0.         0.35440066 0.
  0.5        0.60877193 0.         0.3783389 ]
 [0.         0.5        0.57602339 0.         0.36538588 0.
  0.5        0.51608187 0.         0.34031199]
 [0.         0.5        0.52719298 0.         0.34507389 0.
  0.5        0.72280702 0.         0.41951063]
 [0.         0.5        0.61929825 0.         0.38242492 0.
  0.5        0.51052632 0.         0.33793103]
 [0.         0.5        0.51608187 0.         0.34031199 0.
  0.5        0.53274854 0.         0.34745484]
 [0.         0.5        0.59824561 0.         0.37425287 0.
  0.5        0.51052632 0.         0.33793103]
 [0.         0.5        0.67368421 0.         0.4025     0.
  0.5        0.61403509 0.         0.38038191]
 [0.         0.5        0.69035088 0.         0.40830645 0.
  0.5        0.69035088 0.         0.40830645]
 [0.         0.5        0.52163743 0.         0.34269294 0.
  0.5        0.54385965 0.         0.35221675]
 [0.         0.5        0.60877193 0.         0.3783389  0.
  0.5        0.60350877 0.         0.37629588]
 [0.         0.5        0.61929825 0.         0.38242492 0.
  0.5        0.61929825 0.         0.38242492]
 [0.         0.5        0.58157895 0.         0.36760263 0.
  0.5        0.5871345  0.         0.36981938]
 [0.         0.5        0.64152047 0.         0.39070078 0.
  0.5        0.52163743 0.         0.34269294]
 [0.         0.5        0.69035088 0.         0.40830645 0.
  0.5        0.64152047 0.         0.39070078]
 [0.         0.5        0.60350877 0.         0.37629588 0.
  0.5        0.65263158 0.         0.39483871]
 [0.         0.5        0.59269006 0.         0.37203612 0.
  0.5        0.59269006 0.         0.37203612]
 [0.         0.5        0.86461988 0.         0.46360581 0.
  0.5        0.59269006 0.         0.37203612]
 [0.         0.5        0.68479532 0.         0.40637097 0.
  0.5        0.54385965 0.         0.35221675]
 [0.         0.5        0.66842105 0.         0.40058468 0.
  0.5        0.63596491 0.         0.38863181]
 [0.         0.5        0.76666667 0.         0.43389037 0.
  0.5        0.48947368 0.         0.32857143]
 [0.         0.5        0.50526316 0.         0.33559113 0.
  0.5        0.64152047 0.         0.39070078]
 [0.         0.5        0.57046784 0.         0.36316913 0.
  0.5        0.73918129 0.         0.42493891]
 [0.         0.5        0.53274854 0.         0.34745484 0.
  0.5        0.55964912 0.         0.35876847]
 [0.         0.5        0.55964912 0.         0.35876847 0.
  0.5        0.50526316 0.         0.33559113]
 [0.         0.5        0.53830409 0.         0.3498358  0.
  0.5        0.55438596 0.         0.35658456]
 [0.         0.5        0.69035088 0.         0.40830645 0.
  0.5        0.50526316 0.         0.33559113]
 [0.         0.5        0.64152047 0.         0.39070078 0.
  0.5        0.60350877 0.         0.37629588]
 [0.         0.5        0.61929825 0.         0.38242492 0.
  0.5        0.54385965 0.         0.35221675]
 [0.         0.5        0.60877193 0.         0.3783389  0.
  0.5        0.65263158 0.         0.39483871]]
DUMMY mean:
[0.         0.5        0.61364522 0.         0.37881661 0.
 0.5        0.59285575 0.         0.37089142]
---------------------------
Current folder: C:\Users\Javier\Dropbox\c_sldl_1_2_37
-------------------------------------
----- RESULTS from .csv files ------
-------------------------------------
---------------------------
ALG Means: 
-rows: alg : KNN = 0; DT = 1; RF = 2; SVM = 3; GBM = 4; BDDAE = 5; DUMMY = 5
columns:
'val_cohen','val_uar', 'val_acc', 'val_gm',  'val_f1',  'aro_cohen','aro_uar', 'aro_acc', 'aro_gm',  'aro_f1'
-------------------------------------------------------------
  v_c   v_u   v_a   v_g   v_f1  a_c   a_u   a_a   a_g   a_f1
[[0.425 0.71  0.746 0.671 0.706 0.437 0.717 0.741 0.69  0.713]
 [0.403 0.703 0.728 0.682 0.698 0.429 0.716 0.734 0.699 0.712]
 [0.461 0.722 0.752 0.694 0.719 0.463 0.727 0.749 0.715 0.724]
 [0.192 0.592 0.685 0.295 0.527 0.224 0.608 0.684 0.384 0.56 ]
 [0.363 0.674 0.742 0.562 0.66  0.378 0.683 0.734 0.6   0.673]
 [0.163 0.578 0.628 0.523 0.572 0.238 0.615 0.657 0.564 0.609]
 [0.    0.5   0.614 0.    0.379 0.    0.5   0.593 0.    0.371]]
-------------------------------------------------------------
Standard Deviation of each metric:
[[0.165 0.083 0.071 0.131 0.085 0.159 0.08  0.072 0.099 0.082]
 [0.172 0.084 0.081 0.103 0.087 0.145 0.069 0.063 0.077 0.071]
 [0.185 0.079 0.071 0.135 0.08  0.151 0.064 0.058 0.08  0.066]
 [0.238 0.115 0.095 0.324 0.163 0.202 0.1   0.064 0.296 0.141]
 [0.209 0.103 0.079 0.223 0.121 0.169 0.086 0.058 0.189 0.101]
 [0.192 0.094 0.108 0.127 0.1   0.18  0.086 0.092 0.125 0.095]
 [0.    0.    0.078 0.    0.029 0.    0.    0.071 0.    0.028]]
-------------------------------------------------------------
std_dev/mean [percentage]:
[[ 39.  12.  10.  20.  12.  36.  11.  10.  14.  12.]
 [ 43.  12.  11.  15.  12.  34.  10.   9.  11.  10.]
 [ 40.  11.   9.  19.  11.  33.   9.   8.  11.   9.]
 [124.  19.  14. 110.  31.  90.  16.   9.  77.  25.]
 [ 57.  15.  11.  40.  18.  45.  13.   8.  32.  15.]
 [118.  16.  17.  24.  17.  76.  14.  14.  22.  16.]
 [  0.   0.  13.   0.   8.   0.   0.  12.   0.   8.]]
-------------------------------------
Current folder: C:\Users\Javier\Dropbox\c_sldl_1_2_37
-------------------------------------
----- RESULTS ------
-------------------------------------
Window size (sec):  12.992
step (sec):  6.496
overlap:  True
perc. of overlap:  50.0
overlap duration (sec):  6.496
Number of windows / instances:  184
Elapsed time: 893.9300123771031 minutes
Elapsed time: 14.898833539618385 hours
