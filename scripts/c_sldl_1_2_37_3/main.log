2024-05-11 15:33:14.438813: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-05-11 15:33:17.909214: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-05-11 15:33:26.626793: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
    
    
-------------------------------
participant:  1
-------------------------------
    
    
participant:  1
corriendo en PC gamer:
Window size (sec):  14.0
step (sec):  7.0
overlap:  True
perc. of overlap:  50.0
overlap duration (sec):  7.0
['gsr_chunks', 'ppg_chunks', 'val_chunks', 'aro_chunks', 'time_chunks', 'tag_chunks', 'video']
C:\Users\Javier\Dropbox\c_sldl_1_2_37_3\functions.py:880: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!
You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.
A typical example is when you are setting values in a column of a DataFrame, like:

df["col"][row_indexer] = value


Model: "sequential_1198"
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer (type)                    â”‚ Output Shape           â”‚       Param # â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1stConvL (Conv1D)               â”‚ (None, 14000, 5)       â”‚           105 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1stPoolL (AveragePooling1D)     â”‚ (None, 3500, 5)        â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2ndConvL (Conv1D)               â”‚ (None, 3500, 6)        â”‚           306 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2ndPoolL (AveragePooling1D)     â”‚ (None, 875, 6)         â”‚             0 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 2,209 (8.63 KB)
 Trainable params: 411 (1.61 KB)
 Non-trainable params: 0 (0.00 B)
 Optimizer params: 1,798 (7.03 KB)
----- train_PPG_AE -------
Model: "sequential_1199"
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer (type)                    â”‚ Output Shape           â”‚       Param # â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1stConvL (Conv1D)               â”‚ (None, 14000, 5)       â”‚           105 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1stPoolL (AveragePooling1D)     â”‚ (None, 3500, 5)        â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2ndConvL (Conv1D)               â”‚ (None, 3500, 6)        â”‚           306 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2ndPoolL (AveragePooling1D)     â”‚ (None, 875, 6)         â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling1d_2398              â”‚ (None, 3500, 6)        â”‚             0 â”‚
â”‚ (UpSampling1D)                  â”‚                        â”‚               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv1d_transpose_2398           â”‚ (None, 3500, 6)        â”‚           366 â”‚
â”‚ (Conv1DTranspose)               â”‚                        â”‚               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling1d_2399              â”‚ (None, 14000, 6)       â”‚             0 â”‚
â”‚ (UpSampling1D)                  â”‚                        â”‚               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv1d_transpose_2399           â”‚ (None, 14000, 1)       â”‚           121 â”‚
â”‚ (Conv1DTranspose)               â”‚                        â”‚               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 898 (3.51 KB)
 Trainable params: 898 (3.51 KB)
 Non-trainable params: 0 (0.00 B)
Epoch 1/5

[1m  1/120[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2:12[0m 1s/step - loss: 0.2505 - mean_squared_error: 0.2505
[1m  7/120[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - loss: 0.1448 - mean_squared_error: 0.1448
[1m 13/120[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - loss: 0.1126 - mean_squared_error: 0.1126
[1m 19/120[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - loss: 0.0972 - mean_squared_error: 0.0972
[1m 26/120[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0852 - mean_squared_error: 0.0852
[1m 32/120[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0785 - mean_squared_error: 0.0785
[1m 38/120[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0739 - mean_squared_error: 0.0739
[1m 44/120[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0703 - mean_squared_error: 0.0703
[1m 50/120[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0673 - mean_squared_error: 0.0673
[1m 57/120[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0642 - mean_squared_error: 0.0642
[1m 63/120[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0619 - mean_squared_error: 0.0619
[1m 69/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0598 - mean_squared_error: 0.0598
[1m 75/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0579 - mean_squared_error: 0.0579
[1m 81/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0562 - mean_squared_error: 0.0562
[1m 87/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0547 - mean_squared_error: 0.0547
[1m 93/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0534 - mean_squared_error: 0.0534
[1m 99/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0521 - mean_squared_error: 0.0521
[1m105/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0510 - mean_squared_error: 0.0510
[1m110/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 10ms/step - loss: 0.0501 - mean_squared_error: 0.0501
[1m115/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 10ms/step - loss: 0.0493 - mean_squared_error: 0.0493
[1m120/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m3s[0m 12ms/step - loss: 0.0484 - mean_squared_error: 0.0484 - val_loss: 0.0196 - val_mean_squared_error: 0.0196
Epoch 2/5

[1m  1/120[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 39ms/step - loss: 0.0105 - mean_squared_error: 0.0105
[1m  6/120[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 11ms/step - loss: 0.0123 - mean_squared_error: 0.0123
[1m 12/120[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 11ms/step - loss: 0.0135 - mean_squared_error: 0.0135
[1m 17/120[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 11ms/step - loss: 0.0142 - mean_squared_error: 0.0142
[1m 22/120[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 12ms/step - loss: 0.0146 - mean_squared_error: 0.0146
[1m 28/120[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 11ms/step - loss: 0.0152 - mean_squared_error: 0.0152
[1m 33/120[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0158 - mean_squared_error: 0.0158
[1m 39/120[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0166 - mean_squared_error: 0.0166
[1m 45/120[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0169 - mean_squared_error: 0.0169
[1m 51/120[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0174 - mean_squared_error: 0.0174
[1m 57/120[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0177 - mean_squared_error: 0.0177
[1m 63/120[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0179 - mean_squared_error: 0.0179
[1m 69/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0180 - mean_squared_error: 0.0180
[1m 75/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0180 - mean_squared_error: 0.0180
[1m 81/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0179 - mean_squared_error: 0.0179
[1m 86/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0179 - mean_squared_error: 0.0179
[1m 93/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0180 - mean_squared_error: 0.0180
[1m 99/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0181 - mean_squared_error: 0.0181
[1m104/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0181 - mean_squared_error: 0.0181
[1m109/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 11ms/step - loss: 0.0182 - mean_squared_error: 0.0182
[1m115/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 11ms/step - loss: 0.0182 - mean_squared_error: 0.0182
[1m120/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 11ms/step - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0177 - val_mean_squared_error: 0.0177
Epoch 3/5

[1m  1/120[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 31ms/step - loss: 0.0086 - mean_squared_error: 0.0086
[1m  7/120[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - loss: 0.0123 - mean_squared_error: 0.0123
[1m 13/120[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - loss: 0.0127 - mean_squared_error: 0.0127
[1m 19/120[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - loss: 0.0131 - mean_squared_error: 0.0131
[1m 24/120[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 11ms/step - loss: 0.0134 - mean_squared_error: 0.0134
[1m 30/120[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0135 - mean_squared_error: 0.0135
[1m 35/120[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0138 - mean_squared_error: 0.0138
[1m 41/120[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0142 - mean_squared_error: 0.0142
[1m 47/120[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0145 - mean_squared_error: 0.0145
[1m 53/120[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0147 - mean_squared_error: 0.0147
[1m 59/120[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0149 - mean_squared_error: 0.0149
[1m 65/120[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0150 - mean_squared_error: 0.0150
[1m 71/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0152 - mean_squared_error: 0.0152
[1m 77/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0153 - mean_squared_error: 0.0153
[1m 82/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0154 - mean_squared_error: 0.0154
[1m 88/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0156 - mean_squared_error: 0.0156
[1m 94/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0158 - mean_squared_error: 0.0158
[1m100/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0159 - mean_squared_error: 0.0159
[1m105/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0160 - mean_squared_error: 0.0160
[1m111/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 11ms/step - loss: 0.0161 - mean_squared_error: 0.0161
[1m117/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 11ms/step - loss: 0.0162 - mean_squared_error: 0.0162
[1m120/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 11ms/step - loss: 0.0163 - mean_squared_error: 0.0163 - val_loss: 0.0179 - val_mean_squared_error: 0.0179
Epoch 4/5

[1m  1/120[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 52ms/step - loss: 0.0087 - mean_squared_error: 0.0087
[1m  6/120[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 11ms/step - loss: 0.0150 - mean_squared_error: 0.0150
[1m 11/120[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 11ms/step - loss: 0.0148 - mean_squared_error: 0.0148
[1m 16/120[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 11ms/step - loss: 0.0138 - mean_squared_error: 0.0138
[1m 22/120[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 11ms/step - loss: 0.0126 - mean_squared_error: 0.0126
[1m 27/120[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 11ms/step - loss: 0.0128 - mean_squared_error: 0.0128
[1m 33/120[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0131 - mean_squared_error: 0.0131
[1m 38/120[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0134 - mean_squared_error: 0.0134
[1m 43/120[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0137 - mean_squared_error: 0.0137
[1m 49/120[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0140 - mean_squared_error: 0.0140
[1m 54/120[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0142 - mean_squared_error: 0.0142
[1m 59/120[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0143 - mean_squared_error: 0.0143
[1m 64/120[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0145 - mean_squared_error: 0.0145
[1m 69/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0147 - mean_squared_error: 0.0147
[1m 74/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0149 - mean_squared_error: 0.0149
[1m 79/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0150 - mean_squared_error: 0.0150
[1m 84/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0151 - mean_squared_error: 0.0151
[1m 89/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0153 - mean_squared_error: 0.0153
[1m 94/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0155 - mean_squared_error: 0.0155
[1m100/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0156 - mean_squared_error: 0.0156
[1m106/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0158 - mean_squared_error: 0.0158
[1m113/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 11ms/step - loss: 0.0159 - mean_squared_error: 0.0159
[1m119/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 11ms/step - loss: 0.0160 - mean_squared_error: 0.0160
[1m120/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 11ms/step - loss: 0.0161 - mean_squared_error: 0.0161 - val_loss: 0.0184 - val_mean_squared_error: 0.0184
Epoch 5/5

[1m  1/120[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 31ms/step - loss: 0.0087 - mean_squared_error: 0.0087
[1m  7/120[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - loss: 0.0159 - mean_squared_error: 0.0159
[1m 12/120[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 11ms/step - loss: 0.0160 - mean_squared_error: 0.0160
[1m 18/120[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 11ms/step - loss: 0.0160 - mean_squared_error: 0.0160
[1m 24/120[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 11ms/step - loss: 0.0157 - mean_squared_error: 0.0157
[1m 30/120[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0151 - mean_squared_error: 0.0151
[1m 36/120[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0148 - mean_squared_error: 0.0148
[1m 40/120[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0149 - mean_squared_error: 0.0149
[1m 46/120[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0149 - mean_squared_error: 0.0149
[1m 52/120[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0151 - mean_squared_error: 0.0151
[1m 57/120[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0152 - mean_squared_error: 0.0152
[1m 63/120[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0154 - mean_squared_error: 0.0154
[1m 69/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0155 - mean_squared_error: 0.0155
[1m 75/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0155 - mean_squared_error: 0.0155
[1m 81/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0156 - mean_squared_error: 0.0156
[1m 87/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0156 - mean_squared_error: 0.0156
[1m 92/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0157 - mean_squared_error: 0.0157
[1m 98/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0157 - mean_squared_error: 0.0157
[1m104/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0158 - mean_squared_error: 0.0158
[1m109/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 11ms/step - loss: 0.0159 - mean_squared_error: 0.0159
[1m115/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 11ms/step - loss: 0.0160 - mean_squared_error: 0.0160
[1m120/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 11ms/step - loss: 0.0161 - mean_squared_error: 0.0161 - val_loss: 0.0166 - val_mean_squared_error: 0.0166
(14000, 1, 5)
Model: "sequential_1199"
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer (type)                    â”‚ Output Shape           â”‚       Param # â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1stConvL (Conv1D)               â”‚ (None, 14000, 5)       â”‚           105 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1stPoolL (AveragePooling1D)     â”‚ (None, 3500, 5)        â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2ndConvL (Conv1D)               â”‚ (None, 3500, 6)        â”‚           306 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2ndPoolL (AveragePooling1D)     â”‚ (None, 875, 6)         â”‚             0 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 2,209 (8.63 KB)
 Trainable params: 411 (1.61 KB)
 Non-trainable params: 0 (0.00 B)
 Optimizer params: 1,798 (7.03 KB)
Model: "valence_NN"
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer (type)        â”‚ Output Shape      â”‚    Param # â”‚ Connected to      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ inputGSR            â”‚ (None, 14000, 1)  â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ inputPPG            â”‚ (None, 14000, 1)  â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ sequential_1198     â”‚ (None, 875, 6)    â”‚        411 â”‚ inputGSR[0][0]    â”‚
â”‚ (Sequential)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ sequential_1199     â”‚ (None, 875, 6)    â”‚        411 â”‚ inputPPG[0][0]    â”‚
â”‚ (Sequential)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ concatenate_599     â”‚ (None, 875, 12)   â”‚          0 â”‚ sequential_1198[â€¦ â”‚
â”‚ (Concatenate)       â”‚                   â”‚            â”‚ sequential_1199[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ permute_599         â”‚ (None, 12, 875)   â”‚          0 â”‚ concatenate_599[â€¦ â”‚
â”‚ (Permute)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ flatten_599         â”‚ (None, 10500)     â”‚          0 â”‚ permute_599[0][0] â”‚
â”‚ (Flatten)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout_599         â”‚ (None, 10500)     â”‚          0 â”‚ flatten_599[0][0] â”‚
â”‚ (Dropout)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_599 (Dense)   â”‚ (None, 1)         â”‚     10,501 â”‚ dropout_599[0][0] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 11,323 (44.23 KB)
 Trainable params: 11,323 (44.23 KB)
 Non-trainable params: 0 (0.00 B)
Epoch 1/10

[1m  1/120[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2:36[0m 1s/step - binary_accuracy: 1.0000 - loss: 0.5844
[1m  6/120[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 12ms/step - binary_accuracy: 0.6278 - loss: 0.6612
[1m 13/120[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - binary_accuracy: 0.6597 - loss: 0.6688
[1m 19/120[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 11ms/step - binary_accuracy: 0.6782 - loss: 0.6745
[1m 26/120[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6842 - loss: 0.6784
[1m 33/120[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6880 - loss: 0.6750
[1m 40/120[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6852 - loss: 0.6742
[1m 46/120[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6848 - loss: 0.6719
[1m 52/120[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6828 - loss: 0.6719
[1m 58/120[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6793 - loss: 0.6734
[1m 65/120[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6749 - loss: 0.6746
[1m 71/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6707 - loss: 0.6768
[1m 78/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6679 - loss: 0.6785
[1m 83/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6675 - loss: 0.6790
[1m 89/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6677 - loss: 0.6792
[1m 95/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6670 - loss: 0.6801
[1m101/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6651 - loss: 0.6823
[1m107/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6635 - loss: 0.6841
[1m112/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6619 - loss: 0.6858
[1m117/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6602 - loss: 0.6872
[1m120/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m3s[0m 14ms/step - binary_accuracy: 0.6592 - loss: 0.6881 - val_binary_accuracy: 0.9286 - val_loss: 0.5387
Epoch 2/10

[1m  1/120[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 32ms/step - binary_accuracy: 0.0000e+00 - loss: 0.8439
[1m  7/120[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - binary_accuracy: 0.5854 - loss: 0.5642    
[1m 14/120[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - binary_accuracy: 0.6484 - loss: 0.5589
[1m 20/120[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6565 - loss: 0.5717
[1m 27/120[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6642 - loss: 0.5742
[1m 34/120[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6688 - loss: 0.5727
[1m 40/120[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6679 - loss: 0.5746
[1m 47/120[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6613 - loss: 0.5857
[1m 53/120[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6563 - loss: 0.5931
[1m 58/120[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6536 - loss: 0.5979
[1m 65/120[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6500 - loss: 0.6037
[1m 70/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6493 - loss: 0.6066
[1m 76/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6478 - loss: 0.6100
[1m 82/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6475 - loss: 0.6125
[1m 89/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6466 - loss: 0.6160
[1m 95/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6453 - loss: 0.6194
[1m100/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6442 - loss: 0.6223
[1m106/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6424 - loss: 0.6255
[1m112/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6415 - loss: 0.6279
[1m118/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6407 - loss: 0.6300
[1m120/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 10ms/step - binary_accuracy: 0.6402 - loss: 0.6312 - val_binary_accuracy: 0.9286 - val_loss: 0.4308
Epoch 3/10

[1m  1/120[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 47ms/step - binary_accuracy: 1.0000 - loss: 0.3038
[1m  7/120[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - binary_accuracy: 0.6997 - loss: 0.5836
[1m 13/120[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - binary_accuracy: 0.6757 - loss: 0.6037
[1m 19/120[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - binary_accuracy: 0.6510 - loss: 0.6185
[1m 25/120[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6267 - loss: 0.6315
[1m 31/120[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6019 - loss: 0.6400
[1m 38/120[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.5805 - loss: 0.6469
[1m 44/120[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.5703 - loss: 0.6502
[1m 50/120[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.5662 - loss: 0.6522
[1m 56/120[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.5660 - loss: 0.6523
[1m 63/120[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.5611 - loss: 0.6572
[1m 69/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.5576 - loss: 0.6610
[1m 74/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.5565 - loss: 0.6627
[1m 80/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.5558 - loss: 0.6642
[1m 86/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.5557 - loss: 0.6649
[1m 92/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.5564 - loss: 0.6652
[1m 98/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.5574 - loss: 0.6653
[1m104/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.5586 - loss: 0.6652
[1m110/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.5601 - loss: 0.6647
[1m116/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.5624 - loss: 0.6639
[1m120/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 11ms/step - binary_accuracy: 0.5646 - loss: 0.6628 - val_binary_accuracy: 0.9286 - val_loss: 0.3515
Epoch 4/10

[1m  1/120[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 31ms/step - binary_accuracy: 1.0000 - loss: 0.2575
[1m  7/120[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - binary_accuracy: 0.7507 - loss: 0.4519
[1m 13/120[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - binary_accuracy: 0.6457 - loss: 0.5938
[1m 19/120[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - binary_accuracy: 0.5800 - loss: 0.6668
[1m 26/120[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.5469 - loss: 0.7011
[1m 32/120[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.5430 - loss: 0.7081
[1m 38/120[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.5417 - loss: 0.7120
[1m 44/120[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.5466 - loss: 0.7123
[1m 50/120[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.5551 - loss: 0.7108
[1m 56/120[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.5614 - loss: 0.7099
[1m 61/120[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.5681 - loss: 0.7074
[1m 66/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.5746 - loss: 0.7050
[1m 71/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.5782 - loss: 0.7040
[1m 77/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.5828 - loss: 0.7024
[1m 83/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.5878 - loss: 0.6997
[1m 89/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.5925 - loss: 0.6971
[1m 94/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.5964 - loss: 0.6948
[1m101/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.6012 - loss: 0.6916
[1m107/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.6050 - loss: 0.6890
[1m114/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6088 - loss: 0.6861
[1m120/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6119 - loss: 0.6837
[1m120/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 11ms/step - binary_accuracy: 0.6124 - loss: 0.6834 - val_binary_accuracy: 0.9286 - val_loss: 0.4079
Epoch 5/10

[1m  1/120[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 31ms/step - binary_accuracy: 1.0000 - loss: 0.2806
[1m  8/120[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - binary_accuracy: 0.7372 - loss: 0.4630
[1m 13/120[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - binary_accuracy: 0.7672 - loss: 0.4640
[1m 19/120[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - binary_accuracy: 0.8020 - loss: 0.4549
[1m 26/120[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.8176 - loss: 0.4530
[1m 31/120[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.8149 - loss: 0.4575
[1m 36/120[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.8119 - loss: 0.4603
[1m 42/120[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.8088 - loss: 0.4656
[1m 48/120[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.8029 - loss: 0.4746
[1m 54/120[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.7961 - loss: 0.4832
[1m 60/120[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.7918 - loss: 0.4886
[1m 65/120[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.7864 - loss: 0.4939
[1m 72/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.7772 - loss: 0.5021
[1m 77/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.7712 - loss: 0.5071
[1m 82/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.7646 - loss: 0.5121
[1m 88/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.7570 - loss: 0.5176
[1m 94/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.7497 - loss: 0.5229
[1m100/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.7433 - loss: 0.5276
[1m106/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.7382 - loss: 0.5313
[1m111/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.7343 - loss: 0.5343
[1m116/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.7312 - loss: 0.5369
[1m120/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 11ms/step - binary_accuracy: 0.7284 - loss: 0.5396 - val_binary_accuracy: 0.7857 - val_loss: 0.5219
Epoch 6/10

[1m  1/120[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 31ms/step - binary_accuracy: 1.0000 - loss: 0.6907
[1m  7/120[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - binary_accuracy: 0.7150 - loss: 0.6571
[1m 12/120[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 11ms/step - binary_accuracy: 0.6688 - loss: 0.6552
[1m 19/120[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - binary_accuracy: 0.6434 - loss: 0.6500
[1m 25/120[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6237 - loss: 0.6530
[1m 31/120[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6284 - loss: 0.6490
[1m 37/120[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6368 - loss: 0.6419
[1m 42/120[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.6455 - loss: 0.6358
[1m 48/120[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.6523 - loss: 0.6314
[1m 54/120[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.6596 - loss: 0.6258
[1m 60/120[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.6653 - loss: 0.6199
[1m 66/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.6695 - loss: 0.6144
[1m 72/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.6728 - loss: 0.6093
[1m 78/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.6759 - loss: 0.6045
[1m 83/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.6774 - loss: 0.6022
[1m 89/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.6788 - loss: 0.6003
[1m 94/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.6802 - loss: 0.5989
[1m 99/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.6806 - loss: 0.5984
[1m105/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.6809 - loss: 0.5978
[1m111/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.6807 - loss: 0.5976
[1m116/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.6805 - loss: 0.5974
[1m120/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 11ms/step - binary_accuracy: 0.6798 - loss: 0.5975 - val_binary_accuracy: 0.7143 - val_loss: 0.5507
Epoch 7/10

[1m  1/120[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 35ms/step - binary_accuracy: 1.0000 - loss: 0.4159
[1m  6/120[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - binary_accuracy: 0.8417 - loss: 0.4966
[1m 11/120[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - binary_accuracy: 0.8100 - loss: 0.5293
[1m 17/120[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - binary_accuracy: 0.7767 - loss: 0.5451
[1m 23/120[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7690 - loss: 0.5446
[1m 29/120[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7619 - loss: 0.5485
[1m 34/120[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7556 - loss: 0.5514
[1m 40/120[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7456 - loss: 0.5536
[1m 45/120[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7398 - loss: 0.5541
[1m 50/120[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.7345 - loss: 0.5554
[1m 56/120[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7276 - loss: 0.5586
[1m 61/120[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7221 - loss: 0.5618
[1m 66/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7162 - loss: 0.5666
[1m 72/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7101 - loss: 0.5716
[1m 78/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7049 - loss: 0.5757
[1m 84/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7023 - loss: 0.5784
[1m 90/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7010 - loss: 0.5801
[1m 96/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7007 - loss: 0.5813
[1m102/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7000 - loss: 0.5820
[1m108/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6997 - loss: 0.5824
[1m114/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6993 - loss: 0.5830
[1m120/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6989 - loss: 0.5834
[1m120/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 11ms/step - binary_accuracy: 0.6988 - loss: 0.5834 - val_binary_accuracy: 0.9286 - val_loss: 0.4028
Epoch 8/10

[1m  1/120[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 31ms/step - binary_accuracy: 1.0000 - loss: 0.3466
[1m  7/120[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 11ms/step - binary_accuracy: 0.8439 - loss: 0.4432
[1m 12/120[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 11ms/step - binary_accuracy: 0.8273 - loss: 0.4620
[1m 19/120[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - binary_accuracy: 0.7659 - loss: 0.5331
[1m 25/120[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7561 - loss: 0.5490
[1m 31/120[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7424 - loss: 0.5589
[1m 36/120[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.7341 - loss: 0.5627
[1m 40/120[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.7289 - loss: 0.5663
[1m 47/120[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.7210 - loss: 0.5716
[1m 52/120[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.7163 - loss: 0.5740
[1m 58/120[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.7102 - loss: 0.5773
[1m 63/120[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.7054 - loss: 0.5796
[1m 69/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.7022 - loss: 0.5804
[1m 76/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.7001 - loss: 0.5802
[1m 82/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.6987 - loss: 0.5798
[1m 89/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.6980 - loss: 0.5790
[1m 95/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.6970 - loss: 0.5784
[1m102/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6956 - loss: 0.5777
[1m108/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6949 - loss: 0.5769
[1m113/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.6940 - loss: 0.5766
[1m119/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.6924 - loss: 0.5764
[1m120/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 11ms/step - binary_accuracy: 0.6918 - loss: 0.5764 - val_binary_accuracy: 0.7857 - val_loss: 0.4811
Epoch 9/10

[1m  1/120[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 41ms/step - binary_accuracy: 1.0000 - loss: 0.2505
[1m  7/120[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.6707 - loss: 0.5043 
[1m 13/120[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - binary_accuracy: 0.5296 - loss: 0.6004
[1m 19/120[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.4957 - loss: 0.6324
[1m 24/120[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.5002 - loss: 0.6355
[1m 30/120[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.5176 - loss: 0.6318
[1m 36/120[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.5341 - loss: 0.6278
[1m 41/120[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.5502 - loss: 0.6209
[1m 48/120[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.5705 - loss: 0.6116
[1m 53/120[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.5810 - loss: 0.6065
[1m 58/120[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.5909 - loss: 0.6024
[1m 64/120[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6031 - loss: 0.5968
[1m 69/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6113 - loss: 0.5940
[1m 75/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6195 - loss: 0.5920
[1m 80/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6250 - loss: 0.5910
[1m 86/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6300 - loss: 0.5899
[1m 92/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6337 - loss: 0.5890
[1m 97/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6366 - loss: 0.5884
[1m103/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6402 - loss: 0.5877
[1m108/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6433 - loss: 0.5869
[1m114/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6472 - loss: 0.5859
[1m120/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6504 - loss: 0.5851
[1m120/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 11ms/step - binary_accuracy: 0.6509 - loss: 0.5850 - val_binary_accuracy: 0.6429 - val_loss: 0.5369
Epoch 10/10

[1m  1/120[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 33ms/step - binary_accuracy: 1.0000 - loss: 0.6452
[1m  6/120[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 12ms/step - binary_accuracy: 0.7306 - loss: 0.7060
[1m 11/120[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 12ms/step - binary_accuracy: 0.6619 - loss: 0.7092
[1m 15/120[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 12ms/step - binary_accuracy: 0.6434 - loss: 0.7174
[1m 19/120[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 12ms/step - binary_accuracy: 0.6375 - loss: 0.7134
[1m 24/120[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 12ms/step - binary_accuracy: 0.6317 - loss: 0.7039
[1m 29/120[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 12ms/step - binary_accuracy: 0.6312 - loss: 0.6965
[1m 34/120[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.6367 - loss: 0.6854
[1m 39/120[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.6396 - loss: 0.6764
[1m 45/120[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.6411 - loss: 0.6668
[1m 51/120[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.6429 - loss: 0.6567
[1m 56/120[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.6460 - loss: 0.6487
[1m 61/120[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.6486 - loss: 0.6421
[1m 67/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.6498 - loss: 0.6368
[1m 73/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.6510 - loss: 0.6320
[1m 79/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.6530 - loss: 0.6273
[1m 84/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.6555 - loss: 0.6236
[1m 91/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.6601 - loss: 0.6183
[1m 96/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.6631 - loss: 0.6146
[1m103/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.6671 - loss: 0.6101
[1m107/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.6689 - loss: 0.6079
[1m113/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.6712 - loss: 0.6055
[1m118/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.6729 - loss: 0.6038
[1m120/120[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 11ms/step - binary_accuracy: 0.6740 - loss: 0.6027 - val_binary_accuracy: 0.7857 - val_loss: 0.4666

[1m1/2[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 125ms/step
[1m2/2[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 79ms/step 
[1m2/2[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 79ms/step
predicted [0.62215644 0.28606385 0.71276224 0.7443708  0.6584463  0.6334609
 0.583258   0.78890115 0.31516516 0.12360679 0.1637525  0.31996843
 0.6752299  0.8000051  0.44393426 0.6032529  0.32049534 0.78180325
 0.7305615  0.8151908  0.6226634  0.8089969  0.2246482  0.79373634
 0.2518662  0.9238006  0.19125473 0.6265248  0.60360074 0.5714008
 0.806623   0.6333047  0.92065936 0.8505431 ]
predicted [1 0 1 1 1 1 1 1 0 0 0 0 1 1 0 1 0 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1]
expected [ True False  True  True  True  True False  True False False False  True
  True False False  True False  True  True False  True False  True  True
 False  True False  True  True  True  True  True  True False]
accuracy: 0.7941176470588235
confusion matrix: 
[[ 8  5]
 [ 2 19]]
              precision    recall  f1-score   support

       False       0.80      0.62      0.70        13
        True       0.79      0.90      0.84        21

    accuracy                           0.79        34
   macro avg       0.80      0.76      0.77        34
weighted avg       0.79      0.79      0.79        34

macro avg f1-score: 0.770048309178744
macro avg (UAR): 0.76007326007326
Sensitivity:  0.6153846153846154
Specificity:  0.9047619047619048
g-mean:  0.7461746154731859
-------- Model Performance ----------: 
accuracy:  [0.61764706 0.58823529 0.70588235 0.67647059 0.55882353 0.58823529
 0.76470588 0.58823529 0.64705882 0.79411765]
gmean:  [0.49908341 0.43221891 0.58990283 0.64051262 0.53452248 0.57735027
 0.69798244 0.48418203 0.62017367 0.74617462]
f1_score:  [0.55217832 0.50416667 0.64583333 0.65209302 0.53929539 0.575
 0.7312253  0.52964427 0.62637363 0.77004831]
UAR:  [0.55860806 0.52014652 0.64468864 0.65018315 0.54029304 0.57875458
 0.72161172 0.53479853 0.62637363 0.76007326]
Cohen Kappa score:  [0.12648221 0.04417671 0.31726908 0.30483271 0.07942238 0.15302491
 0.47081712 0.07392996 0.25274725 0.5440613 ]
arousal and valece = ok
------------- Evaluating model --------------
-------------------------------------
-------------------------------------
participant:  30
-------------------------------------
----- RESULTS ------
-------------------------------------
Window size (sec):  14.0
step (sec):  7.008
overlap:  True
perc. of overlap:  49.94285714285714
overlap duration (sec):  6.992
Number of windows / instances:  168
-rows: alg : KNN = 0; DT = 1; RF = 2; SVM = 3; GBM = 4; BDDAE = 5; DUMMY = 5
columns:
'val_cohen','val_uar', 'val_acc', 'val_gm',  'val_f1',  'aro_cohen','aro_uar', 'aro_acc', 'aro_gm',  'aro_f1'
-------------------------------------------------------------
  v_c   v_u   v_a   v_g   v_f1  a_c   a_u   a_a   a_g   a_f1
[[0.767 0.889 0.888 0.888 0.883 0.497 0.75  0.769 0.737 0.745]
 [0.593 0.808 0.816 0.776 0.804 0.462 0.753 0.775 0.736 0.751]
 [0.624 0.834 0.84  0.85  0.829 0.511 0.755 0.787 0.761 0.759]
 [0.691 0.837 0.858 0.827 0.843 0.1   0.543 0.661 0.28  0.494]
 [0.639 0.823 0.84  0.817 0.826 0.334 0.656 0.728 0.598 0.658]
 [0.237 0.614 0.653 0.582 0.613 0.142 0.562 0.656 0.445 0.548]
 [0.    0.5   0.619 0.    0.382 0.    0.5   0.649 0.    0.393]]
last participant performance loaded in numpy array
    
    
-------------------------------
LAST participant's saved data: 
30
-------------------------------
    
    
Saving performance metrics in csv files...
Performance metrics already saved in csv files
---------------------------
KNN performance:
[[0.51307575 0.75787698 0.75698529 0.75289706 0.75422229 0.37776734
  0.67788462 0.79742647 0.59557334 0.68300063]
 [0.50482794 0.7580754  0.75       0.7495795  0.7473511  0.36927213
  0.68160173 0.71323529 0.64589116 0.67549645]
 [0.5372176  0.76263889 0.77904412 0.74385479 0.76300637 0.45012867
  0.725      0.72573529 0.72079345 0.72338186]
 [0.50905756 0.75416667 0.75514706 0.73932709 0.74778484 0.22992102
  0.61083333 0.70845588 0.5249946  0.60868483]
 [0.62587224 0.80106061 0.83308824 0.78309481 0.80896361 0.65354459
  0.82708333 0.82647059 0.81594949 0.82253406]
 [0.53348478 0.76646825 0.76727941 0.75979994 0.76371689 0.65206867
  0.82638889 0.82683824 0.81623736 0.82291386]
 [0.46082505 0.72824675 0.74963235 0.71154025 0.7264971  0.30884759
  0.65486111 0.65551471 0.64558879 0.65072838]
 [0.8733705  0.92757576 0.94632353 0.92161112 0.93563752 0.64968549
  0.83145022 0.83382353 0.82715772 0.82348582]
 [0.34350674 0.65810606 0.74448529 0.60364872 0.6637593  0.32951737
  0.65992424 0.71397059 0.63515901 0.66121823]
 [0.46238219 0.73194444 0.73272059 0.72789492 0.72993132 0.29430545
  0.64753968 0.64852941 0.64431715 0.64514537]
 [0.24155146 0.61461039 0.66139706 0.57541755 0.6133551  0.4155545
  0.70166667 0.72647059 0.67382193 0.69942835]
 [0.68732498 0.83422078 0.85735294 0.82270891 0.8414027  0.51389288
  0.74893939 0.77389706 0.73296356 0.75230506]
 [0.54393935 0.77218254 0.78014706 0.76418786 0.77013355 0.35168492
  0.67436508 0.69191176 0.66204805 0.67424492]
 [0.24755756 0.6247619  0.65441176 0.59930061 0.61771223 0.50526302
  0.75188492 0.75625    0.72651058 0.74268939]
 [0.3284577  0.65568182 0.73823529 0.57257126 0.65440701 0.26794407
  0.6330303  0.67867647 0.59681405 0.62676845]
 [0.36570193 0.680671   0.71507353 0.60363389 0.66432458 0.55072551
  0.77212121 0.80330882 0.75443797 0.77132055]
 [0.5097653  0.7531746  0.76727941 0.73797789 0.75049964 0.49797365
  0.73928571 0.76875    0.71030532 0.74123275]
 [0.09154755 0.54761905 0.83345588 0.19696761 0.52535519 0.42737333
  0.7147619  0.72463235 0.70102931 0.70959307]
 [0.57659377 0.78181818 0.83308824 0.73013646 0.78420772 0.47244748
  0.73238095 0.74411765 0.71274051 0.72933358]
 [0.31751566 0.64492424 0.73345588 0.55054298 0.64593886 0.30070416
  0.64902597 0.68382353 0.62051442 0.64474365]
 [0.21663591 0.60833333 0.74448529 0.47670926 0.60375812 0.14808546
  0.575      0.57279412 0.5594741  0.5660258 ]
 [0.29553194 0.64722222 0.64889706 0.63213789 0.64155324 0.40045438
  0.69772727 0.73235294 0.67937456 0.69771007]
 [0.34048897 0.66621032 0.68529412 0.64349093 0.66338968 0.27469117
  0.62326923 0.76213235 0.51150736 0.623477  ]
 [0.26961335 0.63541667 0.63308824 0.62312879 0.62798382 0.6320167
  0.8105754  0.82132353 0.79973933 0.81337131]
 [0.50194822 0.74964286 0.75735294 0.74030429 0.74799402 0.64295373
  0.82291667 0.82132353 0.81709381 0.8194199 ]
 [0.36759676 0.67936508 0.69154412 0.64954986 0.67272404 0.56222206
  0.78073413 0.78455882 0.77505786 0.7793042 ]
 [0.57297274 0.78689394 0.82169118 0.76810558 0.78244326 0.61055648
  0.80555556 0.80441176 0.79363184 0.80029161]
 [0.07758273 0.53532468 0.58272059 0.49322312 0.53104387 0.56646022
  0.78495671 0.79227941 0.77452049 0.78025596]
 [0.23137339 0.61101732 0.66102941 0.52607874 0.59706847 0.40612762
  0.70117063 0.70808824 0.68869763 0.69840084]
 [0.76746886 0.88915584 0.88786765 0.88766675 0.88323221 0.49700536
  0.74984848 0.76875    0.73716661 0.74477579]]
KNN mean:
[0.43049295 0.71214689 0.75008578 0.66956961 0.70864659 0.4453065
 0.72039278 0.74566176 0.69663705 0.71770939]
---------------------------
---------------------------
DT performance:
[[0.61337748 0.81242063 0.81507353 0.82074952 0.81224536 0.40979907
  0.73012821 0.79852941 0.69037069 0.72808082]
 [0.57835729 0.80378968 0.81029412 0.78764206 0.80253268 0.51851291
  0.77160173 0.78014706 0.77243715 0.76860951]
 [0.34536186 0.62621032 0.62977941 0.63719006 0.61699836 0.40167622
  0.69444444 0.69669118 0.68584832 0.69038886]
 [0.36922331 0.66111111 0.66066176 0.64545378 0.65034765 0.33584094
  0.64583333 0.72022059 0.60217724 0.63886127]
 [0.60024608 0.82909091 0.83345588 0.81512841 0.82295926 0.61944237
  0.80902778 0.80955882 0.81532482 0.80850496]
 [0.38269952 0.69712302 0.70036765 0.68249446 0.69361706 0.55741083
  0.78541667 0.78455882 0.76221361 0.78230085]
 [0.44708288 0.68647186 0.69522059 0.73849306 0.68104753 0.35360083
  0.64652778 0.64852941 0.62376019 0.64155711]
 [0.80989104 0.89818182 0.90477941 0.89598655 0.89290222 0.63342616
  0.82865801 0.83860294 0.81186053 0.82725021]
 [0.47746442 0.67030303 0.72022059 0.68787178 0.66508637 0.47991865
  0.73242424 0.75477941 0.73785071 0.71690759]
 [0.48417343 0.77847222 0.78014706 0.73675826 0.77301453 0.3208534
  0.6806746  0.68308824 0.65092691 0.6775512 ]
 [0.15386255 0.5712987  0.60257353 0.60590926 0.56965586 0.34880517
  0.66984127 0.69117647 0.63498528 0.66696817]
 [0.57880923 0.76919913 0.78529412 0.7772393  0.77031581 0.47215113
  0.73699134 0.74411765 0.72500438 0.73067943]
 [0.38900301 0.71402778 0.72132353 0.69102559 0.71200389 0.29691754
  0.65357143 0.66544118 0.61952973 0.64731235]
 [0.29700741 0.65463203 0.67683824 0.64490985 0.6495679  0.3956728
  0.67321429 0.67352941 0.66035654 0.66948696]
 [0.32606957 0.63007576 0.66801471 0.66336249 0.62348541 0.19154625
  0.58484848 0.63161765 0.55975603 0.580478  ]
 [0.50195117 0.74419913 0.76323529 0.73269971 0.74362922 0.4955391
  0.74242424 0.76139706 0.73823688 0.72619664]
 [0.67585603 0.80253968 0.80919118 0.79626398 0.79726506 0.60001298
  0.79690476 0.80992647 0.80331353 0.79869339]
 [0.2229888  0.61928571 0.85183824 0.50409388 0.62454791 0.49251488
  0.72190476 0.72095588 0.71733232 0.71446008]
 [0.42309561 0.72530303 0.75625    0.69286534 0.70944038 0.4602797
  0.71581349 0.71507353 0.70029854 0.7064923 ]
 [0.25207207 0.66030303 0.70330882 0.61575735 0.64394169 0.24672158
  0.60469697 0.59963235 0.61003749 0.58847204]
 [0.20445313 0.62403846 0.70257353 0.59755611 0.61040299 0.04437539
  0.53472222 0.53529412 0.54307768 0.53169799]
 [0.37651809 0.70208333 0.70220588 0.65608656 0.69971307 0.31958674
  0.63787879 0.64852941 0.61796383 0.6266595 ]
 [0.28929495 0.65162698 0.65330882 0.64346931 0.64652472 0.26546894
  0.61333333 0.69632353 0.52555441 0.5985849 ]
 [0.4165048  0.70694444 0.70919118 0.70744989 0.70252852 0.55088643
  0.75674603 0.76176471 0.71113832 0.75378413]
 [0.39053074 0.73371032 0.74338235 0.69474173 0.72722013 0.65501128
  0.82847222 0.82720588 0.81935276 0.82597106]
 [0.40658165 0.6610119  0.66176471 0.65769635 0.65934757 0.49584439
  0.76515873 0.76838235 0.7334443  0.76406133]
 [0.51058944 0.75242424 0.77904412 0.74872279 0.73980194 0.48125703
  0.75486111 0.75036765 0.74963395 0.74401009]
 [0.11328074 0.55588745 0.57720588 0.47850865 0.54924966 0.37878894
  0.71138528 0.72757353 0.67438668 0.70795039]
 [0.21167119 0.63577922 0.65367647 0.62005637 0.62812023 0.2319207
  0.61015873 0.61213235 0.61824713 0.60165908]
 [0.59259551 0.80816017 0.81617647 0.77577984 0.80415635 0.46221186
  0.75318182 0.77463235 0.73583065 0.75135379]]
DT mean:
[0.4146871  0.70619017 0.72954657 0.69173208 0.70072231 0.41719981
 0.70636154 0.72099265 0.68834169 0.70049947]
---------------------------
---------------------------
RF performance:
[[0.65116598 0.82978175 0.83308824 0.83326751 0.82995593 0.36465586
  0.74038462 0.82720588 0.62784579 0.72876047]
 [0.60457406 0.76146825 0.76764706 0.77055847 0.75791034 0.49715057
  0.74541126 0.76102941 0.69402433 0.74240652]
 [0.55559715 0.73349206 0.74889706 0.7447594  0.73382652 0.52003269
  0.70069444 0.70147059 0.73824187 0.69888189]
 [0.50913841 0.72013889 0.72022059 0.72780397 0.71210268 0.1818628
  0.62       0.69669118 0.60629697 0.60608559]
 [0.57917299 0.76571429 0.78529412 0.74596822 0.76428828 0.57105267
  0.80555556 0.80367647 0.78126397 0.80152403]
 [0.535252   0.73472222 0.73161765 0.70873884 0.72841958 0.6790789
  0.77291667 0.77352941 0.79274846 0.77084541]
 [0.39947227 0.68419913 0.71544118 0.66500723 0.6872374  0.29923383
  0.70138889 0.70257353 0.68180919 0.69855302]
 [0.82018808 0.91393939 0.92242647 0.91803062 0.9125591  0.66566757
  0.83867965 0.84558824 0.78105275 0.83375036]
 [0.40145665 0.7455303  0.79889706 0.64336125 0.7475472  0.35360856
  0.64530303 0.70257353 0.60496898 0.64675743]
 [0.49776666 0.7625     0.76139706 0.72278579 0.75706147 0.44021258
  0.67686508 0.68235294 0.68589124 0.67664681]
 [0.28311043 0.60688312 0.63823529 0.53614385 0.60007546 0.43752705
  0.75349206 0.775      0.7685043  0.74606469]
 [0.71715233 0.85279221 0.86875    0.79042941 0.85671446 0.53495674
  0.74727273 0.75625    0.72729276 0.74173378]
 [0.39905815 0.72630952 0.73161765 0.72298945 0.72244963 0.37125958
  0.65984127 0.67794118 0.65158674 0.66077896]
 [0.2368604  0.60813853 0.65551471 0.55821126 0.6029953  0.4973362
  0.66646825 0.66727941 0.67893925 0.66099206]
 [0.41625757 0.72318182 0.76286765 0.69603909 0.72467727 0.29601091
  0.69878788 0.72683824 0.60231895 0.69675408]
 [0.33735108 0.69134199 0.70441176 0.70210249 0.68674312 0.59990202
  0.79295455 0.82132353 0.78365774 0.79710261]
 [0.61848581 0.83809524 0.85036765 0.81057689 0.83893168 0.63970955
  0.82166667 0.82794118 0.7847474  0.8161275 ]
 [0.26782323 0.56785714 0.84044118 0.40178662 0.56065076 0.53181968
  0.75452381 0.76139706 0.74334763 0.74226384]
 [0.61991195 0.8180303  0.85772059 0.74458951 0.82152546 0.58211729
  0.80085317 0.80404412 0.79240007 0.79804097]
 [0.28417872 0.68916667 0.74485294 0.62247033 0.68046945 0.30724866
  0.64677489 0.67132353 0.62361196 0.63891475]
 [0.06215576 0.59230769 0.73235294 0.34733829 0.59736747 0.0559113
  0.50972222 0.51139706 0.4894111  0.497181  ]
 [0.38185668 0.65277778 0.65477941 0.61869806 0.64388528 0.43347692
  0.71575758 0.73897059 0.68043311 0.70843795]
 [0.26603366 0.58454365 0.59080882 0.60969143 0.58196606 0.42177537
  0.67121795 0.77977941 0.68463017 0.66925031]
 [0.46668221 0.75625    0.75735294 0.69410515 0.74589495 0.48592304
  0.73980159 0.74411765 0.75136724 0.73869574]
 [0.49002783 0.7414881  0.74411765 0.75288642 0.74018244 0.70185248
  0.77916667 0.77904412 0.84266932 0.77636564]
 [0.41344543 0.7        0.70882353 0.6160726  0.69840185 0.53965393
  0.79603175 0.79816176 0.71490799 0.79377245]
 [0.51037936 0.77931818 0.81029412 0.71616882 0.7756087  0.55238137
  0.79583333 0.79301471 0.7851908  0.78709882]
 [0.26801948 0.59818182 0.62426471 0.58985107 0.5979379  0.55127431
  0.75443723 0.77536765 0.7479654  0.75333952]
 [0.30867275 0.59690476 0.62536765 0.62462528 0.59325236 0.31439464
  0.67361111 0.67794118 0.6358457  0.66784702]
 [0.62354137 0.83385281 0.83970588 0.8495378  0.828804   0.51100167
  0.75515152 0.78676471 0.76116156 0.75916607]]
RF mean:
[0.45082628 0.72029692 0.75091912 0.68281984 0.71764807 0.46460296
 0.72601885 0.74568627 0.70813776 0.72180464]
---------------------------
---------------------------
SVM performance:
[[ 0.24575065  0.61589286  0.64926471  0.49003566  0.5705202   0.
   0.5         0.76176471  0.          0.43238095]
 [ 0.37909811  0.68339286  0.70220588  0.65364245  0.67963386  0.3945106
   0.69281385  0.73125     0.61805684  0.67978381]
 [ 0.55658418  0.76160714  0.79705882  0.71890825  0.76532279  0.43620735
   0.71736111  0.71985294  0.70646849  0.71398054]
 [ 0.37052619  0.68263889  0.68970588  0.63269603  0.66341799  0.
   0.5         0.71470588  0.          0.41674877]
 [ 0.57094069  0.76707792  0.81470588  0.73572567  0.77859047  0.50962892
   0.75347222  0.75551471  0.74202275  0.75023238]
 [ 0.40352867  0.6984127   0.70882353  0.65032073  0.68219655  0.52059532
   0.76111111  0.76102941  0.75213832  0.75696511]
 [ 0.          0.5         0.60735294  0.          0.37771673  0.29129159
   0.64583333  0.64742647  0.62870883  0.63830404]
 [ 0.7588669   0.8655303   0.89889706  0.85428335  0.87779658  0.39878025
   0.68393939  0.74485294  0.6191331   0.68116388]
 [ 0.          0.5         0.69632353  0.          0.41042237  0.
   0.5         0.68455882  0.          0.40623518]
 [ 0.38584501  0.69305556  0.69117647  0.68373994  0.68809678  0.0900387
   0.54119048  0.57205882  0.35177479  0.4784851 ]
 [ 0.          0.5         0.63676471  0.          0.38896011  0.20386979
   0.5902381   0.66139706  0.40513442  0.54045807]
 [ 0.35531404  0.65904762  0.73235294  0.53843375  0.64548375  0.14214384
   0.56352814  0.64191176  0.33145884  0.50627743]
 [ 0.2010092   0.5925      0.64926471  0.40494193  0.54345349  0.
   0.5         0.58933824  0.          0.37075783]
 [ 0.          0.5         0.63676471  0.          0.38896011  0.36123051
   0.68035714  0.68529412  0.65607989  0.67080761]
 [ 0.          0.5         0.67867647  0.          0.40414158  0.
   0.5         0.65514706  0.          0.3957672 ]
 [ 0.          0.5         0.60147059  0.          0.37546805 -0.01121495
   0.49545455  0.65514706  0.          0.39561211]
 [ 0.          0.5         0.58933824  0.          0.37075783  0.
   0.5         0.59558824  0.          0.37321937]
 [ 0.          0.5         0.85735294  0.          0.46147849  0.120159
   0.55380952  0.63088235  0.2853594   0.48931197]
 [ 0.          0.5         0.69044118  0.          0.40832877  0.
   0.5         0.55955882  0.          0.35860969]
 [ 0.          0.5         0.67279412  0.          0.40204798  0.02056075
   0.50833333  0.63676471  0.04082483  0.40245218]
 [ 0.          0.5         0.76176471  0.          0.43238095  0.00290913
   0.50138889  0.50588235  0.06868867  0.35434188]
 [ 0.29402527  0.64652778  0.64889706  0.61364471  0.63301568  0.
   0.5         0.64889706  0.          0.39348799]
 [ 0.          0.5         0.57720588  0.          0.36587464  0.
   0.5         0.73823529  0.          0.42456486]
 [ 0.          0.5         0.52352941  0.          0.34358974  0.4092926
   0.69688492  0.72058824  0.638865    0.68252787]
 [ 0.05808696  0.52678571  0.58308824  0.10345225  0.40667949  0.45754826
   0.72777778  0.73235294  0.70637875  0.72077663]
 [-0.01167883  0.49444444  0.53014706  0.          0.34630769  0.39654765
   0.69501984  0.70845588  0.6749841   0.69194737]
 [ 0.1969697   0.58        0.74411765  0.27917938  0.54181518  0.58780172
   0.79444444  0.79264706  0.78689178  0.79063179]
 [ 0.          0.5         0.63088235  0.          0.38671144  0.32258093
   0.64547619  0.70845588  0.55298722  0.63248661]
 [ 0.          0.5         0.61911765  0.          0.38221408  0.16134895
   0.57581349  0.6125      0.41644206  0.52287801]
 [ 0.69051974  0.83681818  0.85772059  0.82703645  0.84342783  0.09983978
   0.54318182  0.66066176  0.27976953  0.49436451]]
SVM mean:
[0.18184622 0.58679107 0.68257353 0.27286802 0.51882704 0.19718902
 0.59558099 0.67442402 0.34207225 0.53885202]
---------------------------
---------------------------
GBM performance:
[[ 0.59708612  0.79771825  0.80955882  0.77795415  0.8000392   0.32186141
   0.61346154  0.80367647  0.34511302  0.59552503]
 [ 0.51068193  0.74700397  0.76801471  0.72209851  0.74813976  0.4972849
   0.7304329   0.76838235  0.70370887  0.73611153]
 [ 0.4817958   0.72676587  0.76139706  0.68188123  0.72678744  0.39119162
   0.68888889  0.69007353  0.68823256  0.68562586]
 [ 0.46315321  0.73194444  0.73272059  0.71163924  0.72246568  0.11028601
   0.55        0.73272059  0.23977046  0.51151888]
 [ 0.55848504  0.77235931  0.82058824  0.74109108  0.78554643  0.64239844
   0.82083333  0.82169118  0.81570969  0.81888367]
 [ 0.48866474  0.7530754   0.74852941  0.7418038   0.7473597   0.62741092
   0.81319444  0.81433824  0.80106873  0.80946174]
 [ 0.36196053  0.66805195  0.72647059  0.59958159  0.664694    0.41468907
   0.70069444  0.70294118  0.69001003  0.69651862]
 [ 0.83386315  0.91431818  0.92830882  0.9041701   0.91580241  0.53440177
   0.75158009  0.79816176  0.71722295  0.75885626]
 [ 0.38606613  0.66878788  0.77463235  0.60262047  0.67978677  0.13701014
   0.54545455  0.70772059  0.17121247  0.4853736 ]
 [ 0.35319702  0.67708333  0.67794118  0.64401008  0.66821997  0.21962578
   0.60746032  0.62463235  0.51670889  0.58235961]
 [ 0.29251963  0.62766234  0.70367647  0.49531514  0.61193075  0.58733079
   0.78444444  0.80992647  0.76103995  0.78724702]
 [ 0.68216155  0.82233766  0.85183824  0.80663905  0.83197477  0.57459971
   0.78922078  0.80992647  0.76520537  0.79157114]
 [ 0.48075878  0.73888889  0.75110294  0.7170251   0.73291071  0.16132082
   0.5881746   0.63639706  0.47491393  0.56822913]
 [ 0.17731916  0.59155844  0.69044118  0.37914522  0.55499878  0.44744951
   0.71577381  0.72242647  0.69234822  0.70834011]
 [ 0.01584562  0.50636364  0.66102941  0.13420317  0.44032841  0.14776474
   0.56833333  0.67279412  0.40269132  0.54565123]
 [ 0.09569578  0.53450216  0.625       0.24209084  0.45291595  0.37391828
   0.67265152  0.7625      0.56394302  0.67082715]
 [ 0.65501294  0.83039683  0.84448529  0.82161133  0.831896    0.43759973
   0.72166667  0.75698529  0.67989202  0.71945569]
 [-0.01818806  0.4897619   0.83970588  0.          0.45622312  0.49103434
   0.73833333  0.76176471  0.71833395  0.74002648]
 [ 0.23692911  0.59674242  0.73161765  0.38726474  0.57492898  0.54796499
   0.76843254  0.78566176  0.74337006  0.76833111]
 [ 0.34557483  0.65469697  0.75588235  0.54005602  0.65050248  0.16852579
   0.56729437  0.65404412  0.37000319  0.53263032]
 [ 0.          0.49615385  0.75588235  0.          0.43042693  0.11644434
   0.54097222  0.54080882  0.53031684  0.53551531]
 [ 0.40077976  0.69513889  0.69669118  0.67995479  0.6862321   0.25766593
   0.61272727  0.70845588  0.50419298  0.60032318]
 [ 0.17900897  0.58339286  0.63088235  0.4810176   0.55558614  0.16484095
   0.56910256  0.75036765  0.31724275  0.54824092]
 [ 0.425935    0.71180556  0.71507353  0.68651343  0.70630503  0.57678854
   0.78172619  0.78602941  0.7742852   0.77993573]
 [ 0.33676739  0.66628968  0.69522059  0.6077263   0.65555001  0.60491999
   0.80277778  0.80294118  0.78940458  0.7991166 ]
 [ 0.38837443  0.69107143  0.70330882  0.6382433   0.67222849  0.49562733
   0.74325397  0.75625     0.73761268  0.74404963]
 [ 0.36884745  0.67424242  0.77352941  0.52711504  0.65969061  0.65892187
   0.83680556  0.83419118  0.82667208  0.83179561]
 [ 0.19916634  0.58887446  0.66654412  0.50066904  0.58004108  0.39535182
   0.69164502  0.73970588  0.62334517  0.68996507]
 [ 0.33193466  0.65805195  0.72720588  0.53204258  0.64643491  0.24421022
   0.63125     0.64779412  0.58891436  0.62182998]
 [ 0.6387926   0.82272727  0.83970588  0.81687118  0.82591502  0.33440009
   0.65621212  0.72757353  0.59750192  0.65846779]]
GBM mean:
[0.37560632 0.68125894 0.74689951 0.57067847 0.66719539 0.38942799
 0.68675995 0.73769608 0.60499958 0.6773928 ]
---------------------------
---------------------------
BDDAE performance:
[[ 0.04747116  0.52263158  0.53235294  0.51383166  0.52178521  0.09405112
   0.53653846  0.74117647  0.30455681  0.52359793]
 [ 0.13607062  0.56877193  0.57058824  0.56480623  0.56580428  0.46181636
   0.72582418  0.75        0.71546233  0.72922282]
 [ 0.02838624  0.51321429  0.55588235  0.43825097  0.49545678  0.11680162
   0.55763889  0.56470588  0.53630978  0.55050203]
 [ 0.0615334   0.53090278  0.53235294  0.52195021  0.52675972  0.17750954
   0.57458333  0.72058824  0.41602535  0.56256995]
 [ 0.47692362  0.73644689  0.75588235  0.72455131  0.73573549  0.51176471
   0.75588235  0.75588235  0.75005479  0.75349768]
 [ 0.60759024  0.80208333  0.80588235  0.79679032  0.80235589 -0.15693934
   0.42118056  0.42058824  0.41247323  0.4165141 ]
 [ 0.12029245  0.56245421  0.59705882  0.51763832  0.55147472  0.
   0.5         0.5         0.47265448  0.48673133]
 [ 0.34451959  0.65434783  0.74411765  0.59455258  0.66182035 -0.00465332
   0.4985348   0.54705882  0.42662139  0.48251233]
 [ 0.51171839  0.72708333  0.82058824  0.68299522  0.74869323  0.45941821
   0.69545455  0.80294118  0.61646081  0.71167639]
 [ 0.05882353  0.52941176  0.52941176  0.51576151  0.52264798  0.28002527
   0.63701754  0.65        0.62497741  0.63705805]
 [ 0.10631003  0.55189394  0.60882353  0.49427149  0.54234661  0.23097744
   0.60928571  0.64117647  0.57228716  0.60485242]
 [ 0.02686795  0.51300366  0.55588235  0.46925493  0.50673743  0.41378443
   0.71483516  0.71470588  0.70574462  0.7024002 ]
 [ 0.1246421   0.56428571  0.57058824  0.54560121  0.5539364   0.32024776
   0.66107143  0.67058824  0.64972375  0.65644018]
 [ 0.23835364  0.61590909  0.66470588  0.57609175  0.61077695  0.43121212
   0.71701389  0.71470588  0.7136651   0.71376373]
 [-0.03008688  0.48399209  0.59705882  0.34168118  0.46826546  0.10360183
   0.54810606  0.62352941  0.46142326  0.53500405]
 [ 0.07078071  0.53607143  0.56764706  0.48233333  0.5218366   0.24283868
   0.60454545  0.70882353  0.45013869  0.58507355]
 [ 0.56446462  0.78642857  0.78529412  0.78258496  0.7805068   0.12740023
   0.55785714  0.61470588  0.44913064  0.53004292]
 [ 0.27480312  0.62724138  0.84411765  0.50117255  0.63062634  0.18907837
   0.59107143  0.62352941  0.55032719  0.58451039]
 [ 0.30669578  0.6472332   0.70882353  0.61129056  0.64817044  0.36539046
   0.68087719  0.69117647  0.6719898   0.68070083]
 [ 0.31209354  0.64407115  0.72058824  0.59299881  0.647104   -0.12027591
   0.44340659  0.52058824  0.25613903  0.40497556]
 [ 0.08396742  0.54471154  0.72058824  0.33571464  0.5255538   0.11176471
   0.55588235  0.55588235  0.55117825  0.55356976]
 [-0.13529412  0.43235294  0.43235294  0.42628566  0.42959932  0.20344602
   0.59204545  0.67058824  0.52292217  0.58966631]
 [ 0.06721106  0.5325      0.54705882  0.52086908  0.53047338  0.33128985
   0.64533333  0.77647059  0.56629285  0.65615112]
 [ 0.14267701  0.57118056  0.57058824  0.55021644  0.56056935  0.2475182
   0.62175439  0.63529412  0.60074035  0.61710244]
 [ 0.01705063  0.50842105  0.52352941  0.477286    0.50050615  0.17703989
   0.58888889  0.58823529  0.57607701  0.58186006]
 [ 0.19581037  0.59652778  0.60294118  0.57636895  0.59015914  0.22415815
   0.60894737  0.62647059  0.58271118  0.60379796]
 [ 0.46937679  0.72541667  0.78529412  0.70854031  0.73381094  0.5
   0.75        0.75        0.73831736  0.74568057]
 [-0.11709196  0.44413919  0.48529412  0.37851021  0.43665905  0.40401015
   0.69714286  0.72058824  0.67597217  0.69682632]
 [ 0.0047757   0.50274725  0.53235294  0.47625058  0.49818723  0.46067995
   0.72561404  0.74117647  0.70633819  0.72461062]
 [ 0.23667636  0.61355311  0.65294118  0.58221033  0.61258582  0.14225363
   0.56174242  0.65588235  0.44537653  0.54799883]]
BDDAE mean:
[0.1784471  0.58630094 0.63068627 0.54335538 0.5820315  0.23487367
 0.61260253 0.65656863 0.55740306 0.60563035]
---------------------------
---------------------------
DUMMY performance:
[[0.         0.5        0.54779412 0.         0.35376638 0.
  0.5        0.76176471 0.         0.43238095]
 [0.         0.5        0.55955882 0.         0.35860969 0.
  0.5        0.60735294 0.         0.37771673]
 [0.         0.5        0.57720588 0.         0.36587464 0.
  0.5        0.51764706 0.         0.34097436]
 [0.         0.5        0.52352941 0.         0.34358974 0.
  0.5        0.71470588 0.         0.41674877]
 [0.         0.5        0.625      0.         0.38446276 0.
  0.5        0.50588235 0.         0.33574359]
 [0.         0.5        0.52977941 0.         0.34625641 0.
  0.5        0.52352941 0.         0.34358974]
 [0.         0.5        0.60735294 0.         0.37771673 0.
  0.5        0.50588235 0.         0.33574359]
 [0.         0.5        0.67279412 0.         0.40204798 0.
  0.5        0.625      0.         0.38446276]
 [0.         0.5        0.69632353 0.         0.41042237 0.
  0.5        0.68455882 0.         0.40623518]
 [0.         0.5        0.47647059 0.         0.32266667 0.
  0.5        0.54779412 0.         0.35376638]
 [0.         0.5        0.63676471 0.         0.38896011 0.
  0.5        0.58933824 0.         0.37075783]
 [0.         0.5        0.61323529 0.         0.3799654  0.
  0.5        0.61323529 0.         0.3799654 ]
 [0.         0.5        0.57720588 0.         0.36587464 0.
  0.5        0.58933824 0.         0.37075783]
 [0.         0.5        0.63676471 0.         0.38896011 0.
  0.5        0.52977941 0.         0.34625641]
 [0.         0.5        0.67867647 0.         0.40414158 0.
  0.5        0.65514706 0.         0.3957672 ]
 [0.         0.5        0.60147059 0.         0.37546805 0.
  0.5        0.66102941 0.         0.39786079]
 [0.         0.5        0.58933824 0.         0.37075783 0.
  0.5        0.59558824 0.         0.37321937]
 [0.         0.5        0.85735294 0.         0.46147849 0.
  0.5        0.59558824 0.         0.37321937]
 [0.         0.5        0.69044118 0.         0.40832877 0.
  0.5        0.55955882 0.         0.35860969]
 [0.         0.5        0.67279412 0.         0.40204798 0.
  0.5        0.63088235 0.         0.38671144]
 [0.         0.5        0.76176471 0.         0.43238095 0.
  0.5        0.50588235 0.         0.33574359]
 [0.         0.5        0.47647059 0.         0.32266667 0.
  0.5        0.64889706 0.         0.39348799]
 [0.         0.5        0.57720588 0.         0.36587464 0.
  0.5        0.73823529 0.         0.42456486]
 [0.         0.5        0.52352941 0.         0.34358974 0.
  0.5        0.54779412 0.         0.35376638]
 [0.         0.5        0.55955882 0.         0.35860969 0.
  0.5        0.51764706 0.         0.34097436]
 [0.         0.5        0.53602941 0.         0.34892308 0.
  0.5        0.55367647 0.         0.35618803]
 [0.         0.5        0.69632353 0.         0.41042237 0.
  0.5        0.50588235 0.         0.33574359]
 [0.         0.5        0.63088235 0.         0.38671144 0.
  0.5        0.60147059 0.         0.37546805]
 [0.         0.5        0.61911765 0.         0.38221408 0.
  0.5        0.55367647 0.         0.35618803]
 [0.         0.5        0.61911765 0.         0.38221408 0.
  0.5        0.64889706 0.         0.39348799]]
DUMMY mean:
[0.         0.5        0.61232843 0.         0.37816677 0.
 0.5        0.59452206 0.         0.37153668]
---------------------------
Current folder: C:\Users\Javier\Dropbox\c_sldl_1_2_37_3
-------------------------------------
----- RESULTS from .csv files ------
-------------------------------------
---------------------------
ALG Means: 
-rows: alg : KNN = 0; DT = 1; RF = 2; SVM = 3; GBM = 4; BDDAE = 5; DUMMY = 5
columns:
'val_cohen','val_uar', 'val_acc', 'val_gm',  'val_f1',  'aro_cohen','aro_uar', 'aro_acc', 'aro_gm',  'aro_f1'
-------------------------------------------------------------
  v_c   v_u   v_a   v_g   v_f1  a_c   a_u   a_a   a_g   a_f1
[[0.43  0.712 0.75  0.67  0.709 0.445 0.72  0.746 0.697 0.718]
 [0.415 0.706 0.73  0.692 0.701 0.417 0.706 0.721 0.688 0.7  ]
 [0.451 0.72  0.751 0.683 0.718 0.465 0.726 0.746 0.708 0.722]
 [0.182 0.587 0.683 0.273 0.519 0.197 0.596 0.674 0.342 0.539]
 [0.376 0.681 0.747 0.571 0.667 0.389 0.687 0.738 0.605 0.677]
 [0.178 0.586 0.631 0.543 0.582 0.235 0.613 0.657 0.557 0.606]
 [0.    0.5   0.612 0.    0.378 0.    0.5   0.595 0.    0.372]]
-------------------------------------------------------------
Standard Deviation of each metric:
[[0.183 0.092 0.078 0.139 0.095 0.139 0.071 0.061 0.086 0.071]
 [0.16  0.08  0.077 0.089 0.081 0.14  0.074 0.072 0.08  0.076]
 [0.164 0.089 0.08  0.119 0.09  0.146 0.07  0.067 0.077 0.071]
 [0.234 0.113 0.093 0.322 0.162 0.199 0.099 0.067 0.301 0.142]
 [0.204 0.103 0.069 0.227 0.121 0.177 0.092 0.068 0.178 0.103]
 [0.193 0.093 0.11  0.112 0.098 0.175 0.087 0.089 0.126 0.093]
 [0.    0.    0.081 0.    0.03  0.    0.    0.071 0.    0.027]]
-------------------------------------------------------------
std_dev/mean [percentage]:
[[ 43.  13.  10.  21.  13.  31.  10.   8.  12.  10.]
 [ 39.  11.  11.  13.  12.  34.  10.  10.  12.  11.]
 [ 36.  12.  11.  17.  13.  31.  10.   9.  11.  10.]
 [129.  19.  14. 118.  31. 101.  17.  10.  88.  26.]
 [ 54.  15.   9.  40.  18.  45.  13.   9.  29.  15.]
 [108.  16.  17.  21.  17.  75.  14.  14.  23.  15.]
 [  0.   0.  13.   0.   8.   0.   0.  12.   0.   7.]]
-------------------------------------
Current folder: C:\Users\Javier\Dropbox\c_sldl_1_2_37_3
-------------------------------------
----- RESULTS ------
-------------------------------------
Window size (sec):  14.0
step (sec):  7.008
overlap:  True
perc. of overlap:  49.94285714285714
overlap duration (sec):  6.992
Number of windows / instances:  168
Elapsed time: 890.9439923763275 minutes
Elapsed time: 14.849066539605458 hours
