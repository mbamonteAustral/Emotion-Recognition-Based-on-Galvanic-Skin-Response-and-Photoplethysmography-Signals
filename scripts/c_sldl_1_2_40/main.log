2024-05-07 16:19:42.042930: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-05-07 16:19:45.799617: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-05-07 16:19:55.296152: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
    
    
-------------------------------
participant:  1
-------------------------------
    
    
participant:  1
corriendo en PC gamer:
Window size (sec):  15.0
step (sec):  7.5
overlap:  True
perc. of overlap:  50.0
overlap duration (sec):  7.5
['gsr_chunks', 'ppg_chunks', 'val_chunks', 'aro_chunks', 'time_chunks', 'tag_chunks', 'video']
C:\Users\Javier\Dropbox\c_sldl_1_2_40\functions.py:880: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!
You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.
A typical example is when you are setting values in a column of a DataFrame, like:

df["col"][row_indexer] = value

 loss: 0.0179 - mean_squared_error: 0.0179
[1m 80/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0180 - mean_squared_error: 0.0180
[1m 86/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0181 - mean_squared_error: 0.0181
[1m 92/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0181 - mean_squared_error: 0.0181
[1m 98/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0181 - mean_squared_error: 0.0181
[1m104/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 11ms/step - loss: 0.0181 - mean_squared_error: 0.0181
[1m110/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 11ms/step - loss: 0.0181 - mean_squared_error: 0.0181
[1m113/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 11ms/step - loss: 0.0181 - mean_squared_error: 0.0181 - val_loss: 0.0198 - val_mean_squared_error: 0.0198
Epoch 4/5

[1m  1/113[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 31ms/step - loss: 0.0057 - mean_squared_error: 0.0057
[1m  6/113[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - loss: 0.0073 - mean_squared_error: 0.0073
[1m 12/113[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - loss: 0.0116 - mean_squared_error: 0.0116
[1m 17/113[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 11ms/step - loss: 0.0134 - mean_squared_error: 0.0134
[1m 23/113[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0137 - mean_squared_error: 0.0137
[1m 29/113[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0135 - mean_squared_error: 0.0135
[1m 34/113[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0133 - mean_squared_error: 0.0133
[1m 39/113[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0134 - mean_squared_error: 0.0134
[1m 45/113[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0134 - mean_squared_error: 0.0134
[1m 51/113[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0135 - mean_squared_error: 0.0135
[1m 57/113[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0139 - mean_squared_error: 0.0139
[1m 62/113[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0141 - mean_squared_error: 0.0141
[1m 67/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0142 - mean_squared_error: 0.0142
[1m 73/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0142 - mean_squared_error: 0.0142
[1m 79/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0143 - mean_squared_error: 0.0143
[1m 85/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0146 - mean_squared_error: 0.0146
[1m 90/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0147 - mean_squared_error: 0.0147
[1m 95/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0149 - mean_squared_error: 0.0149
[1m101/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0151 - mean_squared_error: 0.0151
[1m107/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 11ms/step - loss: 0.0152 - mean_squared_error: 0.0152
[1m113/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 11ms/step - loss: 0.0153 - mean_squared_error: 0.0153
[1m113/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 11ms/step - loss: 0.0153 - mean_squared_error: 0.0153 - val_loss: 0.0190 - val_mean_squared_error: 0.0190
Epoch 5/5

[1m  1/113[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 32ms/step - loss: 0.0032 - mean_squared_error: 0.0032
[1m  6/113[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 12ms/step - loss: 0.0042 - mean_squared_error: 0.0042
[1m 12/113[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 11ms/step - loss: 0.0068 - mean_squared_error: 0.0068
[1m 18/113[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 11ms/step - loss: 0.0084 - mean_squared_error: 0.0084
[1m 24/113[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0096 - mean_squared_error: 0.0096
[1m 30/113[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0111 - mean_squared_error: 0.0111
[1m 36/113[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0119 - mean_squared_error: 0.0119
[1m 41/113[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0122 - mean_squared_error: 0.0122
[1m 47/113[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0124 - mean_squared_error: 0.0124
[1m 53/113[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0126 - mean_squared_error: 0.0126
[1m 58/113[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0126 - mean_squared_error: 0.0126
[1m 64/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0127 - mean_squared_error: 0.0127
[1m 70/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0127 - mean_squared_error: 0.0127
[1m 76/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0128 - mean_squared_error: 0.0128
[1m 82/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0130 - mean_squared_error: 0.0130
[1m 88/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0130 - mean_squared_error: 0.0130
[1m 94/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0131 - mean_squared_error: 0.0131
[1m100/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0133 - mean_squared_error: 0.0133
[1m106/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 11ms/step - loss: 0.0134 - mean_squared_error: 0.0134
[1m112/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 11ms/step - loss: 0.0136 - mean_squared_error: 0.0136
[1m113/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 11ms/step - loss: 0.0136 - mean_squared_error: 0.0136 - val_loss: 0.0184 - val_mean_squared_error: 0.0184
(15008, 1, 5)
Model: "sequential_1197"
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer (type)                    â”‚ Output Shape           â”‚       Param # â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1stConvL (Conv1D)               â”‚ (None, 15008, 5)       â”‚           105 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1stPoolL (AveragePooling1D)     â”‚ (None, 3752, 5)        â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2ndConvL (Conv1D)               â”‚ (None, 3752, 6)        â”‚           306 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2ndPoolL (AveragePooling1D)     â”‚ (None, 938, 6)         â”‚             0 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 2,209 (8.63 KB)
 Trainable params: 411 (1.61 KB)
 Non-trainable params: 0 (0.00 B)
 Optimizer params: 1,798 (7.03 KB)
Model: "valence_NN"
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer (type)        â”‚ Output Shape      â”‚    Param # â”‚ Connected to      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ inputGSR            â”‚ (None, 15008, 1)  â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ inputPPG            â”‚ (None, 15008, 1)  â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ sequential_1196     â”‚ (None, 938, 6)    â”‚        411 â”‚ inputGSR[0][0]    â”‚
â”‚ (Sequential)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ sequential_1197     â”‚ (None, 938, 6)    â”‚        411 â”‚ inputPPG[0][0]    â”‚
â”‚ (Sequential)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ concatenate_598     â”‚ (None, 938, 12)   â”‚          0 â”‚ sequential_1196[â€¦ â”‚
â”‚ (Concatenate)       â”‚                   â”‚            â”‚ sequential_1197[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ permute_598         â”‚ (None, 12, 938)   â”‚          0 â”‚ concatenate_598[â€¦ â”‚
â”‚ (Permute)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ flatten_598         â”‚ (None, 11256)     â”‚          0 â”‚ permute_598[0][0] â”‚
â”‚ (Flatten)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout_598         â”‚ (None, 11256)     â”‚          0 â”‚ flatten_598[0][0] â”‚
â”‚ (Dropout)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_598 (Dense)   â”‚ (None, 1)         â”‚     11,257 â”‚ dropout_598[0][0] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 12,079 (47.18 KB)
 Trainable params: 12,079 (47.18 KB)
 Non-trainable params: 0 (0.00 B)
Epoch 1/10

[1m  1/113[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2:27[0m 1s/step - binary_accuracy: 1.0000 - loss: 0.5948
[1m  6/113[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 13ms/step - binary_accuracy: 0.7111 - loss: 0.6008
[1m 12/113[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 11ms/step - binary_accuracy: 0.6150 - loss: 0.6408
[1m 17/113[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 11ms/step - binary_accuracy: 0.5836 - loss: 0.6558
[1m 24/113[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.5694 - loss: 0.6622
[1m 30/113[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.5791 - loss: 0.6529
[1m 36/113[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.5821 - loss: 0.6635
[1m 42/113[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.5828 - loss: 0.6774
[1m 47/113[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.5813 - loss: 0.6875
[1m 53/113[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.5802 - loss: 0.6964
[1m 59/113[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.5779 - loss: 0.7031
[1m 66/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.5760 - loss: 0.7078
[1m 71/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.5773 - loss: 0.7082
[1m 77/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.5797 - loss: 0.7078
[1m 83/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.5813 - loss: 0.7096
[1m 89/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.5838 - loss: 0.7105
[1m 96/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.5880 - loss: 0.7098
[1m102/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.5911 - loss: 0.7095
[1m108/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.5937 - loss: 0.7101
[1m113/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m3s[0m 12ms/step - binary_accuracy: 0.5959 - loss: 0.7106 - val_binary_accuracy: 0.6154 - val_loss: 0.5996
Epoch 2/10

[1m  1/113[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 31ms/step - binary_accuracy: 1.0000 - loss: 0.4103
[1m  6/113[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 13ms/step - binary_accuracy: 1.0000 - loss: 0.4872
[1m 12/113[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 11ms/step - binary_accuracy: 1.0000 - loss: 0.4557
[1m 17/113[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 11ms/step - binary_accuracy: 0.9615 - loss: 0.4731
[1m 22/113[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 11ms/step - binary_accuracy: 0.9252 - loss: 0.4931
[1m 29/113[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.8800 - loss: 0.5168
[1m 35/113[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.8470 - loss: 0.5362
[1m 41/113[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.8163 - loss: 0.5535
[1m 47/113[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.7891 - loss: 0.5683
[1m 54/113[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7627 - loss: 0.5821
[1m 60/113[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7441 - loss: 0.5913
[1m 66/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7311 - loss: 0.5972
[1m 72/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7213 - loss: 0.6015
[1m 79/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7130 - loss: 0.6046
[1m 85/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7073 - loss: 0.6069
[1m 91/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7029 - loss: 0.6083
[1m 97/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6994 - loss: 0.6095
[1m104/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6960 - loss: 0.6106
[1m110/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6933 - loss: 0.6120
[1m113/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 11ms/step - binary_accuracy: 0.6919 - loss: 0.6127 - val_binary_accuracy: 0.6154 - val_loss: 0.5993
Epoch 3/10

[1m  1/113[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 32ms/step - binary_accuracy: 1.0000 - loss: 0.2994
[1m  8/113[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.9844 - loss: 0.3367 
[1m 14/113[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.9228 - loss: 0.3858
[1m 20/113[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.8692 - loss: 0.4372
[1m 27/113[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.8267 - loss: 0.4744
[1m 32/113[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.8028 - loss: 0.4935
[1m 38/113[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7828 - loss: 0.5105
[1m 43/113[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7689 - loss: 0.5207
[1m 50/113[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7590 - loss: 0.5288
[1m 56/113[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7518 - loss: 0.5353
[1m 61/113[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7458 - loss: 0.5408
[1m 67/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7380 - loss: 0.5465
[1m 73/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7323 - loss: 0.5503
[1m 79/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7287 - loss: 0.5527
[1m 85/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7244 - loss: 0.5558
[1m 91/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7193 - loss: 0.5600
[1m 97/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7144 - loss: 0.5644
[1m104/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7099 - loss: 0.5688
[1m110/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7070 - loss: 0.5718
[1m113/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 10ms/step - binary_accuracy: 0.7055 - loss: 0.5734 - val_binary_accuracy: 0.6154 - val_loss: 0.5948
Epoch 4/10

[1m  1/113[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 32ms/step - binary_accuracy: 1.0000 - loss: 0.6236
[1m  7/113[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - binary_accuracy: 0.7793 - loss: 0.6979
[1m 14/113[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7017 - loss: 0.7289
[1m 19/113[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6902 - loss: 0.7188
[1m 26/113[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6701 - loss: 0.7083
[1m 32/113[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6546 - loss: 0.7013
[1m 38/113[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6491 - loss: 0.6935
[1m 44/113[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6476 - loss: 0.6847
[1m 50/113[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6482 - loss: 0.6773
[1m 56/113[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6512 - loss: 0.6696
[1m 62/113[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6549 - loss: 0.6625
[1m 68/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6595 - loss: 0.6548
[1m 75/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6648 - loss: 0.6475
[1m 81/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6698 - loss: 0.6402
[1m 87/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6742 - loss: 0.6346
[1m 93/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6780 - loss: 0.6297
[1m100/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6802 - loss: 0.6276
[1m105/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6814 - loss: 0.6267
[1m112/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6825 - loss: 0.6262
[1m113/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 10ms/step - binary_accuracy: 0.6829 - loss: 0.6260 - val_binary_accuracy: 0.6923 - val_loss: 0.6201
Epoch 5/10

[1m  1/113[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 32ms/step - binary_accuracy: 1.0000 - loss: 0.5849
[1m  8/113[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.8716 - loss: 0.5550 
[1m 14/113[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7319 - loss: 0.5972
[1m 20/113[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6860 - loss: 0.6036
[1m 27/113[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6804 - loss: 0.5961
[1m 33/113[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6830 - loss: 0.5892
[1m 40/113[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6796 - loss: 0.5875
[1m 46/113[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6780 - loss: 0.5854
[1m 51/113[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6739 - loss: 0.5858
[1m 57/113[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6690 - loss: 0.5875
[1m 63/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6656 - loss: 0.5885
[1m 69/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6618 - loss: 0.5895
[1m 75/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6601 - loss: 0.5898
[1m 80/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6597 - loss: 0.5897
[1m 86/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6592 - loss: 0.5895
[1m 91/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6591 - loss: 0.5894
[1m 97/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6587 - loss: 0.5896
[1m102/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6586 - loss: 0.5896
[1m106/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6585 - loss: 0.5895
[1m111/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6581 - loss: 0.5896
[1m113/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 11ms/step - binary_accuracy: 0.6580 - loss: 0.5896 - val_binary_accuracy: 0.7692 - val_loss: 0.5689
Epoch 6/10

[1m  1/113[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 31ms/step - binary_accuracy: 1.0000 - loss: 0.2940
[1m  5/113[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 13ms/step - binary_accuracy: 0.7433 - loss: 0.5638
[1m 11/113[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 11ms/step - binary_accuracy: 0.7990 - loss: 0.5166
[1m 17/113[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 11ms/step - binary_accuracy: 0.7959 - loss: 0.5167
[1m 23/113[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.7905 - loss: 0.5107
[1m 29/113[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.7856 - loss: 0.5028
[1m 35/113[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7757 - loss: 0.4999
[1m 41/113[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7724 - loss: 0.5001
[1m 46/113[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7724 - loss: 0.4998
[1m 53/113[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7682 - loss: 0.5038
[1m 59/113[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7651 - loss: 0.5069
[1m 65/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7612 - loss: 0.5114
[1m 70/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7587 - loss: 0.5143
[1m 76/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7573 - loss: 0.5161
[1m 82/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7565 - loss: 0.5170
[1m 89/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7548 - loss: 0.5181
[1m 94/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7531 - loss: 0.5196
[1m100/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7519 - loss: 0.5206
[1m106/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7506 - loss: 0.5222
[1m112/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7497 - loss: 0.5236
[1m113/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 11ms/step - binary_accuracy: 0.7494 - loss: 0.5239 - val_binary_accuracy: 0.7692 - val_loss: 0.5674
Epoch 7/10

[1m  1/113[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 31ms/step - binary_accuracy: 0.0000e+00 - loss: 0.7609
[1m  7/113[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - binary_accuracy: 0.2459 - loss: 0.7734    
[1m 13/113[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 11ms/step - binary_accuracy: 0.4525 - loss: 0.6623
[1m 19/113[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.5392 - loss: 0.6152
[1m 25/113[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.5806 - loss: 0.6075
[1m 32/113[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6099 - loss: 0.6062
[1m 38/113[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6293 - loss: 0.6025
[1m 43/113[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6395 - loss: 0.6014
[1m 49/113[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6477 - loss: 0.6014
[1m 55/113[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6549 - loss: 0.6009
[1m 61/113[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6622 - loss: 0.5992
[1m 67/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6702 - loss: 0.5959
[1m 73/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6787 - loss: 0.5911
[1m 78/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6846 - loss: 0.5879
[1m 85/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6903 - loss: 0.5846
[1m 91/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6941 - loss: 0.5825
[1m 97/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6972 - loss: 0.5804
[1m103/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6998 - loss: 0.5785
[1m110/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7029 - loss: 0.5757
[1m113/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 11ms/step - binary_accuracy: 0.7046 - loss: 0.5741 - val_binary_accuracy: 0.6923 - val_loss: 0.5927
Epoch 8/10

[1m  1/113[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 31ms/step - binary_accuracy: 1.0000 - loss: 0.6239
[1m  7/113[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - binary_accuracy: 0.9272 - loss: 0.4156
[1m 13/113[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 11ms/step - binary_accuracy: 0.8581 - loss: 0.4758
[1m 20/113[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.8202 - loss: 0.4989
[1m 25/113[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.8022 - loss: 0.5084
[1m 32/113[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7860 - loss: 0.5111
[1m 38/113[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7805 - loss: 0.5094
[1m 43/113[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7805 - loss: 0.5056
[1m 49/113[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7810 - loss: 0.5016
[1m 56/113[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7791 - loss: 0.4984
[1m 62/113[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7782 - loss: 0.4962
[1m 69/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7776 - loss: 0.4945
[1m 74/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7777 - loss: 0.4934
[1m 79/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7771 - loss: 0.4934
[1m 86/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7769 - loss: 0.4931
[1m 92/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7767 - loss: 0.4931
[1m 98/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7761 - loss: 0.4936
[1m104/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7756 - loss: 0.4942
[1m110/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7750 - loss: 0.4951
[1m113/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 10ms/step - binary_accuracy: 0.7746 - loss: 0.4954 - val_binary_accuracy: 0.7692 - val_loss: 0.5688
Epoch 9/10

[1m  1/113[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 31ms/step - binary_accuracy: 1.0000 - loss: 0.3834
[1m  7/113[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - binary_accuracy: 0.9272 - loss: 0.3124
[1m 13/113[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - binary_accuracy: 0.9033 - loss: 0.3084
[1m 19/113[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.8758 - loss: 0.3315
[1m 25/113[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.8577 - loss: 0.3465
[1m 31/113[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.8436 - loss: 0.3603
[1m 37/113[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.8266 - loss: 0.3768
[1m 43/113[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.8169 - loss: 0.3896
[1m 49/113[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.8129 - loss: 0.3984
[1m 56/113[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.8124 - loss: 0.4042
[1m 62/113[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.8105 - loss: 0.4100
[1m 68/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.8097 - loss: 0.4142
[1m 75/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.8089 - loss: 0.4185
[1m 81/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.8083 - loss: 0.4222
[1m 87/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.8062 - loss: 0.4269
[1m 93/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.8039 - loss: 0.4308
[1m 99/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.8017 - loss: 0.4344
[1m106/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.8000 - loss: 0.4376
[1m112/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7992 - loss: 0.4395
[1m113/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 11ms/step - binary_accuracy: 0.7990 - loss: 0.4400 - val_binary_accuracy: 0.7692 - val_loss: 0.5554
Epoch 10/10

[1m  1/113[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 31ms/step - binary_accuracy: 1.0000 - loss: 0.3370
[1m  8/113[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.8664 - loss: 0.4659 
[1m 13/113[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.8407 - loss: 0.4452
[1m 18/113[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.8294 - loss: 0.4276
[1m 24/113[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.8124 - loss: 0.4180
[1m 30/113[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.8026 - loss: 0.4160
[1m 37/113[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7964 - loss: 0.4183
[1m 42/113[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7915 - loss: 0.4201
[1m 47/113[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7876 - loss: 0.4227
[1m 54/113[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7832 - loss: 0.4255
[1m 60/113[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7808 - loss: 0.4282
[1m 66/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7800 - loss: 0.4299
[1m 72/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7789 - loss: 0.4317
[1m 78/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7779 - loss: 0.4332
[1m 84/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7780 - loss: 0.4335
[1m 90/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7791 - loss: 0.4326
[1m 97/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7802 - loss: 0.4318
[1m102/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7810 - loss: 0.4312
[1m108/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7816 - loss: 0.4309
[1m113/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 11ms/step - binary_accuracy: 0.7821 - loss: 0.4307 - val_binary_accuracy: 0.6923 - val_loss: 0.5274

[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 110ms/step
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 110ms/step
predicted [0.9357073  0.19919679 0.00873756 0.8545696  0.05952572 0.73943955
 0.17244267 0.8986582  0.8777446  0.48395756 0.02031288 0.9005393
 0.08603223 0.88261044 0.07746454 0.00700596 0.21942483 0.34090525
 0.70164657 0.71861523 0.87300795 0.827109   0.06949061 0.88872284
 0.24465194 0.86014456 0.05928829 0.91976047 0.7846606  0.9389207
 0.7746418  0.90008235]
predicted [1 0 0 1 0 1 0 1 1 0 0 1 0 1 0 0 0 0 1 1 1 1 0 1 0 1 0 1 1 1 1 1]
expected [ True  True False  True False  True  True False False  True False  True
 False  True  True False False  True  True  True False False False False
  True  True  True  True  True False  True  True]
accuracy: 0.59375
confusion matrix: 
[[ 7  6]
 [ 7 12]]
              precision    recall  f1-score   support

       False       0.50      0.54      0.52        13
        True       0.67      0.63      0.65        19

    accuracy                           0.59        32
   macro avg       0.58      0.59      0.58        32
weighted avg       0.60      0.59      0.60        32

macro avg f1-score: 0.5835835835835836
macro avg (UAR): 0.5850202429149798
Sensitivity:  0.5384615384615384
Specificity:  0.631578947368421
g-mean:  0.5831646179767074
-------- Model Performance ----------: 
accuracy:  [0.625   0.65625 0.6875  0.625   0.6875  0.5     0.65625 0.65625 0.59375
 0.     ]
gmean:  [0.60697698 0.52469386 0.6234292  0.60697698 0.58662557 0.49286406
 0.64888568 0.60363273 0.58316462 0.        ]
f1_score:  [0.61133603 0.58830409 0.65367965 0.61133603 0.63636364 0.49206349
 0.64764765 0.62672322 0.58358358 0.        ]
UAR:  [0.61133603 0.60121457 0.65182186 0.61133603 0.63967611 0.49392713
 0.64979757 0.62550607 0.58502024 0.        ]
Cohen Kappa score:  [ 0.22267206  0.22123894  0.31914894  0.22267206  0.30131004 -0.01185771
  0.296       0.2605042   0.168       0.        ]
Split Repetition number:  9
StratifiedShuffleSplit(n_splits=1, random_state=None, test_size=0.2,
            train_size=None)
TRAIN: [ 85  73 107  50  86  72 112   8  46  18 124  11  43  93  69 115 148  56
 155 102  51   1 144  23 128 138 152  13  63  98  49  48 134  19  76  65
  39 146  67  68 121  74  44  29 109 149  90  52  96   2  59  58  66  71
  97 127  88 154 106  70  82   0 117  92 129  26 141  89 116  55 101  94
  33  40  60  91 142 139  37 113  77  20 156  32 153   7 103 114 108 135
  25  45  99  17  36  27  95  78 130  24  14  64   3  80  57   6 105  16
  81  30 131 140  12 125  62 111  21  31  47  75  34 150 137 110  28 123] TEST: [ 10 147   5 157 118 120 143 104 122 145 100  61  41  79 133  53  87 126
 151 136  35  42   4 132  38  84  15  54  83  22   9 119]
(DL) TRAIN number of instances:  126
(DL) TEST number of instances:  32
(DL) Total number of instances (TRAIN+TEST):  158
C:\Users\Javier\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\keras\src\layers\convolutional\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(
----- train_GSR_AE -------
Model: "sequential_1198"
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer (type)                    â”‚ Output Shape           â”‚       Param # â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1stConvL (Conv1D)               â”‚ (None, 15008, 5)       â”‚           105 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1stPoolL (AveragePooling1D)     â”‚ (None, 3752, 5)        â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2ndConvL (Conv1D)               â”‚ (None, 3752, 6)        â”‚           306 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2ndPoolL (AveragePooling1D)     â”‚ (None, 938, 6)         â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling1d_2396              â”‚ (None, 3752, 6)        â”‚             0 â”‚
â”‚ (UpSampling1D)                  â”‚                        â”‚               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv1d_transpose_2396           â”‚ (None, 3752, 6)        â”‚           366 â”‚
â”‚ (Conv1DTranspose)               â”‚                        â”‚               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling1d_2397              â”‚ (None, 15008, 6)       â”‚             0 â”‚
â”‚ (UpSampling1D)                  â”‚                        â”‚               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv1d_transpose_2397           â”‚ (None, 15008, 1)       â”‚           121 â”‚
â”‚ (Conv1DTranspose)               â”‚                        â”‚               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 898 (3.51 KB)
 Trainable params: 898 (3.51 KB)
 Non-trainable params: 0 (0.00 B)
Epoch 1/5

[1m  1/113[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2:02[0m 1s/step - loss: 32.5467 - mean_squared_error: 32.5467
[1m  6/113[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 12ms/step - loss: 23.5709 - mean_squared_error: 23.5709
[1m 11/113[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 13ms/step - loss: 21.5576 - mean_squared_error: 21.5576
[1m 16/113[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 12ms/step - loss: 19.5333 - mean_squared_error: 19.5333
[1m 21/113[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 12ms/step - loss: 18.0468 - mean_squared_error: 18.0468
[1m 27/113[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 16.7313 - mean_squared_error: 16.7313
[1m 33/113[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 15.8355 - mean_squared_error: 15.8355
[1m 38/113[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 15.2126 - mean_squared_error: 15.2126
[1m 43/113[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 14.6988 - mean_squared_error: 14.6988
[1m 48/113[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 14.3480 - mean_squared_error: 14.3480
[1m 54/113[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 14.0095 - mean_squared_error: 14.0095
[1m 59/113[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 13.8495 - mean_squared_error: 13.8495
[1m 65/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 13.6387 - mean_squared_error: 13.6387
[1m 70/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 13.4500 - mean_squared_error: 13.4500
[1m 77/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 13.1906 - mean_squared_error: 13.1906
[1m 82/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 13.0078 - mean_squared_error: 13.0078
[1m 88/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 12.8854 - mean_squared_error: 12.8854
[1m 94/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 11ms/step - loss: 12.8093 - mean_squared_error: 12.8093
[1m100/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 11ms/step - loss: 12.7434 - mean_squared_error: 12.7434
[1m105/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 11ms/step - loss: 12.6886 - mean_squared_error: 12.6886
[1m111/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 11ms/step - loss: 12.6198 - mean_squared_error: 12.6198
[1m113/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m3s[0m 13ms/step - loss: 12.5889 - mean_squared_error: 12.5889 - val_loss: 14.3822 - val_mean_squared_error: 14.3822
Epoch 2/5

[1m  1/113[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 32ms/step - loss: 28.6498 - mean_squared_error: 28.6498
[1m  7/113[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - loss: 16.4591 - mean_squared_error: 16.4591
[1m 12/113[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 11ms/step - loss: 14.0236 - mean_squared_error: 14.0236
[1m 17/113[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 11ms/step - loss: 12.7454 - mean_squared_error: 12.7454
[1m 22/113[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 11ms/step - loss: 11.9223 - mean_squared_error: 11.9223
[1m 28/113[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 12.0471 - mean_squared_error: 12.0471
[1m 34/113[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 12.2967 - mean_squared_error: 12.2967
[1m 40/113[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 12.3278 - mean_squared_error: 12.3278
[1m 45/113[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 12.2519 - mean_squared_error: 12.2519
[1m 51/113[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 12.1557 - mean_squared_error: 12.1557
[1m 57/113[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 12.0448 - mean_squared_error: 12.0448
[1m 63/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 11.9290 - mean_squared_error: 11.9290
[1m 69/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 11.8518 - mean_squared_error: 11.8518
[1m 75/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 11.7756 - mean_squared_error: 11.7756
[1m 80/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 11.7175 - mean_squared_error: 11.7175
[1m 86/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 11.6661 - mean_squared_error: 11.6661
[1m 91/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 11ms/step - loss: 11.6357 - mean_squared_error: 11.6357
[1m 96/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 11ms/step - loss: 11.6123 - mean_squared_error: 11.6123
[1m102/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 11ms/step - loss: 11.5740 - mean_squared_error: 11.5740
[1m108/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 11ms/step - loss: 11.5360 - mean_squared_error: 11.5360
[1m113/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 11ms/step - loss: 11.4957 - mean_squared_error: 11.4957 - val_loss: 14.3709 - val_mean_squared_error: 14.3709
Epoch 3/5

[1m  1/113[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 32ms/step - loss: 11.8920 - mean_squared_error: 11.8920
[1m  6/113[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 13ms/step - loss: 8.6013 - mean_squared_error: 8.6013  
[1m 12/113[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 11ms/step - loss: 8.1396 - mean_squared_error: 8.1396
[1m 18/113[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 11ms/step - loss: 8.5696 - mean_squared_error: 8.5696
[1m 23/113[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 11ms/step - loss: 9.0891 - mean_squared_error: 9.0891
[1m 29/113[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 9.4383 - mean_squared_error: 9.4383
[1m 35/113[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 9.6265 - mean_squared_error: 9.6265
[1m 41/113[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 9.6065 - mean_squared_error: 9.6065
[1m 46/113[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 9.5274 - mean_squared_error: 9.5274
[1m 51/113[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 9.4401 - mean_squared_error: 9.4401
[1m 57/113[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 9.3246 - mean_squared_error: 9.3246
[1m 63/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 9.2729 - mean_squared_error: 9.2729
[1m 69/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 9.2081 - mean_squared_error: 9.2081
[1m 74/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 9.1915 - mean_squared_error: 9.1915
[1m 80/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 9.1441 - mean_squared_error: 9.1441
[1m 86/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 9.1571 - mean_squared_error: 9.1571
[1m 92/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 11ms/step - loss: 9.1998 - mean_squared_error: 9.1998
[1m 97/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 11ms/step - loss: 9.2364 - mean_squared_error: 9.2364
[1m103/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 11ms/step - loss: 9.3100 - mean_squared_error: 9.3100
[1m109/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 11ms/step - loss: 9.3833 - mean_squared_error: 9.3833
[1m113/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 11ms/step - loss: 9.4406 - mean_squared_error: 9.4406 - val_loss: 14.3679 - val_mean_squared_error: 14.3679
Epoch 4/5

[1m  1/113[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 32ms/step - loss: 5.3135 - mean_squared_error: 5.3135
[1m  7/113[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - loss: 9.4587 - mean_squared_error: 9.4587
[1m 13/113[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - loss: 11.5775 - mean_squared_error: 11.5775
[1m 19/113[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 12.0108 - mean_squared_error: 12.0108
[1m 25/113[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 12.1402 - mean_squared_error: 12.1402
[1m 31/113[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 12.2619 - mean_squared_error: 12.2619
[1m 37/113[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 12.0712 - mean_squared_error: 12.0712
[1m 42/113[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 11.9113 - mean_squared_error: 11.9113
[1m 48/113[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 11.7274 - mean_squared_error: 11.7274
[1m 54/113[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 11.5015 - mean_squared_error: 11.5015
[1m 59/113[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 11.3252 - mean_squared_error: 11.3252
[1m 65/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 11.1962 - mean_squared_error: 11.1962
[1m 71/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 11.1200 - mean_squared_error: 11.1200
[1m 77/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 11.0750 - mean_squared_error: 11.0750
[1m 83/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 11.0340 - mean_squared_error: 11.0340
[1m 89/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 11.0158 - mean_squared_error: 11.0158
[1m 94/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 11ms/step - loss: 11.0251 - mean_squared_error: 11.0251
[1m 99/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 11ms/step - loss: 11.0193 - mean_squared_error: 11.0193
[1m104/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 11ms/step - loss: 11.0085 - mean_squared_error: 11.0085
[1m109/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 11ms/step - loss: 11.0034 - mean_squared_error: 11.0034
[1m113/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 11ms/step - loss: 10.9920 - mean_squared_error: 10.9920 - val_loss: 14.3667 - val_mean_squared_error: 14.3667
Epoch 5/5

[1m  1/113[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 32ms/step - loss: 5.5786 - mean_squared_error: 5.5786
[1m  7/113[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - loss: 15.1354 - mean_squared_error: 15.1354
[1m 13/113[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - loss: 14.2164 - mean_squared_error: 14.2164
[1m 19/113[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 13.5479 - mean_squared_error: 13.5479
[1m 25/113[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 13.3192 - mean_squared_error: 13.3192
[1m 31/113[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 13.0774 - mean_squared_error: 13.0774
[1m 37/113[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 12.7832 - mean_squared_error: 12.7832
[1m 43/113[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 12.6112 - mean_squared_error: 12.6112
[1m 49/113[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 12.3972 - mean_squared_error: 12.3972
[1m 55/113[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 12.1638 - mean_squared_error: 12.1638
[1m 61/113[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 11.9411 - mean_squared_error: 11.9411
[1m 67/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 11.8275 - mean_squared_error: 11.8275
[1m 73/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 11.6997 - mean_squared_error: 11.6997
[1m 79/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 11.5613 - mean_squared_error: 11.5613
[1m 85/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 11.4154 - mean_squared_error: 11.4154
[1m 91/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 10ms/step - loss: 11.2787 - mean_squared_error: 11.2787
[1m 97/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 10ms/step - loss: 11.1833 - mean_squared_error: 11.1833
[1m102/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 10ms/step - loss: 11.1246 - mean_squared_error: 11.1246
[1m108/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 10ms/step - loss: 11.0639 - mean_squared_error: 11.0639
[1m113/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 11ms/step - loss: 11.0252 - mean_squared_error: 11.0252 - val_loss: 14.3676 - val_mean_squared_error: 14.3676
(126, 938, 6)
Model: "sequential_1198"
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer (type)                    â”‚ Output Shape           â”‚       Param # â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1stConvL (Conv1D)               â”‚ (None, 15008, 5)       â”‚           105 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1stPoolL (AveragePooling1D)     â”‚ (None, 3752, 5)        â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2ndConvL (Conv1D)               â”‚ (None, 3752, 6)        â”‚           306 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2ndPoolL (AveragePooling1D)     â”‚ (None, 938, 6)         â”‚             0 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 2,209 (8.63 KB)
 Trainable params: 411 (1.61 KB)
 Non-trainable params: 0 (0.00 B)
 Optimizer params: 1,798 (7.03 KB)
----- train_PPG_AE -------
Model: "sequential_1199"
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer (type)                    â”‚ Output Shape           â”‚       Param # â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1stConvL (Conv1D)               â”‚ (None, 15008, 5)       â”‚           105 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1stPoolL (AveragePooling1D)     â”‚ (None, 3752, 5)        â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2ndConvL (Conv1D)               â”‚ (None, 3752, 6)        â”‚           306 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2ndPoolL (AveragePooling1D)     â”‚ (None, 938, 6)         â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling1d_2398              â”‚ (None, 3752, 6)        â”‚             0 â”‚
â”‚ (UpSampling1D)                  â”‚                        â”‚               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv1d_transpose_2398           â”‚ (None, 3752, 6)        â”‚           366 â”‚
â”‚ (Conv1DTranspose)               â”‚                        â”‚               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling1d_2399              â”‚ (None, 15008, 6)       â”‚             0 â”‚
â”‚ (UpSampling1D)                  â”‚                        â”‚               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv1d_transpose_2399           â”‚ (None, 15008, 1)       â”‚           121 â”‚
â”‚ (Conv1DTranspose)               â”‚                        â”‚               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 898 (3.51 KB)
 Trainable params: 898 (3.51 KB)
 Non-trainable params: 0 (0.00 B)
Epoch 1/5

[1m  1/113[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2:04[0m 1s/step - loss: 0.2509 - mean_squared_error: 0.2509
[1m  6/113[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 12ms/step - loss: 0.1463 - mean_squared_error: 0.1463
[1m 12/113[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 11ms/step - loss: 0.1080 - mean_squared_error: 0.1080
[1m 17/113[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 12ms/step - loss: 0.0943 - mean_squared_error: 0.0943
[1m 23/113[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 11ms/step - loss: 0.0845 - mean_squared_error: 0.0845
[1m 29/113[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0779 - mean_squared_error: 0.0779
[1m 34/113[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0735 - mean_squared_error: 0.0735
[1m 39/113[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0699 - mean_squared_error: 0.0699
[1m 45/113[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0663 - mean_squared_error: 0.0663
[1m 51/113[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0633 - mean_squared_error: 0.0633
[1m 57/113[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0609 - mean_squared_error: 0.0609
[1m 62/113[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0591 - mean_squared_error: 0.0591
[1m 68/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0572 - mean_squared_error: 0.0572
[1m 74/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0556 - mean_squared_error: 0.0556
[1m 80/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0540 - mean_squared_error: 0.0540
[1m 86/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0526 - mean_squared_error: 0.0526
[1m 92/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0514 - mean_squared_error: 0.0514
[1m 98/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0502 - mean_squared_error: 0.0502
[1m103/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 11ms/step - loss: 0.0493 - mean_squared_error: 0.0493
[1m108/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 11ms/step - loss: 0.0485 - mean_squared_error: 0.0485
[1m113/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 11ms/step - loss: 0.0477 - mean_squared_error: 0.0477
[1m113/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m3s[0m 13ms/step - loss: 0.0475 - mean_squared_error: 0.0475 - val_loss: 0.0116 - val_mean_squared_error: 0.0116
Epoch 2/5

[1m  1/113[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 32ms/step - loss: 0.0052 - mean_squared_error: 0.0052
[1m  7/113[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - loss: 0.0074 - mean_squared_error: 0.0074
[1m 13/113[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - loss: 0.0146 - mean_squared_error: 0.0146
[1m 18/113[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 11ms/step - loss: 0.0177 - mean_squared_error: 0.0177
[1m 24/113[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0193 - mean_squared_error: 0.0193
[1m 30/113[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0198 - mean_squared_error: 0.0198
[1m 36/113[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0198 - mean_squared_error: 0.0198
[1m 42/113[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0198 - mean_squared_error: 0.0198
[1m 48/113[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0197 - mean_squared_error: 0.0197
[1m 53/113[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0196 - mean_squared_error: 0.0196
[1m 59/113[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0197 - mean_squared_error: 0.0197
[1m 64/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0197 - mean_squared_error: 0.0197
[1m 70/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0198 - mean_squared_error: 0.0198
[1m 75/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0199 - mean_squared_error: 0.0199
[1m 81/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0200 - mean_squared_error: 0.0200
[1m 87/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0201 - mean_squared_error: 0.0201
[1m 93/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0202 - mean_squared_error: 0.0202
[1m 99/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0202 - mean_squared_error: 0.0202
[1m105/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 11ms/step - loss: 0.0202 - mean_squared_error: 0.0202
[1m110/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 11ms/step - loss: 0.0202 - mean_squared_error: 0.0202
[1m113/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 11ms/step - loss: 0.0203 - mean_squared_error: 0.0203 - val_loss: 0.0119 - val_mean_squared_error: 0.0119
Epoch 3/5

[1m  1/113[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 31ms/step - loss: 0.0060 - mean_squared_error: 0.0060
[1m  6/113[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 12ms/step - loss: 0.0115 - mean_squared_error: 0.0115
[1m 12/113[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 11ms/step - loss: 0.0115 - mean_squared_error: 0.0115
[1m 17/113[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 12ms/step - loss: 0.0107 - mean_squared_error: 0.0107
[1m 22/113[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 12ms/step - loss: 0.0103 - mean_squared_error: 0.0103
[1m 28/113[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - loss: 0.0098 - mean_squared_error: 0.0098
[1m 33/113[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - loss: 0.0102 - mean_squared_error: 0.0102
[1m 39/113[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - loss: 0.0108 - mean_squared_error: 0.0108
[1m 45/113[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0112 - mean_squared_error: 0.0112
[1m 51/113[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0116 - mean_squared_error: 0.0116
[1m 57/113[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0119 - mean_squared_error: 0.0119
[1m 63/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0122 - mean_squared_error: 0.0122
[1m 69/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0124 - mean_squared_error: 0.0124
[1m 74/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0127 - mean_squared_error: 0.0127
[1m 80/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0130 - mean_squared_error: 0.0130
[1m 85/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0132 - mean_squared_error: 0.0132
[1m 91/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0135 - mean_squared_error: 0.0135
[1m 97/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0137 - mean_squared_error: 0.0137
[1m102/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 11ms/step - loss: 0.0140 - mean_squared_error: 0.0140
[1m108/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 11ms/step - loss: 0.0142 - mean_squared_error: 0.0142
[1m113/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 11ms/step - loss: 0.0144 - mean_squared_error: 0.0144
[1m113/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 12ms/step - loss: 0.0145 - mean_squared_error: 0.0145 - val_loss: 0.0102 - val_mean_squared_error: 0.0102
Epoch 4/5

[1m  1/113[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 31ms/step - loss: 0.0043 - mean_squared_error: 0.0043
[1m  7/113[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - loss: 0.0152 - mean_squared_error: 0.0152
[1m 13/113[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - loss: 0.0153 - mean_squared_error: 0.0153
[1m 19/113[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0165 - mean_squared_error: 0.0165
[1m 25/113[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0165 - mean_squared_error: 0.0165
[1m 31/113[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0162 - mean_squared_error: 0.0162
[1m 36/113[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0160 - mean_squared_error: 0.0160
[1m 41/113[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0160 - mean_squared_error: 0.0160
[1m 47/113[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0160 - mean_squared_error: 0.0160
[1m 53/113[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0162 - mean_squared_error: 0.0162
[1m 59/113[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0163 - mean_squared_error: 0.0163
[1m 64/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0163 - mean_squared_error: 0.0163
[1m 70/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0164 - mean_squared_error: 0.0164
[1m 75/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0165 - mean_squared_error: 0.0165
[1m 81/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0166 - mean_squared_error: 0.0166
[1m 86/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0167 - mean_squared_error: 0.0167
[1m 92/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0169 - mean_squared_error: 0.0169
[1m 98/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0171 - mean_squared_error: 0.0171
[1m104/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 11ms/step - loss: 0.0173 - mean_squared_error: 0.0173
[1m110/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 11ms/step - loss: 0.0174 - mean_squared_error: 0.0174
[1m113/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 11ms/step - loss: 0.0175 - mean_squared_error: 0.0175 - val_loss: 0.0116 - val_mean_squared_error: 0.0116
Epoch 5/5

[1m  1/113[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 32ms/step - loss: 0.0075 - mean_squared_error: 0.0075
[1m  7/113[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - loss: 0.0111 - mean_squared_error: 0.0111
[1m 13/113[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - loss: 0.0099 - mean_squared_error: 0.0099
[1m 19/113[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0097 - mean_squared_error: 0.0097
[1m 25/113[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 0.0099 - mean_squared_error: 0.0099
[1m 30/113[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0103 - mean_squared_error: 0.0103
[1m 36/113[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0107 - mean_squared_error: 0.0107
[1m 42/113[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0112 - mean_squared_error: 0.0112
[1m 48/113[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0115 - mean_squared_error: 0.0115
[1m 54/113[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0119 - mean_squared_error: 0.0119
[1m 60/113[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0126 - mean_squared_error: 0.0126
[1m 66/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0132 - mean_squared_error: 0.0132
[1m 72/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0138 - mean_squared_error: 0.0138
[1m 78/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0142 - mean_squared_error: 0.0142
[1m 84/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0145 - mean_squared_error: 0.0145
[1m 90/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0148 - mean_squared_error: 0.0148
[1m 96/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0150 - mean_squared_error: 0.0150
[1m101/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 11ms/step - loss: 0.0151 - mean_squared_error: 0.0151
[1m107/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 11ms/step - loss: 0.0153 - mean_squared_error: 0.0153
[1m112/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 11ms/step - loss: 0.0154 - mean_squared_error: 0.0154
[1m113/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 11ms/step - loss: 0.0155 - mean_squared_error: 0.0155 - val_loss: 0.0113 - val_mean_squared_error: 0.0113
(15008, 1, 5)
Model: "sequential_1199"
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer (type)                    â”‚ Output Shape           â”‚       Param # â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1stConvL (Conv1D)               â”‚ (None, 15008, 5)       â”‚           105 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1stPoolL (AveragePooling1D)     â”‚ (None, 3752, 5)        â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2ndConvL (Conv1D)               â”‚ (None, 3752, 6)        â”‚           306 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2ndPoolL (AveragePooling1D)     â”‚ (None, 938, 6)         â”‚             0 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 2,209 (8.63 KB)
 Trainable params: 411 (1.61 KB)
 Non-trainable params: 0 (0.00 B)
 Optimizer params: 1,798 (7.03 KB)
Model: "valence_NN"
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer (type)        â”‚ Output Shape      â”‚    Param # â”‚ Connected to      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ inputGSR            â”‚ (None, 15008, 1)  â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ inputPPG            â”‚ (None, 15008, 1)  â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ sequential_1198     â”‚ (None, 938, 6)    â”‚        411 â”‚ inputGSR[0][0]    â”‚
â”‚ (Sequential)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ sequential_1199     â”‚ (None, 938, 6)    â”‚        411 â”‚ inputPPG[0][0]    â”‚
â”‚ (Sequential)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ concatenate_599     â”‚ (None, 938, 12)   â”‚          0 â”‚ sequential_1198[â€¦ â”‚
â”‚ (Concatenate)       â”‚                   â”‚            â”‚ sequential_1199[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ permute_599         â”‚ (None, 12, 938)   â”‚          0 â”‚ concatenate_599[â€¦ â”‚
â”‚ (Permute)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ flatten_599         â”‚ (None, 11256)     â”‚          0 â”‚ permute_599[0][0] â”‚
â”‚ (Flatten)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout_599         â”‚ (None, 11256)     â”‚          0 â”‚ flatten_599[0][0] â”‚
â”‚ (Dropout)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_599 (Dense)   â”‚ (None, 1)         â”‚     11,257 â”‚ dropout_599[0][0] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 12,079 (47.18 KB)
 Trainable params: 12,079 (47.18 KB)
 Non-trainable params: 0 (0.00 B)
Epoch 1/10

[1m  1/113[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2:53[0m 2s/step - binary_accuracy: 0.0000e+00 - loss: 0.7226
[1m  7/113[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - binary_accuracy: 0.4088 - loss: 0.7044    
[1m 12/113[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 11ms/step - binary_accuracy: 0.4051 - loss: 0.7415
[1m 17/113[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 11ms/step - binary_accuracy: 0.4192 - loss: 0.7503
[1m 24/113[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.4394 - loss: 0.7439
[1m 30/113[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.4639 - loss: 0.7351
[1m 36/113[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.4837 - loss: 0.7288
[1m 43/113[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.4986 - loss: 0.7257
[1m 49/113[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.5108 - loss: 0.7210
[1m 56/113[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.5248 - loss: 0.7135
[1m 62/113[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.5352 - loss: 0.7066
[1m 68/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.5452 - loss: 0.6988
[1m 74/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.5554 - loss: 0.6900
[1m 80/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.5646 - loss: 0.6832
[1m 87/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.5742 - loss: 0.6761
[1m 93/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.5805 - loss: 0.6726
[1m 99/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.5861 - loss: 0.6699
[1m105/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.5911 - loss: 0.6678
[1m111/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.5947 - loss: 0.6662
[1m113/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m3s[0m 12ms/step - binary_accuracy: 0.5960 - loss: 0.6657 - val_binary_accuracy: 0.5385 - val_loss: 0.6499
Epoch 2/10

[1m  1/113[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 31ms/step - binary_accuracy: 1.0000 - loss: 0.4732
[1m  7/113[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - binary_accuracy: 0.7724 - loss: 0.5635
[1m 12/113[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 11ms/step - binary_accuracy: 0.8247 - loss: 0.5048
[1m 18/113[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 11ms/step - binary_accuracy: 0.8341 - loss: 0.4894
[1m 23/113[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 11ms/step - binary_accuracy: 0.8330 - loss: 0.4883
[1m 28/113[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.8353 - loss: 0.4788
[1m 34/113[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.8392 - loss: 0.4679
[1m 40/113[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.8400 - loss: 0.4689
[1m 46/113[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.8399 - loss: 0.4704
[1m 51/113[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.8384 - loss: 0.4739
[1m 56/113[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.8370 - loss: 0.4777
[1m 61/113[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.8342 - loss: 0.4815
[1m 68/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.8280 - loss: 0.4900
[1m 73/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.8225 - loss: 0.4963
[1m 79/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.8140 - loss: 0.5038
[1m 85/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.8064 - loss: 0.5106
[1m 92/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.7983 - loss: 0.5181
[1m 98/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.7932 - loss: 0.5234
[1m104/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.7878 - loss: 0.5284
[1m110/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.7823 - loss: 0.5331
[1m113/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 11ms/step - binary_accuracy: 0.7789 - loss: 0.5359 - val_binary_accuracy: 0.6154 - val_loss: 0.6606
Epoch 3/10

[1m  1/113[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 31ms/step - binary_accuracy: 1.0000 - loss: 0.5467
[1m  8/113[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.9509 - loss: 0.4953 
[1m 14/113[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.8957 - loss: 0.5272
[1m 20/113[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.8815 - loss: 0.5255
[1m 26/113[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.8636 - loss: 0.5254
[1m 33/113[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.8450 - loss: 0.5381
[1m 39/113[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.8310 - loss: 0.5468
[1m 45/113[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.8164 - loss: 0.5570
[1m 51/113[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.8049 - loss: 0.5641
[1m 56/113[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7972 - loss: 0.5685
[1m 63/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7890 - loss: 0.5730
[1m 69/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7836 - loss: 0.5766
[1m 76/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7772 - loss: 0.5810
[1m 82/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7728 - loss: 0.5844
[1m 88/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7697 - loss: 0.5866
[1m 94/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7668 - loss: 0.5883
[1m 99/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7650 - loss: 0.5892
[1m105/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7628 - loss: 0.5905
[1m110/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7608 - loss: 0.5920
[1m113/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 11ms/step - binary_accuracy: 0.7593 - loss: 0.5931 - val_binary_accuracy: 0.5385 - val_loss: 0.7403
Epoch 4/10

[1m  1/113[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 31ms/step - binary_accuracy: 1.0000 - loss: 0.1871
[1m  8/113[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.8738 - loss: 0.4295 
[1m 14/113[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7617 - loss: 0.5573
[1m 20/113[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7160 - loss: 0.6009
[1m 26/113[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6948 - loss: 0.6196
[1m 31/113[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6827 - loss: 0.6272
[1m 38/113[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6780 - loss: 0.6295
[1m 44/113[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6758 - loss: 0.6304
[1m 50/113[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6747 - loss: 0.6317
[1m 56/113[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6758 - loss: 0.6310
[1m 61/113[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6788 - loss: 0.6285
[1m 67/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6839 - loss: 0.6233
[1m 73/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6877 - loss: 0.6189
[1m 79/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6911 - loss: 0.6154
[1m 84/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6927 - loss: 0.6145
[1m 90/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6933 - loss: 0.6144
[1m 95/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6940 - loss: 0.6142
[1m101/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6944 - loss: 0.6137
[1m108/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.6946 - loss: 0.6133
[1m113/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 11ms/step - binary_accuracy: 0.6947 - loss: 0.6130 - val_binary_accuracy: 0.6154 - val_loss: 0.7055
Epoch 5/10

[1m  1/113[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 31ms/step - binary_accuracy: 1.0000 - loss: 0.4598
[1m  6/113[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 13ms/step - binary_accuracy: 1.0000 - loss: 0.5715
[1m 12/113[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 11ms/step - binary_accuracy: 0.9456 - loss: 0.5955
[1m 18/113[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 11ms/step - binary_accuracy: 0.9284 - loss: 0.5841
[1m 25/113[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.9178 - loss: 0.5619
[1m 31/113[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.9000 - loss: 0.5584
[1m 37/113[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.8795 - loss: 0.5654
[1m 43/113[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.8636 - loss: 0.5700
[1m 49/113[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.8492 - loss: 0.5730
[1m 56/113[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.8337 - loss: 0.5753
[1m 62/113[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.8235 - loss: 0.5762
[1m 68/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.8139 - loss: 0.5780
[1m 74/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.8060 - loss: 0.5799
[1m 80/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7986 - loss: 0.5811
[1m 86/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7904 - loss: 0.5831
[1m 92/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7821 - loss: 0.5850
[1m 98/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7747 - loss: 0.5864
[1m104/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7686 - loss: 0.5878
[1m110/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7640 - loss: 0.5883
[1m113/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 11ms/step - binary_accuracy: 0.7613 - loss: 0.5884 - val_binary_accuracy: 0.5385 - val_loss: 0.7659
Epoch 6/10

[1m  1/113[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 32ms/step - binary_accuracy: 1.0000 - loss: 0.1514
[1m  7/113[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - binary_accuracy: 1.0000 - loss: 0.1777
[1m 13/113[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - binary_accuracy: 0.9193 - loss: 0.2956
[1m 19/113[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.8684 - loss: 0.3512
[1m 26/113[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.8433 - loss: 0.3865
[1m 32/113[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.8272 - loss: 0.4106
[1m 37/113[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.8105 - loss: 0.4369
[1m 43/113[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7979 - loss: 0.4575
[1m 49/113[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7866 - loss: 0.4733
[1m 56/113[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7786 - loss: 0.4863
[1m 62/113[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7756 - loss: 0.4933
[1m 68/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7745 - loss: 0.4978
[1m 75/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7735 - loss: 0.5011
[1m 80/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7733 - loss: 0.5023
[1m 85/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7736 - loss: 0.5029
[1m 90/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.7729 - loss: 0.5049
[1m 95/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.7718 - loss: 0.5074
[1m 99/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.7707 - loss: 0.5098
[1m104/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.7693 - loss: 0.5125
[1m110/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.7671 - loss: 0.5156
[1m113/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 11ms/step - binary_accuracy: 0.7655 - loss: 0.5176 - val_binary_accuracy: 0.5385 - val_loss: 0.7050
Epoch 7/10

[1m  1/113[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 31ms/step - binary_accuracy: 1.0000 - loss: 0.4694
[1m  7/113[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - binary_accuracy: 1.0000 - loss: 0.4780
[1m 13/113[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.9748 - loss: 0.4810
[1m 18/113[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.9234 - loss: 0.4898
[1m 24/113[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.8940 - loss: 0.4902
[1m 30/113[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.8573 - loss: 0.5045
[1m 36/113[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.8312 - loss: 0.5195
[1m 41/113[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.8173 - loss: 0.5269
[1m 47/113[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.8081 - loss: 0.5312
[1m 53/113[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.8015 - loss: 0.5322
[1m 59/113[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7962 - loss: 0.5323
[1m 65/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7911 - loss: 0.5320
[1m 71/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7870 - loss: 0.5316
[1m 76/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7832 - loss: 0.5316
[1m 81/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7802 - loss: 0.5313
[1m 87/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7781 - loss: 0.5304
[1m 92/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.7756 - loss: 0.5304
[1m 98/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7725 - loss: 0.5303
[1m104/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.7694 - loss: 0.5309
[1m111/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7665 - loss: 0.5317
[1m113/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 11ms/step - binary_accuracy: 0.7654 - loss: 0.5321 - val_binary_accuracy: 0.5385 - val_loss: 0.7234
Epoch 8/10

[1m  1/113[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 32ms/step - binary_accuracy: 1.0000 - loss: 0.3920
[1m  7/113[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - binary_accuracy: 0.7354 - loss: 0.4291
[1m 13/113[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - binary_accuracy: 0.7548 - loss: 0.4367
[1m 19/113[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7529 - loss: 0.4715
[1m 24/113[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7569 - loss: 0.4775
[1m 31/113[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7657 - loss: 0.4810
[1m 37/113[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7754 - loss: 0.4806
[1m 44/113[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7823 - loss: 0.4797
[1m 49/113[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7838 - loss: 0.4808
[1m 55/113[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7824 - loss: 0.4836
[1m 61/113[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7833 - loss: 0.4848
[1m 67/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7831 - loss: 0.4874
[1m 74/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7823 - loss: 0.4914
[1m 80/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7815 - loss: 0.4948
[1m 87/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7808 - loss: 0.4989
[1m 93/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7799 - loss: 0.5025
[1m 99/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7795 - loss: 0.5055
[1m106/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7796 - loss: 0.5079
[1m112/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7802 - loss: 0.5091
[1m113/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 10ms/step - binary_accuracy: 0.7803 - loss: 0.5094 - val_binary_accuracy: 0.5385 - val_loss: 0.7267
Epoch 9/10

[1m  1/113[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 32ms/step - binary_accuracy: 1.0000 - loss: 0.0785
[1m  8/113[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.9665 - loss: 0.2510 
[1m 14/113[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.8981 - loss: 0.3462
[1m 20/113[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.8421 - loss: 0.4218
[1m 26/113[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.8147 - loss: 0.4512
[1m 33/113[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7873 - loss: 0.4725
[1m 39/113[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7716 - loss: 0.4892
[1m 45/113[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7638 - loss: 0.4971
[1m 49/113[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7603 - loss: 0.5004
[1m 55/113[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7546 - loss: 0.5071
[1m 62/113[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7493 - loss: 0.5139
[1m 68/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7442 - loss: 0.5198
[1m 74/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7408 - loss: 0.5243
[1m 79/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7391 - loss: 0.5267
[1m 85/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7387 - loss: 0.5277
[1m 91/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7393 - loss: 0.5277
[1m 98/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7403 - loss: 0.5273
[1m104/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7404 - loss: 0.5274
[1m109/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7401 - loss: 0.5277
[1m113/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 10ms/step - binary_accuracy: 0.7392 - loss: 0.5284 - val_binary_accuracy: 0.5385 - val_loss: 0.7109
Epoch 10/10

[1m  1/113[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 32ms/step - binary_accuracy: 1.0000 - loss: 0.3838
[1m  7/113[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - binary_accuracy: 0.8439 - loss: 0.5145
[1m 13/113[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 10ms/step - binary_accuracy: 0.8378 - loss: 0.5083
[1m 19/113[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.8189 - loss: 0.5194
[1m 24/113[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.8094 - loss: 0.5185
[1m 30/113[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7955 - loss: 0.5180
[1m 37/113[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7841 - loss: 0.5225
[1m 43/113[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7758 - loss: 0.5268
[1m 48/113[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7706 - loss: 0.5294
[1m 54/113[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7666 - loss: 0.5302
[1m 61/113[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7618 - loss: 0.5325
[1m 67/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7583 - loss: 0.5338
[1m 73/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7560 - loss: 0.5353
[1m 80/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7546 - loss: 0.5362
[1m 85/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7548 - loss: 0.5363
[1m 92/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7551 - loss: 0.5361
[1m 98/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7560 - loss: 0.5354
[1m105/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7577 - loss: 0.5338
[1m111/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7591 - loss: 0.5323
[1m113/113[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 11ms/step - binary_accuracy: 0.7597 - loss: 0.5316 - val_binary_accuracy: 0.6154 - val_loss: 0.6881

[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 109ms/step
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 109ms/step
predicted [0.65789974 0.30210337 0.8831742  0.15575561 0.7045518  0.7771918
 0.20213094 0.65565807 0.7066808  0.56521356 0.25888875 0.83879054
 0.8523904  0.7693045  0.281766   0.8345562  0.6614301  0.77444404
 0.3749721  0.3211685  0.8493854  0.85815704 0.5592333  0.6895488
 0.79169965 0.76771575 0.86877227 0.7789207  0.55294985 0.8405972
 0.7888232  0.58557904]
predicted [1 0 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1]
expected [False False  True False  True  True False  True  True False  True  True
  True  True False  True  True  True False False False  True False  True
  True  True False  True  True False False  True]
accuracy: 0.75
confusion matrix: 
[[ 6  7]
 [ 1 18]]
              precision    recall  f1-score   support

       False       0.86      0.46      0.60        13
        True       0.72      0.95      0.82        19

    accuracy                           0.75        32
   macro avg       0.79      0.70      0.71        32
weighted avg       0.78      0.75      0.73        32

macro avg f1-score: 0.7090909090909091
macro avg (UAR): 0.7044534412955465
Sensitivity:  0.46153846153846156
Specificity:  0.9473684210526315
g-mean:  0.6612465225335805
-------- Model Performance ----------: 
accuracy:  [0.625   0.65625 0.6875  0.625   0.6875  0.5     0.65625 0.65625 0.59375
 0.75   ]
gmean:  [0.60697698 0.52469386 0.6234292  0.60697698 0.58662557 0.49286406
 0.64888568 0.60363273 0.58316462 0.66124652]
f1_score:  [0.61133603 0.58830409 0.65367965 0.61133603 0.63636364 0.49206349
 0.64764765 0.62672322 0.58358358 0.70909091]
UAR:  [0.61133603 0.60121457 0.65182186 0.61133603 0.63967611 0.49392713
 0.64979757 0.62550607 0.58502024 0.70445344]
Cohen Kappa score:  [ 0.22267206  0.22123894  0.31914894  0.22267206  0.30131004 -0.01185771
  0.296       0.2605042   0.168       0.44104803]
arousal and valece = ok
------------- Evaluating model --------------
-------------------------------------
-------------------------------------
participant:  30
-------------------------------------
----- RESULTS ------
-------------------------------------
Window size (sec):  15.008
step (sec):  7.504
overlap:  True
perc. of overlap:  50.0
overlap duration (sec):  7.504
Number of windows / instances:  158
-rows: alg : KNN = 0; DT = 1; RF = 2; SVM = 3; GBM = 4; BDDAE = 5; DUMMY = 5
columns:
'val_cohen','val_uar', 'val_acc', 'val_gm',  'val_f1',  'aro_cohen','aro_uar', 'aro_acc', 'aro_gm',  'aro_f1'
-------------------------------------------------------------
  v_c   v_u   v_a   v_g   v_f1  a_c   a_u   a_a   a_g   a_f1
[[ 0.803  0.906  0.904  0.903  0.901  0.538  0.765  0.796  0.752  0.767]
 [ 0.577  0.772  0.798  0.743  0.772  0.557  0.766  0.797  0.74   0.77 ]
 [ 0.668  0.883  0.885  0.884  0.88   0.612  0.735  0.772  0.725  0.739]
 [ 0.781  0.884  0.898  0.878  0.89   0.     0.5    0.671  0.     0.401]
 [ 0.622  0.79   0.803  0.788  0.786  0.401  0.68   0.766  0.607  0.682]
 [ 0.244  0.617  0.644  0.594  0.616 -0.001  0.498  0.634  0.187  0.437]
 [ 0.     0.5    0.607  0.     0.378  0.     0.5    0.671  0.     0.401]]
last participant performance loaded in numpy array
    
    
-------------------------------
LAST participant's saved data: 
30
-------------------------------
    
    
Saving performance metrics in csv files...
Performance metrics already saved in csv files
---------------------------
KNN performance:
[[0.54004004 0.76815476 0.77208333 0.76466096 0.76931797 0.3875913
  0.67916667 0.80375    0.59009629 0.68315432]
 [0.53758586 0.77529762 0.76625    0.7629626  0.76296478 0.49965565
  0.74365079 0.77208333 0.70778738 0.73875389]
 [0.54394721 0.76436508 0.78666667 0.74200284 0.76594134 0.51352311
  0.75426587 0.75958333 0.74390563 0.75336129]
 [0.41248125 0.70327381 0.71       0.69044022 0.70175232 0.24554196
  0.61242424 0.70875    0.52809576 0.60863278]
 [0.5881746  0.78111111 0.81625    0.75923009 0.78943218 0.61665399
  0.80714286 0.81041667 0.79784026 0.80528892]
 [0.51871988 0.76041667 0.75833333 0.74915213 0.75453094 0.64780049
  0.82539683 0.82375    0.81233657 0.81923192]
 [0.3201438  0.65634921 0.68458333 0.63560688 0.65654872 0.34941957
  0.67420635 0.67875    0.65522741 0.6673674 ]
 [0.83672953 0.91181818 0.93041667 0.90492301 0.91710924 0.63558152
  0.82015873 0.82333333 0.81723773 0.81663245]
 [0.25958328 0.61939394 0.70208333 0.57415371 0.62345083 0.24029883
  0.61818182 0.68375    0.55302082 0.61522241]
 [0.40699788 0.70446429 0.70291667 0.68368457 0.69375566 0.35426237
  0.675      0.6825     0.66081159 0.67158095]
 [0.236459   0.61666667 0.6375     0.59935587 0.61325501 0.43726072
  0.71428571 0.73375    0.6889693  0.71048057]
 [0.69063185 0.84190476 0.86083333 0.82156859 0.84105127 0.60720547
  0.79222222 0.8225     0.77597645 0.80030645]
 [0.63753981 0.81880952 0.82416667 0.8136482  0.8177892  0.30722859
  0.64984127 0.66333333 0.63754876 0.64966969]
 [0.20842572 0.60757576 0.65791667 0.55368627 0.59262467 0.42525295
  0.71289683 0.71416667 0.69524604 0.70504256]
 [0.37628034 0.68181818 0.74125    0.65139833 0.68498463 0.38090637
  0.69060606 0.72208333 0.66545659 0.68542914]
 [0.39895249 0.69547619 0.72083333 0.6786156  0.69638486 0.4842773
  0.73636364 0.77708333 0.70817345 0.73748187]
 [0.53012051 0.76539683 0.77208333 0.75353655 0.7607881  0.34423188
  0.66555556 0.69666667 0.62843304 0.66163587]
 [0.1315758  0.55723443 0.835      0.24969272 0.55347901 0.41378271
  0.70984127 0.71541667 0.7032885  0.70430049]
 [0.57643333 0.79181818 0.81833333 0.77743302 0.78652864 0.43669075
  0.71934524 0.72125    0.70964246 0.71484253]
 [0.37461205 0.67742424 0.74666667 0.60639108 0.67617552 0.3434514
  0.66833333 0.715      0.60546897 0.66312436]
 [0.17659156 0.58108974 0.71375    0.49290616 0.58171524 0.07763227
  0.53819444 0.545      0.51940084 0.53192352]
 [0.40854656 0.70585317 0.70375    0.68677028 0.69582841 0.37249692
  0.68651515 0.72666667 0.61951775 0.67419904]
 [0.40183011 0.70079365 0.70916667 0.68141162 0.69406933 0.35398601
  0.66507576 0.78583333 0.564296   0.6645297 ]
 [0.26478887 0.63392857 0.63416667 0.60906661 0.62107364 0.52925112
  0.75912698 0.77166667 0.74881265 0.76244173]
 [0.51908542 0.75634921 0.76541667 0.74604626 0.75619507 0.66148352
  0.83154762 0.83041667 0.82149207 0.82705447]
 [0.40671159 0.70009921 0.70875    0.67243162 0.69184704 0.45342791
  0.72480159 0.73291667 0.71834641 0.72490308]
 [0.5932485  0.79340909 0.82916667 0.78484159 0.7956081  0.50438312
  0.75178571 0.75291667 0.74259734 0.74895078]
 [0.26146475 0.63       0.64458333 0.61792726 0.62553227 0.55254244
  0.77674603 0.77958333 0.76998703 0.77247861]
 [0.11654644 0.55222222 0.61291667 0.47824424 0.54160781 0.26298547
  0.6296627  0.64041667 0.61011627 0.62499356]
 [0.80307143 0.90563492 0.90375    0.90308587 0.90059428 0.53819758
  0.76484848 0.79625    0.75152742 0.76663789]]
KNN mean:
[0.43591065 0.71527164 0.74898611 0.68149582 0.71206454 0.43256678
 0.71323966 0.73965278 0.68502189 0.71032174]
---------------------------
---------------------------
DT performance:
[[ 0.63126272  0.82361111  0.82208333  0.7946301   0.81939705  0.34553225
   0.69583333  0.7925      0.57411927  0.69688597]
 [ 0.60468188  0.78988095  0.79125     0.79001922  0.78665107  0.55540244
   0.79365079  0.80416667  0.76076025  0.79193236]
 [ 0.55802322  0.77936508  0.79208333  0.76492055  0.7825766   0.37713134
   0.72996032  0.735       0.67998555  0.72677043]
 [ 0.29013325  0.63105159  0.63375     0.63984983  0.62446763  0.23308387
   0.61356061  0.69458333  0.48180037  0.61079733]
 [ 0.66247607  0.81833333  0.8225      0.80882517  0.81145682  0.6073385
   0.81230159  0.81041667  0.78905915  0.80758361]
 [ 0.46529866  0.72003968  0.72041667  0.71284365  0.71694807  0.59721396
   0.78650794  0.78541667  0.75157801  0.7784847 ]
 [ 0.27673165  0.63912698  0.64666667  0.6225078   0.63223396  0.3367507
   0.66021825  0.66416667  0.66622493  0.65624341]
 [ 0.81413255  0.89727273  0.91125     0.88267676  0.89727623  0.52393253
   0.75920635  0.75958333  0.73231529  0.74745368]
 [ 0.16942004  0.6194697   0.69041667  0.52020142  0.61314913  0.30369598
   0.66454545  0.70166667  0.67949012  0.64991703]
 [ 0.38010942  0.70357143  0.70333333  0.6736275   0.69962885  0.33805439
   0.67579365  0.67625     0.67600483  0.66672429]
 [ 0.19279438  0.61388889  0.63333333  0.59497991  0.6096587   0.59388338
   0.79944444  0.80458333  0.79623562  0.79396106]
 [ 0.60198674  0.7702381   0.7825      0.75591006  0.76405073  0.47380673
   0.74111111  0.75125     0.7512296   0.73870886]
 [ 0.58269446  0.80198413  0.80958333  0.7788823   0.80258555  0.22603235
   0.61785714  0.62583333  0.58338048  0.61325081]
 [ 0.17246262  0.62954545  0.66333333  0.56236731  0.61929916  0.45054903
   0.72738095  0.72708333  0.68882897  0.72321825]
 [ 0.45948375  0.73181818  0.76541667  0.73122088  0.73122175  0.22697281
   0.60984848  0.62        0.5779921   0.58326783]
 [ 0.22224083  0.63301587  0.65791667  0.57856797  0.61721999  0.48166096
   0.74530303  0.77208333  0.7474831   0.74315865]
 [ 0.63974532  0.82857143  0.82291667  0.81835092  0.81670415  0.56867756
   0.76833333  0.78        0.74821036  0.76974449]
 [ 0.24372529  0.62811355  0.81166667  0.33956776  0.60523891  0.48590104
   0.74063492  0.75333333  0.73982188  0.73871608]
 [ 0.60776129  0.79090909  0.81666667  0.78635513  0.78892729  0.54951509
   0.78105159  0.78375     0.75961571  0.77918603]
 [ 0.22043586  0.59015152  0.67208333  0.47600297  0.58260159  0.19650554
   0.62166667  0.66416667  0.55545646  0.62181097]
 [-0.01732553  0.45384615  0.62041667  0.31691067  0.45779008  0.20006457
   0.55873016  0.56416667  0.58866392  0.55406405]
 [ 0.33285398  0.67509921  0.67291667  0.65339744  0.67144841  0.31441109
   0.62651515  0.65333333  0.62483405  0.62117432]
 [ 0.23698764  0.62261905  0.63291667  0.66292523  0.62040529  0.27108667
   0.69265152  0.75916667  0.60371413  0.68489278]
 [ 0.32410331  0.68323413  0.67583333  0.6589033   0.67181454  0.54653031
   0.76815476  0.77208333  0.76213198  0.76063738]
 [ 0.52021229  0.74166667  0.745       0.72277869  0.735685    0.5938428
   0.75228175  0.75375     0.76159506  0.74642733]
 [ 0.29724623  0.65664683  0.65833333  0.64003764  0.65187739  0.40238829
   0.69355159  0.70083333  0.64483607  0.68921445]
 [ 0.51167576  0.76227273  0.7975      0.76733546  0.75718803  0.566361
   0.80803571  0.80916667  0.78249492  0.80582866]
 [ 0.15430676  0.56666667  0.59416667  0.5344539   0.56314516  0.4826479
   0.73134921  0.74583333  0.74183399  0.72700634]
 [ 0.32031238  0.64666667  0.65833333  0.66534668  0.63913512  0.22143533
   0.59603175  0.60083333  0.61723206  0.59479083]
 [ 0.57665368  0.77222222  0.7975      0.74346485  0.77233276  0.55656739
   0.76560606  0.79708333  0.74049718  0.7700535 ]]
DT mean:
[0.40175422 0.70069664 0.72740278 0.66659537 0.69540383 0.42089919
 0.71123725 0.72873611 0.68691418 0.70639685]
---------------------------
---------------------------
RF performance:
[[0.62646718 0.83779762 0.84166667 0.84406345 0.83794439 0.46487734
  0.7375     0.84291667 0.52232738 0.75228941]
 [0.65399324 0.82748016 0.82958333 0.78865343 0.82468469 0.5327488
  0.70039683 0.72166667 0.78264298 0.69372645]
 [0.47761495 0.69984127 0.72291667 0.77055172 0.70142458 0.44490636
  0.74494048 0.74708333 0.73082361 0.74381161]
 [0.60717777 0.72589286 0.72916667 0.68454241 0.72486391 0.17417584
  0.66204545 0.73916667 0.60167289 0.66529593]
 [0.59388633 0.79666667 0.82333333 0.74833203 0.79401105 0.59457796
  0.77212302 0.77333333 0.79095793 0.76725041]
 [0.62100818 0.7577381  0.75791667 0.7419951  0.75571008 0.56852548
  0.775      0.77291667 0.80614234 0.76726586]
 [0.29435256 0.70722222 0.72166667 0.69147646 0.70666873 0.44974816
  0.68720238 0.69041667 0.64002259 0.6835512 ]
 [0.88129181 0.94090909 0.95583333 0.93610354 0.9461955  0.6132293
  0.76642857 0.77791667 0.77653636 0.76606199]
 [0.29912965 0.62113636 0.69083333 0.59884239 0.61572658 0.37158792
  0.66818182 0.715      0.58694202 0.65859324]
 [0.31689189 0.71428571 0.71458333 0.73723539 0.70976641 0.38198519
  0.6844246  0.68916667 0.68920064 0.67741936]
 [0.29619085 0.67666667 0.70791667 0.587294   0.66949782 0.55101576
  0.80706349 0.82375    0.75532341 0.81165005]
 [0.66117984 0.83301587 0.83458333 0.83107604 0.8263456  0.55920047
  0.775      0.78958333 0.72612741 0.7747903 ]
 [0.5220508  0.79301587 0.79708333 0.76196612 0.78795957 0.28127872
  0.61642857 0.63208333 0.57168203 0.60852842]
 [0.14129553 0.57409091 0.63125    0.43628229 0.57116031 0.46161573
  0.70079365 0.70208333 0.64515102 0.69547993]
 [0.42153526 0.67181818 0.7275     0.6675874  0.67476291 0.3556806
  0.71106061 0.73583333 0.68089569 0.70334504]
 [0.24859885 0.69761905 0.71541667 0.72222475 0.6866225  0.52499776
  0.80227273 0.83541667 0.71620076 0.80351057]
 [0.67543569 0.85746032 0.86041667 0.86104714 0.85564309 0.55127304
  0.81198413 0.81666667 0.80353875 0.81023148]
 [0.35957912 0.67893773 0.86125    0.57410085 0.67525843 0.49668852
  0.76579365 0.78541667 0.78023194 0.76681837]
 [0.67941949 0.82454545 0.85416667 0.80629087 0.82578346 0.6432402
  0.8203373  0.82125    0.75341932 0.81955125]
 [0.3891424  0.69       0.74708333 0.63115056 0.68158234 0.26748751
  0.65166667 0.695      0.51813157 0.64476889]
 [0.1148482  0.56826923 0.75458333 0.17844571 0.55073352 0.007366
  0.40416667 0.405      0.47503197 0.398334  ]
 [0.37011278 0.7015873  0.7025     0.69579766 0.69771297 0.39034951
  0.73015152 0.7725     0.69742267 0.73277031]
 [0.42016731 0.64444444 0.65833333 0.65730226 0.63757363 0.47502859
  0.69227273 0.77291667 0.62979803 0.68551151]
 [0.35636348 0.6953373  0.69625    0.66420404 0.69180067 0.4385774
  0.73948413 0.74041667 0.765684   0.73251379]
 [0.42846121 0.72896825 0.7325     0.69952788 0.71943447 0.67969128
  0.8219246  0.82333333 0.77260107 0.82101236]
 [0.30240509 0.6171627  0.61833333 0.59366039 0.60334808 0.47992321
  0.77837302 0.79       0.75474084 0.78023277]
 [0.50601817 0.77681818 0.81       0.76994412 0.77234833 0.62017375
  0.78928571 0.79083333 0.78702078 0.78445801]
 [0.08981178 0.60277778 0.63208333 0.59410399 0.59904953 0.55736638
  0.73039683 0.75166667 0.68796522 0.73398493]
 [0.30335844 0.60111111 0.63375    0.62427226 0.59915494 0.31787293
  0.70882937 0.715      0.67766206 0.70803925]
 [0.66847838 0.88293651 0.88541667 0.88415001 0.87987366 0.61163277
  0.73530303 0.77166667 0.7246315  0.73863645]]
RF mean:
[0.44420887 0.72485176 0.75493056 0.69274081 0.72075472 0.46222742
 0.72636105 0.748      0.69501763 0.72431444]
---------------------------
---------------------------
SVM performance:
[[0.21056172 0.59980159 0.62583333 0.48520298 0.5570829  0.
  0.5        0.76       0.         0.43174603]
 [0.38009057 0.68571429 0.70208333 0.65598758 0.68024688 0.38994968
  0.68126984 0.73458333 0.58453964 0.66910048]
 [0.52418689 0.74619048 0.78541667 0.6979765  0.74728592 0.38843945
  0.69335317 0.69625    0.67930861 0.68824809]
 [0.33825592 0.66388889 0.67708333 0.58298583 0.64090527 0.
  0.5        0.72166667 0.         0.41900692]
 [0.56367275 0.76611111 0.80916667 0.73010335 0.77271389 0.5133308
  0.75515873 0.76041667 0.73902691 0.75098693]
 [0.31535304 0.65545635 0.66416667 0.58961409 0.62837922 0.58440963
  0.79375    0.79166667 0.78536986 0.78860924]
 [0.         0.5        0.60125    0.         0.37530769 0.31062255
  0.65228175 0.66541667 0.58902483 0.62957681]
 [0.74075182 0.86181818 0.89791667 0.83766008 0.86508282 0.40556762
  0.69611111 0.73375    0.64395075 0.68683795]
 [0.         0.5        0.70291667 0.         0.41265771 0.
  0.5        0.68333333 0.         0.40592593]
 [0.32857143 0.66428571 0.66458333 0.64197814 0.65402537 0.11346289
  0.5531746  0.58875    0.27423364 0.46398319]
 [0.         0.5        0.62       0.         0.38269231 0.22243728
  0.60039683 0.67083333 0.37906001 0.54880105]
 [0.24728584 0.60944444 0.69041667 0.43137729 0.57657183 0.01538462
  0.50666667 0.62       0.07745967 0.40576923]
 [0.2500368  0.61507937 0.65833333 0.52298147 0.5921576  0.
  0.5        0.57625    0.         0.36546154]
 [0.         0.5        0.65833333 0.         0.39680912 0.44656406
  0.7219246  0.72583333 0.70500339 0.7171558 ]
 [0.         0.5        0.68333333 0.         0.40592593 0.
  0.5        0.64583333 0.         0.39225071]
 [0.         0.5        0.60125    0.         0.37530769 0.
  0.5        0.65833333 0.         0.39680912]
 [0.         0.5        0.5825     0.         0.36792308 0.
  0.5        0.58875    0.         0.37038462]
 [0.         0.5        0.85458333 0.         0.46067323 0.11098401
  0.55031746 0.6275     0.251367   0.47695987]
 [0.         0.5        0.68333333 0.         0.40592593 0.
  0.5        0.55041667 0.         0.35489855]
 [0.         0.5        0.67083333 0.         0.40136752 0.
  0.5        0.63333333 0.         0.38769231]
 [0.         0.5        0.77875    0.         0.43765736 0.
  0.5        0.52541667 0.         0.34423188]
 [0.33113604 0.66656746 0.66541667 0.64122665 0.65416816 0.
  0.5        0.64583333 0.         0.39225071]
 [0.         0.5        0.57       0.         0.363      0.
  0.5        0.74041667 0.         0.42535613]
 [0.         0.5        0.53791667 0.         0.34956522 0.47357411
  0.72956349 0.75291667 0.68113336 0.71964314]
 [0.         0.5        0.57       0.         0.363      0.47794063
  0.73660714 0.74083333 0.71366173 0.73023933]
 [0.         0.5        0.53166667 0.         0.34689855 0.43840652
  0.7125     0.73208333 0.68878583 0.71217143]
 [0.26077392 0.605      0.76       0.40228439 0.58863268 0.59313154
  0.79642857 0.79708333 0.78817615 0.79368234]
 [0.         0.5        0.62       0.         0.38269231 0.39187377
  0.685      0.72875    0.62274315 0.67670619]
 [0.         0.5        0.62       0.         0.38269231 0.14632822
  0.56845238 0.60166667 0.41383808 0.51553391]
 [0.78069622 0.88404762 0.89833333 0.87834332 0.8895629  0.
  0.5        0.67083333 0.         0.40136752]]
SVM mean:
[0.17571243 0.58411352 0.67951389 0.26992406 0.51523038 0.20074691
 0.59776521 0.67895833 0.32055609 0.53537956]
---------------------------
---------------------------
GBM performance:
[[ 0.62487872  0.80833333  0.81666667  0.79580979  0.80881405  0.2640404
   0.62083333  0.81708333  0.32278327  0.60642491]
 [ 0.46524489  0.70763889  0.72291667  0.70466029  0.70565582  0.47837717
   0.71992063  0.76625     0.68844893  0.71791317]
 [ 0.54304025  0.75611111  0.79208333  0.71733566  0.76033787  0.40080867
   0.6781746   0.6825      0.64860478  0.66432918]
 [ 0.37222318  0.68501984  0.69166667  0.67641297  0.68066726  0.02516769
   0.48636364  0.70208333  0.05        0.41192002]
 [ 0.55801909  0.77111111  0.81583333  0.72702058  0.77438967  0.52631781
   0.76944444  0.77333333  0.75077876  0.76303971]
 [ 0.45741145  0.73125     0.72583333  0.71489225  0.72311501  0.57895569
   0.79494048  0.79833333  0.77064914  0.78583588]
 [ 0.29183674  0.64087302  0.68458333  0.58995859  0.63863855  0.38642124
   0.6859127   0.68958333  0.68944084  0.68046629]
 [ 0.86419793  0.92636364  0.94333333  0.92175627  0.93165004  0.60676014
   0.78857143  0.81083333  0.77472584  0.79309064]
 [ 0.20157352  0.59431818  0.74125     0.33970154  0.57945686  0.30170221
   0.63363636  0.74041667  0.43318735  0.61274555]
 [ 0.51879699  0.75357143  0.75291667  0.74161147  0.7478338   0.41033251
   0.70545635  0.71        0.67958754  0.69448133]
 [ 0.27976998  0.62166667  0.6825      0.55056087  0.61615263  0.64416664
   0.81190476  0.83625     0.78486523  0.81753695]
 [ 0.67361798  0.82912698  0.86083333  0.81761716  0.83827671  0.60418751
   0.79555556  0.81541667  0.7814197   0.80009241]
 [ 0.55485693  0.76920635  0.79083333  0.75675211  0.77180478  0.2512273
   0.62722222  0.65666667  0.57993695  0.61832454]
 [ 0.11024483  0.54757576  0.68333333  0.23762684  0.4920212   0.29496729
   0.64513889  0.65166667  0.61304138  0.63559122]
 [ 0.17002869  0.57590909  0.72083333  0.3186625   0.54311741  0.17819569
   0.58181818  0.67791667  0.37588475  0.54396778]
 [ 0.03470968  0.51380952  0.60208333  0.19415999  0.4355276   0.3912304
   0.66924242  0.75291667  0.60458499  0.66801821]
 [ 0.62218634  0.81269841  0.81666667  0.80434411  0.80852902  0.4205392
   0.70769841  0.74125     0.63765481  0.69998232]
 [ 0.11796009  0.54642857  0.86125     0.14142136  0.52882959  0.45692356
   0.71825397  0.75333333  0.68395798  0.71899075]
 [ 0.2482017   0.60909091  0.72208333  0.47822968  0.59986021  0.50286407
   0.74404762  0.76541667  0.70918965  0.74013015]
 [ 0.16973809  0.5719697   0.69        0.42577757  0.55633001  0.20181965
   0.58666667  0.68375     0.43237212  0.56086037]
 [ 0.00888889  0.50416667  0.7725      0.04787136  0.45165818  0.23150178
   0.6328373   0.63375     0.63194331  0.62969286]
 [ 0.38945819  0.69513889  0.69708333  0.68444779  0.69103042  0.35431332
   0.66878788  0.74625     0.53930215  0.65289866]
 [ 0.19713559  0.59404762  0.63291667  0.52185482  0.56915224 -0.01111111
   0.49583333  0.73416667  0.          0.42323972]
 [ 0.29838864  0.65654762  0.65791667  0.61710076  0.64559977  0.55511427
   0.7703373   0.77875     0.75528596  0.76233914]
 [ 0.33843275  0.66785714  0.69458333  0.62292016  0.66326983  0.55460985
   0.78333333  0.78541667  0.78474124  0.78257963]
 [ 0.40510288  0.70406746  0.71583333  0.66241609  0.69749766  0.5243354
   0.75694444  0.77125     0.75187354  0.76004638]
 [ 0.36506389  0.67613636  0.7725      0.58349154  0.67747995  0.65588803
   0.82142857  0.82208333  0.79974182  0.81996877]
 [ 0.05490602  0.52444444  0.60625     0.30579402  0.48899617  0.36569055
   0.68730159  0.72083333  0.6016303   0.67137349]
 [ 0.42827208  0.69666667  0.76041667  0.61347515  0.69442405  0.2994598
   0.65803571  0.67666667  0.60963648  0.65188045]
 [ 0.62201832  0.79        0.80291667  0.7879559   0.78600692  0.40061842
   0.67969697  0.76583333  0.60676725  0.68184586]]
GBM mean:
[0.36620681 0.67603818 0.74101389 0.57005464 0.66353744 0.39518084
 0.69084464 0.742      0.60306787 0.67898688]
---------------------------
---------------------------
BDDAE performance:
[[ 0.05602845  0.52764706  0.534375    0.50623933  0.52009852  0.03326748
   0.51458333  0.721875    0.20975677  0.48659036]
 [ 0.40843833  0.70714286  0.70625     0.70048451  0.70124251  0.5668701
   0.78481781  0.790625    0.77928692  0.78183965]
 [ 0.03454308  0.51680162  0.553125    0.45327099  0.50131505  0.04462256
   0.52235294  0.525       0.50189541  0.5132242 ]
 [ 0.05455915  0.52686275  0.534375    0.49273968  0.51376687  0.11862613
   0.55096618  0.709375    0.35433143  0.5317958 ]
 [ 0.44982116  0.72083333  0.746875    0.71023661  0.72340659  0.3625
   0.68125     0.68125     0.66958775  0.67572481]
 [ 0.52674144  0.75882353  0.76875     0.73940008  0.75712308 -0.18709618
   0.40666667  0.40625     0.3787995   0.39315088]
 [ 0.1414098   0.56842105  0.6         0.52886794  0.56046101  0.10202969
   0.55156863  0.553125    0.53007205  0.54119856]
 [ 0.39355848  0.68272727  0.7625      0.63927922  0.69044588  0.23317701
   0.61052632  0.65        0.55990899  0.60261814]
 [ 0.43305045  0.69363636  0.78125     0.64676945  0.71049057  0.44118733
   0.685       0.803125    0.59913162  0.70153003]
 [ 0.11875     0.559375    0.559375    0.54828412  0.55401698  0.22211399
   0.60960784  0.615625    0.59645664  0.60639106]
 [-0.0771532   0.46333333  0.525       0.38437612  0.45101211  0.39121377
   0.68684211  0.721875    0.64815846  0.68419406]
 [ 0.1626045   0.57833333  0.61875     0.54666134  0.57665991  0.39023264
   0.70083333  0.709375    0.69270748  0.69244625]
 [ 0.25931152  0.63015873  0.63125     0.62482695  0.62611754  0.23388918
   0.61626984  0.628125    0.5881431   0.60726954]
 [ 0.13063903  0.56471861  0.621875    0.52299248  0.56069506  0.33481435
   0.66784314  0.66875     0.66430207  0.66617185]
 [-0.02512211  0.48954545  0.609375    0.32248684  0.46457284  0.31599052
   0.65454545  0.7         0.62977757  0.6546994 ]
 [ 0.20146335  0.6         0.61875     0.57711533  0.59418328  0.17687179
   0.57597403  0.690625    0.40431619  0.54902304]
 [ 0.55757299  0.78785425  0.78125     0.77564279  0.77395396  0.16459226
   0.5708502   0.61875     0.49179843  0.5543014 ]
 [ 0.20737481  0.60185185  0.809375    0.47513373  0.59740057  0.02917919
   0.51295547  0.55        0.4685714   0.50655969]
 [ 0.15809543  0.57636364  0.65        0.52880928  0.57547744  0.37239435
   0.68571429  0.69375     0.67553221  0.6833942 ]
 [ 0.07225181  0.53398268  0.615625    0.41682272  0.51735442 -0.02764892
   0.4875      0.584375    0.23815181  0.43402025]
 [-0.02725468  0.486       0.703125    0.22498561  0.47197072  0.20493538
   0.6027451   0.60625     0.5930934   0.59929886]
 [ 0.0875      0.54375     0.54375     0.53132113  0.53762234  0.05236203
   0.52532468  0.615625    0.39882482  0.50623321]
 [-0.02543189  0.48571429  0.49375     0.47283864  0.4817736   0.34262383
   0.65833333  0.775       0.60520759  0.66766959]
 [ 0.06949062  0.53490196  0.5375      0.52904851  0.5327795   0.21934046
   0.60952381  0.61875     0.59694257  0.60621425]
 [ 0.03309396  0.51626984  0.534375    0.48820789  0.51009558  0.1125
   0.55625     0.55625     0.53622552  0.54638194]
 [ 0.25247406  0.62470588  0.63125     0.60712982  0.6197112   0.20550469
   0.6015873   0.61875     0.57189889  0.59375668]
 [ 0.40736751  0.69409091  0.759375    0.66716638  0.70089846  0.5125
   0.75625     0.75625     0.73916673  0.74953495]
 [ 0.10546771  0.5525      0.578125    0.53198481  0.54813416  0.35053893
   0.6694332   0.696875    0.64325806  0.6679862 ]
 [ 0.10409543  0.55083333  0.584375    0.52145901  0.54553031  0.42422057
   0.70833333  0.721875    0.69410421  0.70801413]
 [ 0.24407366  0.61740891  0.64375     0.59384962  0.61601283 -0.00087235
   0.49848485  0.634375    0.18708184  0.43670779]]
BDDAE mean:
[0.18382716 0.58981959 0.63458333 0.54361436 0.58447743 0.22474936
 0.60876444 0.6540625  0.54154965 0.59826469]
---------------------------
---------------------------
DUMMY performance:
[[0.         0.5        0.53791667 0.         0.34956522 0.
  0.5        0.76       0.         0.43174603]
 [0.         0.5        0.55041667 0.         0.35489855 0.
  0.5        0.6075     0.         0.37776923]
 [0.         0.5        0.5825     0.         0.36792308 0.
  0.5        0.51916667 0.         0.34156522]
 [0.         0.5        0.53166667 0.         0.34689855 0.
  0.5        0.72166667 0.         0.41900692]
 [0.         0.5        0.62       0.         0.38269231 0.
  0.5        0.51291667 0.         0.33889855]
 [0.         0.5        0.52541667 0.         0.34423188 0.
  0.5        0.52541667 0.         0.34423188]
 [0.         0.5        0.60125    0.         0.37530769 0.
  0.5        0.52541667 0.         0.34423188]
 [0.         0.5        0.67708333 0.         0.40364672 0.
  0.5        0.6075     0.         0.37776923]
 [0.         0.5        0.70291667 0.         0.41265771 0.
  0.5        0.68333333 0.         0.40592593]
 [0.         0.5        0.50666667 0.         0.33623188 0.
  0.5        0.54416667 0.         0.35223188]
 [0.         0.5        0.62       0.         0.38269231 0.
  0.5        0.58875    0.         0.37038462]
 [0.         0.5        0.61375    0.         0.38023077 0.
  0.5        0.62       0.         0.38269231]
 [0.         0.5        0.57625    0.         0.36546154 0.
  0.5        0.57625    0.         0.36546154]
 [0.         0.5        0.65833333 0.         0.39680912 0.
  0.5        0.51916667 0.         0.34156522]
 [0.         0.5        0.68333333 0.         0.40592593 0.
  0.5        0.64583333 0.         0.39225071]
 [0.         0.5        0.60125    0.         0.37530769 0.
  0.5        0.65833333 0.         0.39680912]
 [0.         0.5        0.5825     0.         0.36792308 0.
  0.5        0.58875    0.         0.37038462]
 [0.         0.5        0.85458333 0.         0.46067323 0.
  0.5        0.595      0.         0.37284615]
 [0.         0.5        0.68333333 0.         0.40592593 0.
  0.5        0.55041667 0.         0.35489855]
 [0.         0.5        0.67083333 0.         0.40136752 0.
  0.5        0.63333333 0.         0.38769231]
 [0.         0.5        0.77875    0.         0.43765736 0.
  0.5        0.52541667 0.         0.34423188]
 [0.         0.5        0.51291667 0.         0.33889855 0.
  0.5        0.64583333 0.         0.39225071]
 [0.         0.5        0.57       0.         0.363      0.
  0.5        0.74041667 0.         0.42535613]
 [0.         0.5        0.53791667 0.         0.34956522 0.
  0.5        0.55041667 0.         0.35489855]
 [0.         0.5        0.57       0.         0.363      0.
  0.5        0.51291667 0.         0.33889855]
 [0.         0.5        0.53166667 0.         0.34689855 0.
  0.5        0.56333333 0.         0.36028261]
 [0.         0.5        0.69666667 0.         0.41054131 0.
  0.5        0.50666667 0.         0.33623188]
 [0.         0.5        0.62       0.         0.38269231 0.
  0.5        0.58875    0.         0.37038462]
 [0.         0.5        0.62       0.         0.38269231 0.
  0.5        0.55041667 0.         0.35489855]
 [0.         0.5        0.6075     0.         0.37776923 0.
  0.5        0.67083333 0.         0.40136752]]
DUMMY mean:
[0.         0.5        0.61418056 0.         0.37896952 0.
 0.5        0.59459722 0.         0.3715721 ]
---------------------------
Current folder: C:\Users\Javier\Dropbox\c_sldl_1_2_40
-------------------------------------
----- RESULTS from .csv files ------
-------------------------------------
---------------------------
ALG Means: 
-rows: alg : KNN = 0; DT = 1; RF = 2; SVM = 3; GBM = 4; BDDAE = 5; DUMMY = 5
columns:
'val_cohen','val_uar', 'val_acc', 'val_gm',  'val_f1',  'aro_cohen','aro_uar', 'aro_acc', 'aro_gm',  'aro_f1'
-------------------------------------------------------------
  v_c   v_u   v_a   v_g   v_f1  a_c   a_u   a_a   a_g   a_f1
[[0.436 0.715 0.749 0.681 0.712 0.433 0.713 0.74  0.685 0.71 ]
 [0.402 0.701 0.727 0.667 0.695 0.421 0.711 0.729 0.687 0.706]
 [0.444 0.725 0.755 0.693 0.721 0.462 0.726 0.748 0.695 0.724]
 [0.176 0.584 0.68  0.27  0.515 0.201 0.598 0.679 0.321 0.535]
 [0.366 0.676 0.741 0.57  0.664 0.395 0.691 0.742 0.603 0.679]
 [0.184 0.59  0.635 0.544 0.584 0.225 0.609 0.654 0.542 0.598]
 [0.    0.5   0.614 0.    0.379 0.    0.5   0.595 0.    0.372]]
-------------------------------------------------------------
Standard Deviation of each metric:
[[0.182 0.092 0.078 0.13  0.094 0.135 0.068 0.063 0.085 0.069]
 [0.196 0.096 0.081 0.132 0.097 0.139 0.071 0.067 0.082 0.072]
 [0.189 0.094 0.084 0.142 0.096 0.146 0.08  0.081 0.09  0.082]
 [0.234 0.113 0.096 0.322 0.161 0.216 0.107 0.071 0.319 0.154]
 [0.21  0.104 0.076 0.22  0.12  0.168 0.085 0.055 0.197 0.101]
 [0.172 0.084 0.091 0.117 0.088 0.173 0.085 0.085 0.15  0.095]
 [0.    0.    0.079 0.    0.029 0.    0.    0.07  0.    0.027]]
-------------------------------------------------------------
std_dev/mean [percentage]:
[[ 42.  13.  10.  19.  13.  31.  10.   9.  12.  10.]
 [ 49.  14.  11.  20.  14.  33.  10.   9.  12.  10.]
 [ 43.  13.  11.  20.  13.  32.  11.  11.  13.  11.]
 [133.  19.  14. 119.  31. 108.  18.  10. 100.  29.]
 [ 57.  15.  10.  39.  18.  43.  12.   7.  33.  15.]
 [ 94.  14.  14.  22.  15.  77.  14.  13.  28.  16.]
 [  0.   0.  13.   0.   8.   0.   0.  12.   0.   7.]]
-------------------------------------
Current folder: C:\Users\Javier\Dropbox\c_sldl_1_2_40
-------------------------------------
----- RESULTS ------
-------------------------------------
Window size (sec):  15.008
step (sec):  7.504
overlap:  True
perc. of overlap:  50.0
overlap duration (sec):  7.504
Number of windows / instances:  158
Elapsed time: 962.662425259749 minutes
Elapsed time: 16.04437375432915 hours
