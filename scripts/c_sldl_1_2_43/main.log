2024-05-09 04:13:23.074295: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-05-09 04:13:26.923720: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-05-09 04:13:36.277679: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
    
    
-------------------------------
participant:  1
-------------------------------
    
    
participant:  1
corriendo en PC gamer:
Window size (sec):  17.0
step (sec):  8.5
overlap:  True
perc. of overlap:  50.0
overlap duration (sec):  8.5
['gsr_chunks', 'ppg_chunks', 'val_chunks', 'aro_chunks', 'time_chunks', 'tag_chunks', 'video']
C:\Users\Javier\Dropbox\c_sldl_1_2_43\functions.py:880: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!
You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.
A typical example is when you are setting values in a column of a DataFrame, like:


Split Repetition number:  8
StratifiedShuffleSplit(n_splits=1, random_state=None, test_size=0.2,
            train_size=None)
TRAIN: [ 26  13 122  43  28 110  51  11   2  40 125 128  92  94   1  41 112  10
  18  88  29  77  67  90  75 117  61  48  15   5 113  38  31   6  89  62
 136 121  97  37 109  24  95  63  85  27 114  60  83  23  86  12 127  42
 111 134 131  22  50  39  58  79  98  55  64  21  47  91 133 126  74  20
 119  65  69  52  16 107  76  72  36  99 115  68  45  53  46   3 124  33
  34  35 132 118 108  96  30  82  84  71  87 102 120   7  32  49   8  70
  56] TEST: [116 103 129  54 104  80 105 123  81 130  14  73  25  19 101  66  93  78
  59 100  44  17 135   0   4 106   9  57]
(DL) TRAIN number of instances:  109
(DL) TEST number of instances:  28
(DL) Total number of instances (TRAIN+TEST):  137
C:\Users\Javier\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\keras\src\layers\convolutional\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(
----- train_GSR_AE -------
Model: "sequential_1196"
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer (type)                    â”‚ Output Shape           â”‚       Param # â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1stConvL (Conv1D)               â”‚ (None, 16992, 5)       â”‚           105 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1stPoolL (AveragePooling1D)     â”‚ (None, 4248, 5)        â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2ndConvL (Conv1D)               â”‚ (None, 4248, 6)        â”‚           306 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2ndPoolL (AveragePooling1D)     â”‚ (None, 1062, 6)        â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling1d_2392              â”‚ (None, 4248, 6)        â”‚             0 â”‚
â”‚ (UpSampling1D)                  â”‚                        â”‚               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv1d_transpose_2392           â”‚ (None, 4248, 6)        â”‚           366 â”‚
â”‚ (Conv1DTranspose)               â”‚                        â”‚               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling1d_2393              â”‚ (None, 16992, 6)       â”‚             0 â”‚
â”‚ (UpSampling1D)                  â”‚                        â”‚               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv1d_transpose_2393           â”‚ (None, 16992, 1)       â”‚           121 â”‚
â”‚ (Conv1DTranspose)               â”‚                        â”‚               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 898 (3.51 KB)
 Trainable params: 898 (3.51 KB)
 Non-trainable params: 0 (0.00 B)
Epoch 1/5

[1m 1/98[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1:48[0m 1s/step - loss: 10.3492 - mean_squared_error: 10.3492
[1m 7/98[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 9.1406 - mean_squared_error: 9.1406  
[1m14/98[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 9.7251 - mean_squared_error: 9.7251
[1m22/98[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 11.5368 - mean_squared_error: 11.5368
[1m30/98[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 12.0489 - mean_squared_error: 12.0489
[1m36/98[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 12.2127 - mean_squared_error: 12.2127
[1m43/98[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 12.3461 - mean_squared_error: 12.3461
[1m50/98[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 12.4416 - mean_squared_error: 12.4416
[1m58/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 12.5930 - mean_squared_error: 12.5930
[1m65/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 12.6557 - mean_squared_error: 12.6557
[1m72/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 12.6411 - mean_squared_error: 12.6411
[1m78/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 12.6135 - mean_squared_error: 12.6135
[1m86/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 8ms/step - loss: 12.5827 - mean_squared_error: 12.5827
[1m94/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 8ms/step - loss: 12.5359 - mean_squared_error: 12.5359
[1m98/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m2s[0m 11ms/step - loss: 12.4934 - mean_squared_error: 12.4934 - val_loss: 6.4552 - val_mean_squared_error: 6.4552
Epoch 2/5

[1m 1/98[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 16ms/step - loss: 0.0840 - mean_squared_error: 0.0840
[1m 7/98[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 2.0115 - mean_squared_error: 2.0115
[1m14/98[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 5.0026 - mean_squared_error: 5.0026
[1m21/98[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 6.0923 - mean_squared_error: 6.0923 
[1m29/98[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 7.1371 - mean_squared_error: 7.1371
[1m36/98[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 7.7676 - mean_squared_error: 7.7676
[1m43/98[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 8.2038 - mean_squared_error: 8.2038
[1m51/98[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 8.5562 - mean_squared_error: 8.5562
[1m59/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 8.8519 - mean_squared_error: 8.8519
[1m67/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 9.1365 - mean_squared_error: 9.1365
[1m74/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 9.3392 - mean_squared_error: 9.3392
[1m82/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 9ms/step - loss: 9.5952 - mean_squared_error: 9.5952
[1m90/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 8ms/step - loss: 9.7867 - mean_squared_error: 9.7867
[1m98/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 8ms/step - loss: 9.9171 - mean_squared_error: 9.9171
[1m98/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 9ms/step - loss: 9.9301 - mean_squared_error: 9.9301 - val_loss: 6.4488 - val_mean_squared_error: 6.4488
Epoch 3/5

[1m 1/98[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 31ms/step - loss: 15.5651 - mean_squared_error: 15.5651
[1m 9/98[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 8.8702 - mean_squared_error: 8.8702   
[1m16/98[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 9.5144 - mean_squared_error: 9.5144
[1m23/98[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 9.9573 - mean_squared_error: 9.9573
[1m30/98[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 9.8866 - mean_squared_error: 9.8866
[1m36/98[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 9.7836 - mean_squared_error: 9.7836
[1m44/98[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 9.8234 - mean_squared_error: 9.8234
[1m51/98[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 9.8598 - mean_squared_error: 9.8598
[1m59/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 9.8361 - mean_squared_error: 9.8361
[1m66/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 9.8815 - mean_squared_error: 9.8815
[1m74/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 9.9702 - mean_squared_error: 9.9702
[1m81/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 8ms/step - loss: 10.0456 - mean_squared_error: 10.0456
[1m88/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 8ms/step - loss: 10.1710 - mean_squared_error: 10.1710
[1m95/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 9ms/step - loss: 10.2855 - mean_squared_error: 10.2855
[1m98/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 9ms/step - loss: 10.3251 - mean_squared_error: 10.3251 - val_loss: 6.4469 - val_mean_squared_error: 6.4469
Epoch 4/5

[1m 1/98[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 31ms/step - loss: 0.0835 - mean_squared_error: 0.0835
[1m 7/98[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 8.1843 - mean_squared_error: 8.1843 
[1m14/98[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 9.1282 - mean_squared_error: 9.1282
[1m22/98[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 9.9396 - mean_squared_error: 9.9396
[1m29/98[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 10.4486 - mean_squared_error: 10.4486
[1m37/98[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 11.0083 - mean_squared_error: 11.0083
[1m44/98[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 11.2470 - mean_squared_error: 11.2470
[1m50/98[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 11.3566 - mean_squared_error: 11.3566
[1m58/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 11.3712 - mean_squared_error: 11.3712
[1m65/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 11.3766 - mean_squared_error: 11.3766
[1m73/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 11.3755 - mean_squared_error: 11.3755
[1m79/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 8ms/step - loss: 11.3775 - mean_squared_error: 11.3775
[1m86/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 8ms/step - loss: 11.3490 - mean_squared_error: 11.3490
[1m93/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 8ms/step - loss: 11.3261 - mean_squared_error: 11.3261
[1m98/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 9ms/step - loss: 11.3176 - mean_squared_error: 11.3176 - val_loss: 6.4572 - val_mean_squared_error: 6.4572
Epoch 5/5

[1m 1/98[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 25ms/step - loss: 3.7289 - mean_squared_error: 3.7289
[1m 8/98[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 3.1210 - mean_squared_error: 3.1210 
[1m15/98[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 6.0612 - mean_squared_error: 6.0612
[1m21/98[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 6.8259 - mean_squared_error: 6.8259
[1m28/98[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 7.6956 - mean_squared_error: 7.6956
[1m36/98[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 8.4445 - mean_squared_error: 8.4445
[1m44/98[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 9.1567 - mean_squared_error: 9.1567
[1m51/98[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 9.6207 - mean_squared_error: 9.6207
[1m57/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 9.8754 - mean_squared_error: 9.8754
[1m64/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 10.0846 - mean_squared_error: 10.0846
[1m72/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 10.3334 - mean_squared_error: 10.3334
[1m79/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 8ms/step - loss: 10.4689 - mean_squared_error: 10.4689
[1m87/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 8ms/step - loss: 10.5502 - mean_squared_error: 10.5502
[1m94/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 8ms/step - loss: 10.5809 - mean_squared_error: 10.5809
[1m98/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 9ms/step - loss: 10.6148 - mean_squared_error: 10.6148 - val_loss: 6.4591 - val_mean_squared_error: 6.4591
(109, 1062, 6)
Model: "sequential_1196"
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer (type)                    â”‚ Output Shape           â”‚       Param # â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1stConvL (Conv1D)               â”‚ (None, 16992, 5)       â”‚           105 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1stPoolL (AveragePooling1D)     â”‚ (None, 4248, 5)        â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2ndConvL (Conv1D)               â”‚ (None, 4248, 6)        â”‚           306 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2ndPoolL (AveragePooling1D)     â”‚ (None, 1062, 6)        â”‚             0 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 2,209 (8.63 KB)
 Trainable params: 411 (1.61 KB)
 Non-trainable params: 0 (0.00 B)
 Optimizer params: 1,798 (7.03 KB)
----- train_PPG_AE -------
Model: "sequential_1197"
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer (type)                    â”‚ Output Shape           â”‚       Param # â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1stConvL (Conv1D)               â”‚ (None, 16992, 5)       â”‚           105 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1stPoolL (AveragePooling1D)     â”‚ (None, 4248, 5)        â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2ndConvL (Conv1D)               â”‚ (None, 4248, 6)        â”‚           306 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2ndPoolL (AveragePooling1D)     â”‚ (None, 1062, 6)        â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling1d_2394              â”‚ (None, 4248, 6)        â”‚             0 â”‚
â”‚ (UpSampling1D)                  â”‚                        â”‚               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv1d_transpose_2394           â”‚ (None, 4248, 6)        â”‚           366 â”‚
â”‚ (Conv1DTranspose)               â”‚                        â”‚               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling1d_2395              â”‚ (None, 16992, 6)       â”‚             0 â”‚
â”‚ (UpSampling1D)                  â”‚                        â”‚               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv1d_transpose_2395           â”‚ (None, 16992, 1)       â”‚           121 â”‚
â”‚ (Conv1DTranspose)               â”‚                        â”‚               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 898 (3.51 KB)
 Trainable params: 898 (3.51 KB)
 Non-trainable params: 0 (0.00 B)
Epoch 1/5

[1m 1/98[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1:47[0m 1s/step - loss: 0.9011 - mean_squared_error: 0.9011
[1m 9/98[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.6579 - mean_squared_error: 0.6579 
[1m16/98[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.5333 - mean_squared_error: 0.5333
[1m24/98[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.4401 - mean_squared_error: 0.4401
[1m31/98[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.3840 - mean_squared_error: 0.3840
[1m38/98[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.3427 - mean_squared_error: 0.3427
[1m46/98[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.3069 - mean_squared_error: 0.3069
[1m53/98[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.2822 - mean_squared_error: 0.2822
[1m60/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.2618 - mean_squared_error: 0.2618
[1m67/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.2447 - mean_squared_error: 0.2447
[1m74/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.2304 - mean_squared_error: 0.2304
[1m82/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.2164 - mean_squared_error: 0.2164
[1m89/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 8ms/step - loss: 0.2059 - mean_squared_error: 0.2059
[1m96/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 8ms/step - loss: 0.1966 - mean_squared_error: 0.1966
[1m98/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m2s[0m 11ms/step - loss: 0.1929 - mean_squared_error: 0.1929 - val_loss: 0.0275 - val_mean_squared_error: 0.0275
Epoch 2/5

[1m 1/98[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 31ms/step - loss: 0.0677 - mean_squared_error: 0.0677
[1m 8/98[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 0.0597 - mean_squared_error: 0.0597 
[1m15/98[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 0.0479 - mean_squared_error: 0.0479
[1m22/98[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 0.0431 - mean_squared_error: 0.0431
[1m30/98[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 0.0393 - mean_squared_error: 0.0393
[1m37/98[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 0.0366 - mean_squared_error: 0.0366
[1m45/98[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 0.0342 - mean_squared_error: 0.0342
[1m51/98[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 0.0328 - mean_squared_error: 0.0328
[1m58/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 0.0317 - mean_squared_error: 0.0317
[1m66/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0307 - mean_squared_error: 0.0307
[1m73/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0300 - mean_squared_error: 0.0300
[1m81/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0293 - mean_squared_error: 0.0293
[1m87/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0288 - mean_squared_error: 0.0288
[1m93/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 9ms/step - loss: 0.0284 - mean_squared_error: 0.0284
[1m98/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 9ms/step - loss: 0.0280 - mean_squared_error: 0.0280 - val_loss: 0.0230 - val_mean_squared_error: 0.0230
Epoch 3/5

[1m 1/98[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 31ms/step - loss: 0.0064 - mean_squared_error: 0.0064
[1m 9/98[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0174 - mean_squared_error: 0.0174 
[1m15/98[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 0.0196 - mean_squared_error: 0.0196
[1m22/98[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0190 - mean_squared_error: 0.0190
[1m29/98[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0193 - mean_squared_error: 0.0193
[1m37/98[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0196 - mean_squared_error: 0.0196
[1m44/98[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0197 - mean_squared_error: 0.0197
[1m52/98[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0196 - mean_squared_error: 0.0196
[1m60/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0196 - mean_squared_error: 0.0196
[1m67/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0195 - mean_squared_error: 0.0195
[1m75/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0194 - mean_squared_error: 0.0194
[1m82/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0193 - mean_squared_error: 0.0193
[1m90/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 8ms/step - loss: 0.0193 - mean_squared_error: 0.0193
[1m97/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 8ms/step - loss: 0.0194 - mean_squared_error: 0.0194
[1m98/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 9ms/step - loss: 0.0194 - mean_squared_error: 0.0194 - val_loss: 0.0211 - val_mean_squared_error: 0.0211
Epoch 4/5

[1m 1/98[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 31ms/step - loss: 0.0094 - mean_squared_error: 0.0094
[1m 8/98[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 0.0086 - mean_squared_error: 0.0086 
[1m15/98[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 0.0100 - mean_squared_error: 0.0100
[1m23/98[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 0.0124 - mean_squared_error: 0.0124
[1m30/98[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 0.0133 - mean_squared_error: 0.0133
[1m38/98[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0139 - mean_squared_error: 0.0139
[1m45/98[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 0.0144 - mean_squared_error: 0.0144
[1m53/98[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0150 - mean_squared_error: 0.0150
[1m60/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 0.0154 - mean_squared_error: 0.0154
[1m68/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0156 - mean_squared_error: 0.0156
[1m75/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0158 - mean_squared_error: 0.0158
[1m83/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0159 - mean_squared_error: 0.0159
[1m89/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 8ms/step - loss: 0.0160 - mean_squared_error: 0.0160
[1m96/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 8ms/step - loss: 0.0162 - mean_squared_error: 0.0162
[1m98/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 9ms/step - loss: 0.0162 - mean_squared_error: 0.0162 - val_loss: 0.0199 - val_mean_squared_error: 0.0199
Epoch 5/5

[1m 1/98[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 31ms/step - loss: 0.0057 - mean_squared_error: 0.0057
[1m 7/98[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 0.0076 - mean_squared_error: 0.0076 
[1m14/98[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0137 - mean_squared_error: 0.0137
[1m22/98[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0165 - mean_squared_error: 0.0165
[1m29/98[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0177 - mean_squared_error: 0.0177
[1m37/98[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0182 - mean_squared_error: 0.0182
[1m43/98[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0181 - mean_squared_error: 0.0181
[1m50/98[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0180 - mean_squared_error: 0.0180
[1m57/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0183 - mean_squared_error: 0.0183
[1m65/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0187 - mean_squared_error: 0.0187
[1m72/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0189 - mean_squared_error: 0.0189
[1m79/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0190 - mean_squared_error: 0.0190
[1m85/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0190 - mean_squared_error: 0.0190
[1m93/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 8ms/step - loss: 0.0189 - mean_squared_error: 0.0189
[1m98/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 9ms/step - loss: 0.0189 - mean_squared_error: 0.0189 - val_loss: 0.0193 - val_mean_squared_error: 0.0193
(16992, 1, 5)
Model: "sequential_1197"
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer (type)                    â”‚ Output Shape           â”‚       Param # â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1stConvL (Conv1D)               â”‚ (None, 16992, 5)       â”‚           105 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1stPoolL (AveragePooling1D)     â”‚ (None, 4248, 5)        â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2ndConvL (Conv1D)               â”‚ (None, 4248, 6)        â”‚           306 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2ndPoolL (AveragePooling1D)     â”‚ (None, 1062, 6)        â”‚             0 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 2,209 (8.63 KB)
 Trainable params: 411 (1.61 KB)
 Non-trainable params: 0 (0.00 B)
 Optimizer params: 1,798 (7.03 KB)
Model: "valence_NN"
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer (type)        â”‚ Output Shape      â”‚    Param # â”‚ Connected to      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ inputGSR            â”‚ (None, 16992, 1)  â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ inputPPG            â”‚ (None, 16992, 1)  â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ sequential_1196     â”‚ (None, 1062, 6)   â”‚        411 â”‚ inputGSR[0][0]    â”‚
â”‚ (Sequential)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ sequential_1197     â”‚ (None, 1062, 6)   â”‚        411 â”‚ inputPPG[0][0]    â”‚
â”‚ (Sequential)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ concatenate_598     â”‚ (None, 1062, 12)  â”‚          0 â”‚ sequential_1196[â€¦ â”‚
â”‚ (Concatenate)       â”‚                   â”‚            â”‚ sequential_1197[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ permute_598         â”‚ (None, 12, 1062)  â”‚          0 â”‚ concatenate_598[â€¦ â”‚
â”‚ (Permute)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ flatten_598         â”‚ (None, 12744)     â”‚          0 â”‚ permute_598[0][0] â”‚
â”‚ (Flatten)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout_598         â”‚ (None, 12744)     â”‚          0 â”‚ flatten_598[0][0] â”‚
â”‚ (Dropout)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_598 (Dense)   â”‚ (None, 1)         â”‚     12,745 â”‚ dropout_598[0][0] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 13,567 (53.00 KB)
 Trainable params: 13,567 (53.00 KB)
 Non-trainable params: 0 (0.00 B)
Epoch 1/10

[1m 1/98[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2:30[0m 2s/step - binary_accuracy: 0.0000e+00 - loss: 0.8201
[1m 7/98[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.2289 - loss: 0.7555    
[1m15/98[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.2906 - loss: 0.7503 
[1m23/98[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.3304 - loss: 0.7439
[1m32/98[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.3522 - loss: 0.7401
[1m40/98[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.3740 - loss: 0.7335
[1m47/98[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.3965 - loss: 0.7256
[1m54/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.4188 - loss: 0.7165
[1m63/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.4397 - loss: 0.7115
[1m71/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.4559 - loss: 0.7075
[1m79/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.4699 - loss: 0.7038
[1m86/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.4807 - loss: 0.7000
[1m93/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.4906 - loss: 0.6959
[1m98/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m3s[0m 10ms/step - binary_accuracy: 0.4985 - loss: 0.6917 - val_binary_accuracy: 0.6364 - val_loss: 0.7174
Epoch 2/10

[1m 1/98[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 31ms/step - binary_accuracy: 1.0000 - loss: 0.1990
[1m 9/98[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7362 - loss: 0.5969 
[1m17/98[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7315 - loss: 0.6018
[1m25/98[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7154 - loss: 0.6076
[1m34/98[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.6974 - loss: 0.6120
[1m42/98[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.6992 - loss: 0.6062
[1m50/98[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.6997 - loss: 0.6060
[1m59/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7012 - loss: 0.6056
[1m67/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7023 - loss: 0.6051
[1m74/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7032 - loss: 0.6045
[1m83/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7023 - loss: 0.6058
[1m91/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.6991 - loss: 0.6074
[1m98/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 8ms/step - binary_accuracy: 0.6975 - loss: 0.6084 - val_binary_accuracy: 0.6364 - val_loss: 0.6420
Epoch 3/10

[1m 1/98[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 31ms/step - binary_accuracy: 1.0000 - loss: 0.4292
[1m 8/98[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 1.0000 - loss: 0.3673 
[1m16/98[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.9178 - loss: 0.4243
[1m24/98[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8683 - loss: 0.4590
[1m32/98[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8431 - loss: 0.4833
[1m40/98[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8213 - loss: 0.5038
[1m49/98[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8056 - loss: 0.5210
[1m57/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7938 - loss: 0.5317
[1m65/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7844 - loss: 0.5387
[1m74/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7755 - loss: 0.5449
[1m82/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7708 - loss: 0.5476
[1m91/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7650 - loss: 0.5515
[1m98/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7599 - loss: 0.5556
[1m98/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 8ms/step - binary_accuracy: 0.7592 - loss: 0.5561 - val_binary_accuracy: 0.6364 - val_loss: 0.6257
Epoch 4/10

[1m 1/98[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 31ms/step - binary_accuracy: 1.0000 - loss: 0.4031
[1m 9/98[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 1.0000 - loss: 0.3971 
[1m17/98[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.9847 - loss: 0.3799
[1m25/98[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.9412 - loss: 0.3998
[1m33/98[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.9085 - loss: 0.4197
[1m42/98[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8774 - loss: 0.4410
[1m50/98[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8591 - loss: 0.4535
[1m58/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8484 - loss: 0.4618
[1m67/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8406 - loss: 0.4694
[1m75/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8339 - loss: 0.4757
[1m83/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8287 - loss: 0.4811
[1m91/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8231 - loss: 0.4870
[1m98/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 8ms/step - binary_accuracy: 0.8172 - loss: 0.4925 - val_binary_accuracy: 0.5455 - val_loss: 0.6182
Epoch 5/10

[1m 1/98[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 31ms/step - binary_accuracy: 1.0000 - loss: 0.2623
[1m 9/98[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 1.0000 - loss: 0.3421 
[1m17/98[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.9235 - loss: 0.4003
[1m26/98[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8768 - loss: 0.4457
[1m34/98[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8433 - loss: 0.4719
[1m42/98[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8218 - loss: 0.4875
[1m51/98[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8056 - loss: 0.4968
[1m58/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7981 - loss: 0.5000
[1m66/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7913 - loss: 0.5012
[1m74/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7821 - loss: 0.5056
[1m82/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7747 - loss: 0.5098
[1m88/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7716 - loss: 0.5119
[1m97/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7674 - loss: 0.5151
[1m98/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 8ms/step - binary_accuracy: 0.7668 - loss: 0.5157 - val_binary_accuracy: 0.6364 - val_loss: 0.6279
Epoch 6/10

[1m 1/98[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 38ms/step - binary_accuracy: 1.0000 - loss: 0.2090
[1m 9/98[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.7016 - loss: 0.4969 
[1m17/98[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.7343 - loss: 0.4769
[1m25/98[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7446 - loss: 0.4735
[1m33/98[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7420 - loss: 0.4721
[1m41/98[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7402 - loss: 0.4712
[1m48/98[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7370 - loss: 0.4731
[1m56/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7344 - loss: 0.4743
[1m65/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.7366 - loss: 0.4715
[1m73/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7367 - loss: 0.4705
[1m81/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7359 - loss: 0.4713
[1m89/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7344 - loss: 0.4736
[1m97/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7335 - loss: 0.4752
[1m98/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 8ms/step - binary_accuracy: 0.7333 - loss: 0.4755 - val_binary_accuracy: 0.6364 - val_loss: 0.6830
Epoch 7/10

[1m 1/98[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 32ms/step - binary_accuracy: 1.0000 - loss: 0.6856
[1m 9/98[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 1.0000 - loss: 0.4332 
[1m17/98[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.9700 - loss: 0.4124
[1m25/98[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.9209 - loss: 0.4152
[1m34/98[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8880 - loss: 0.4201
[1m42/98[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8698 - loss: 0.4254
[1m50/98[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8570 - loss: 0.4286
[1m59/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8502 - loss: 0.4277
[1m66/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8444 - loss: 0.4282
[1m73/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8392 - loss: 0.4289
[1m82/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8315 - loss: 0.4308
[1m90/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8258 - loss: 0.4333
[1m98/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8216 - loss: 0.4350
[1m98/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 8ms/step - binary_accuracy: 0.8211 - loss: 0.4352 - val_binary_accuracy: 0.5455 - val_loss: 0.7411
Epoch 8/10

[1m 1/98[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 32ms/step - binary_accuracy: 0.0000e+00 - loss: 0.7887
[1m 8/98[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.5497 - loss: 0.4805     
[1m16/98[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.6795 - loss: 0.4114
[1m24/98[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7315 - loss: 0.3880
[1m33/98[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7405 - loss: 0.4033
[1m41/98[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7441 - loss: 0.4188
[1m49/98[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7483 - loss: 0.4295
[1m56/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7501 - loss: 0.4377
[1m64/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7527 - loss: 0.4441
[1m70/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7544 - loss: 0.4478
[1m79/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7566 - loss: 0.4513
[1m87/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7582 - loss: 0.4527
[1m95/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7611 - loss: 0.4529
[1m98/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 8ms/step - binary_accuracy: 0.7628 - loss: 0.4526 - val_binary_accuracy: 0.6364 - val_loss: 0.8153
Epoch 9/10

[1m 1/98[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 31ms/step - binary_accuracy: 1.0000 - loss: 0.2559
[1m 8/98[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 1.0000 - loss: 0.2957 
[1m16/98[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.9620 - loss: 0.3050
[1m25/98[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8825 - loss: 0.3639
[1m33/98[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8614 - loss: 0.3773
[1m42/98[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8548 - loss: 0.3828
[1m49/98[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8506 - loss: 0.3855
[1m57/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8479 - loss: 0.3871
[1m65/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8439 - loss: 0.3879
[1m74/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8403 - loss: 0.3880
[1m82/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8378 - loss: 0.3870
[1m89/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8351 - loss: 0.3874
[1m96/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8322 - loss: 0.3879
[1m98/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 8ms/step - binary_accuracy: 0.8311 - loss: 0.3880 - val_binary_accuracy: 0.4545 - val_loss: 0.9131
Epoch 10/10

[1m 1/98[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 31ms/step - binary_accuracy: 1.0000 - loss: 0.1204
[1m 8/98[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.8478 - loss: 0.2950 
[1m16/98[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.8542 - loss: 0.3003
[1m24/98[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8529 - loss: 0.3091
[1m32/98[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8462 - loss: 0.3280
[1m40/98[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8330 - loss: 0.3462
[1m47/98[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8302 - loss: 0.3514
[1m55/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8257 - loss: 0.3592
[1m63/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8227 - loss: 0.3641
[1m70/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8189 - loss: 0.3685
[1m78/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8163 - loss: 0.3705
[1m85/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8147 - loss: 0.3720
[1m92/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8134 - loss: 0.3738
[1m98/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 8ms/step - binary_accuracy: 0.8133 - loss: 0.3747 - val_binary_accuracy: 0.3636 - val_loss: 0.9795

[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 122ms/step
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 122ms/step
predicted [0.16834241 0.5940591  0.00555565 0.76894    0.5239692  0.4992778
 0.70500696 0.03033701 0.37446365 0.11012916 0.8429354  0.05768997
 0.8470608  0.7762846  0.9543646  0.04812633 0.44598335 0.74644053
 0.7589257  0.9296074  0.5921481  0.9291135  0.04810341 0.4829374
 0.64372194 0.6831535  0.42436504 0.7617619 ]
predicted [0 1 0 1 1 0 1 0 0 0 1 0 1 1 1 0 0 1 1 1 1 1 0 0 1 1 0 1]
expected [False  True False  True  True  True  True False  True False False  True
 False False  True  True  True  True  True  True  True False False False
  True  True False  True]
accuracy: 0.6785714285714286
confusion matrix: 
[[ 7  4]
 [ 5 12]]
              precision    recall  f1-score   support

       False       0.58      0.64      0.61        11
        True       0.75      0.71      0.73        17

    accuracy                           0.68        28
   macro avg       0.67      0.67      0.67        28
weighted avg       0.68      0.68      0.68        28

macro avg f1-score: 0.6679841897233202
macro avg (UAR): 0.6711229946524064
Sensitivity:  0.6363636363636364
Specificity:  0.7058823529411765
g-mean:  0.6702222474392855
-------- Model Performance ----------: 
accuracy:  [0.71428571 0.5        0.64285714 0.67857143 0.60714286 0.53571429
 0.53571429 0.71428571 0.67857143 0.        ]
gmean:  [0.67022225 0.5066404  0.62050523 0.61182641 0.52732804 0.51708769
 0.43876345 0.69758943 0.67022225 0.        ]
f1_score:  [0.68888889 0.4974359  0.62566845 0.64153627 0.56187767 0.52042161
 0.48221906 0.70053476 0.66798419 0.        ]
UAR:  [0.68449198 0.50802139 0.62566845 0.63903743 0.56417112 0.52139037
 0.48930481 0.70053476 0.67112299 0.        ]
Cohen Kappa score:  [ 0.38121547  0.01507538  0.2513369   0.29213483  0.13483146  0.04210526
 -0.02247191  0.40106952  0.33684211  0.        ]
Split Repetition number:  9
StratifiedShuffleSplit(n_splits=1, random_state=None, test_size=0.2,
            train_size=None)
TRAIN: [ 32 100  43  76 115  90  67  73  87   4 124 133  92 105  16  37  89 112
 104  50  19 120  17 108  98 107 110 126  40  48  12 122 132 123  44 114
 101  52  71  11 111   6  81 129  65 118  23 121  35   0  97  59  84 135
  68  86 134  45  66  94 131  83  41   2   8  79  14  58  95  91  42  47
 128  54  78  63 106  80  24 130   7  26 127  29  57  93  99  15  61  33
  53  39  60 116  30  27  72  51 117  69   3  46 109  74   1  18  38  36
  88] TEST: [ 56  64  20   5  31  28  55  82  77  10 113 103 102 119  70  22  21  34
  85  96   9 125  75  13  62  25  49 136]
(DL) TRAIN number of instances:  109
(DL) TEST number of instances:  28
(DL) Total number of instances (TRAIN+TEST):  137
C:\Users\Javier\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\keras\src\layers\convolutional\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(
----- train_GSR_AE -------
Model: "sequential_1198"
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer (type)                    â”‚ Output Shape           â”‚       Param # â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1stConvL (Conv1D)               â”‚ (None, 16992, 5)       â”‚           105 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1stPoolL (AveragePooling1D)     â”‚ (None, 4248, 5)        â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2ndConvL (Conv1D)               â”‚ (None, 4248, 6)        â”‚           306 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2ndPoolL (AveragePooling1D)     â”‚ (None, 1062, 6)        â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling1d_2396              â”‚ (None, 4248, 6)        â”‚             0 â”‚
â”‚ (UpSampling1D)                  â”‚                        â”‚               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv1d_transpose_2396           â”‚ (None, 4248, 6)        â”‚           366 â”‚
â”‚ (Conv1DTranspose)               â”‚                        â”‚               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling1d_2397              â”‚ (None, 16992, 6)       â”‚             0 â”‚
â”‚ (UpSampling1D)                  â”‚                        â”‚               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv1d_transpose_2397           â”‚ (None, 16992, 1)       â”‚           121 â”‚
â”‚ (Conv1DTranspose)               â”‚                        â”‚               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 898 (3.51 KB)
 Trainable params: 898 (3.51 KB)
 Non-trainable params: 0 (0.00 B)
Epoch 1/5

[1m 1/98[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1:48[0m 1s/step - loss: 71.2495 - mean_squared_error: 71.2495
[1m 7/98[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 36.7810 - mean_squared_error: 36.7810
[1m14/98[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 30.8122 - mean_squared_error: 30.8122
[1m22/98[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 26.5442 - mean_squared_error: 26.5442 
[1m30/98[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 23.7540 - mean_squared_error: 23.7540
[1m37/98[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 21.9704 - mean_squared_error: 21.9704
[1m45/98[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 20.6555 - mean_squared_error: 20.6556
[1m52/98[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 19.7459 - mean_squared_error: 19.7459
[1m58/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 19.1017 - mean_squared_error: 19.1017
[1m65/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 18.4243 - mean_squared_error: 18.4243
[1m73/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 17.7844 - mean_squared_error: 17.7844
[1m80/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 9ms/step - loss: 17.4144 - mean_squared_error: 17.4144
[1m88/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 8ms/step - loss: 17.1358 - mean_squared_error: 17.1358
[1m94/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 9ms/step - loss: 16.9726 - mean_squared_error: 16.9726
[1m98/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m2s[0m 11ms/step - loss: 16.8257 - mean_squared_error: 16.8258 - val_loss: 6.3784 - val_mean_squared_error: 6.3784
Epoch 2/5

[1m 1/98[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 31ms/step - loss: 0.8799 - mean_squared_error: 0.8799
[1m 8/98[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 11.5895 - mean_squared_error: 11.5895
[1m16/98[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 11.1721 - mean_squared_error: 11.1721
[1m23/98[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 10.7635 - mean_squared_error: 10.7635
[1m30/98[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 10.2518 - mean_squared_error: 10.2518
[1m38/98[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 9.9764 - mean_squared_error: 9.9764  
[1m45/98[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 9.9639 - mean_squared_error: 9.9639
[1m52/98[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 10.0045 - mean_squared_error: 10.0045
[1m59/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 10.1029 - mean_squared_error: 10.1029
[1m67/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 10.2509 - mean_squared_error: 10.2509
[1m74/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 10.4581 - mean_squared_error: 10.4581
[1m82/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 9ms/step - loss: 10.6857 - mean_squared_error: 10.6857
[1m89/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 9ms/step - loss: 10.8277 - mean_squared_error: 10.8277
[1m96/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 9ms/step - loss: 10.9657 - mean_squared_error: 10.9657
[1m98/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 9ms/step - loss: 11.0236 - mean_squared_error: 11.0236 - val_loss: 6.3687 - val_mean_squared_error: 6.3687
Epoch 3/5

[1m 1/98[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 16ms/step - loss: 1.4018 - mean_squared_error: 1.4018
[1m 7/98[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 7.4603 - mean_squared_error: 7.4603
[1m14/98[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - loss: 11.4304 - mean_squared_error: 11.4304
[1m22/98[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 14.4981 - mean_squared_error: 14.4981 
[1m29/98[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 15.4243 - mean_squared_error: 15.4243
[1m37/98[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 15.7283 - mean_squared_error: 15.7283
[1m44/98[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 15.6470 - mean_squared_error: 15.6470
[1m51/98[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 15.4319 - mean_squared_error: 15.4319
[1m59/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 15.2410 - mean_squared_error: 15.2410
[1m66/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 15.0868 - mean_squared_error: 15.0868
[1m73/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 14.9580 - mean_squared_error: 14.9580
[1m79/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 9ms/step - loss: 14.8544 - mean_squared_error: 14.8544
[1m87/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 9ms/step - loss: 14.7455 - mean_squared_error: 14.7455
[1m94/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 9ms/step - loss: 14.6348 - mean_squared_error: 14.6348
[1m98/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 9ms/step - loss: 14.5480 - mean_squared_error: 14.5480 - val_loss: 6.3658 - val_mean_squared_error: 6.3658
Epoch 4/5

[1m 1/98[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 31ms/step - loss: 0.3287 - mean_squared_error: 0.3287
[1m 9/98[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 4.9137 - mean_squared_error: 4.9137 
[1m16/98[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 5.6544 - mean_squared_error: 5.6544
[1m23/98[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 6.4295 - mean_squared_error: 6.4295
[1m31/98[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 7.4418 - mean_squared_error: 7.4418
[1m38/98[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 8.1854 - mean_squared_error: 8.1854
[1m45/98[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 8.6515 - mean_squared_error: 8.6515
[1m53/98[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 9.1258 - mean_squared_error: 9.1258
[1m60/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 9.6498 - mean_squared_error: 9.6498
[1m67/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 10.0539 - mean_squared_error: 10.0539
[1m74/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 10.3735 - mean_squared_error: 10.3735
[1m82/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 9ms/step - loss: 10.6444 - mean_squared_error: 10.6444
[1m89/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 9ms/step - loss: 10.8306 - mean_squared_error: 10.8306
[1m96/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 9ms/step - loss: 10.9867 - mean_squared_error: 10.9867
[1m98/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 9ms/step - loss: 11.0440 - mean_squared_error: 11.0440 - val_loss: 6.3647 - val_mean_squared_error: 6.3647
Epoch 5/5

[1m 1/98[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 31ms/step - loss: 2.2474 - mean_squared_error: 2.2474
[1m 9/98[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 8.4462 - mean_squared_error: 8.4462 
[1m16/98[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 12.2166 - mean_squared_error: 12.2166
[1m23/98[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 12.9581 - mean_squared_error: 12.9581
[1m30/98[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 13.3748 - mean_squared_error: 13.3748
[1m36/98[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 13.5389 - mean_squared_error: 13.5389
[1m43/98[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 13.5184 - mean_squared_error: 13.5184
[1m51/98[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 13.3391 - mean_squared_error: 13.3391
[1m58/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 13.2238 - mean_squared_error: 13.2238
[1m66/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 13.1860 - mean_squared_error: 13.1860
[1m72/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 13.1590 - mean_squared_error: 13.1590
[1m78/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 13.1313 - mean_squared_error: 13.1313
[1m86/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 8ms/step - loss: 13.0504 - mean_squared_error: 13.0504
[1m93/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 9ms/step - loss: 13.0120 - mean_squared_error: 13.0120
[1m98/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 9ms/step - loss: 13.0023 - mean_squared_error: 13.0023 - val_loss: 6.3646 - val_mean_squared_error: 6.3646
(109, 1062, 6)
Model: "sequential_1198"
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer (type)                    â”‚ Output Shape           â”‚       Param # â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1stConvL (Conv1D)               â”‚ (None, 16992, 5)       â”‚           105 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1stPoolL (AveragePooling1D)     â”‚ (None, 4248, 5)        â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2ndConvL (Conv1D)               â”‚ (None, 4248, 6)        â”‚           306 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2ndPoolL (AveragePooling1D)     â”‚ (None, 1062, 6)        â”‚             0 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 2,209 (8.63 KB)
 Trainable params: 411 (1.61 KB)
 Non-trainable params: 0 (0.00 B)
 Optimizer params: 1,798 (7.03 KB)
----- train_PPG_AE -------
Model: "sequential_1199"
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer (type)                    â”‚ Output Shape           â”‚       Param # â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1stConvL (Conv1D)               â”‚ (None, 16992, 5)       â”‚           105 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1stPoolL (AveragePooling1D)     â”‚ (None, 4248, 5)        â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2ndConvL (Conv1D)               â”‚ (None, 4248, 6)        â”‚           306 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2ndPoolL (AveragePooling1D)     â”‚ (None, 1062, 6)        â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling1d_2398              â”‚ (None, 4248, 6)        â”‚             0 â”‚
â”‚ (UpSampling1D)                  â”‚                        â”‚               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv1d_transpose_2398           â”‚ (None, 4248, 6)        â”‚           366 â”‚
â”‚ (Conv1DTranspose)               â”‚                        â”‚               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling1d_2399              â”‚ (None, 16992, 6)       â”‚             0 â”‚
â”‚ (UpSampling1D)                  â”‚                        â”‚               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv1d_transpose_2399           â”‚ (None, 16992, 1)       â”‚           121 â”‚
â”‚ (Conv1DTranspose)               â”‚                        â”‚               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 898 (3.51 KB)
 Trainable params: 898 (3.51 KB)
 Non-trainable params: 0 (0.00 B)
Epoch 1/5

[1m 1/98[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1:50[0m 1s/step - loss: 0.2777 - mean_squared_error: 0.2777
[1m 7/98[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 0.1368 - mean_squared_error: 0.1368 
[1m14/98[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 0.1051 - mean_squared_error: 0.1051
[1m21/98[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 0.0912 - mean_squared_error: 0.0912
[1m29/98[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 0.0800 - mean_squared_error: 0.0800
[1m35/98[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 0.0742 - mean_squared_error: 0.0742
[1m42/98[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 0.0688 - mean_squared_error: 0.0688
[1m49/98[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 0.0645 - mean_squared_error: 0.0645
[1m57/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 0.0608 - mean_squared_error: 0.0608
[1m64/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 0.0585 - mean_squared_error: 0.0585
[1m71/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 0.0565 - mean_squared_error: 0.0565
[1m77/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 0.0549 - mean_squared_error: 0.0549
[1m85/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 9ms/step - loss: 0.0529 - mean_squared_error: 0.0529
[1m92/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 9ms/step - loss: 0.0514 - mean_squared_error: 0.0514
[1m98/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m2s[0m 11ms/step - loss: 0.0501 - mean_squared_error: 0.0501 - val_loss: 0.0168 - val_mean_squared_error: 0.0168
Epoch 2/5

[1m 1/98[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 31ms/step - loss: 0.1031 - mean_squared_error: 0.1031
[1m 9/98[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0391 - mean_squared_error: 0.0391 
[1m16/98[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0305 - mean_squared_error: 0.0305
[1m24/98[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0273 - mean_squared_error: 0.0273
[1m31/98[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0250 - mean_squared_error: 0.0250
[1m38/98[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0236 - mean_squared_error: 0.0236
[1m46/98[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0232 - mean_squared_error: 0.0232
[1m54/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0229 - mean_squared_error: 0.0229
[1m61/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0227 - mean_squared_error: 0.0227
[1m68/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0225 - mean_squared_error: 0.0225
[1m76/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0223 - mean_squared_error: 0.0223
[1m83/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0222 - mean_squared_error: 0.0222
[1m91/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 8ms/step - loss: 0.0221 - mean_squared_error: 0.0221
[1m98/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 8ms/step - loss: 0.0220 - mean_squared_error: 0.0220
[1m98/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 9ms/step - loss: 0.0220 - mean_squared_error: 0.0220 - val_loss: 0.0149 - val_mean_squared_error: 0.0149
Epoch 3/5

[1m 1/98[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 31ms/step - loss: 0.0046 - mean_squared_error: 0.0046
[1m 9/98[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0182 - mean_squared_error: 0.0182 
[1m15/98[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0195 - mean_squared_error: 0.0195
[1m22/98[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0196 - mean_squared_error: 0.0196
[1m29/98[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0207 - mean_squared_error: 0.0207
[1m36/98[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 0.0216 - mean_squared_error: 0.0216
[1m44/98[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0218 - mean_squared_error: 0.0218
[1m51/98[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0217 - mean_squared_error: 0.0217
[1m59/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0214 - mean_squared_error: 0.0214
[1m66/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0211 - mean_squared_error: 0.0211
[1m74/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0207 - mean_squared_error: 0.0207
[1m81/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0204 - mean_squared_error: 0.0204
[1m89/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 8ms/step - loss: 0.0202 - mean_squared_error: 0.0202
[1m96/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 8ms/step - loss: 0.0201 - mean_squared_error: 0.0201
[1m98/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 9ms/step - loss: 0.0201 - mean_squared_error: 0.0201 - val_loss: 0.0146 - val_mean_squared_error: 0.0146
Epoch 4/5

[1m 1/98[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 31ms/step - loss: 0.0022 - mean_squared_error: 0.0022
[1m 8/98[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 0.0053 - mean_squared_error: 0.0053 
[1m16/98[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0104 - mean_squared_error: 0.0104
[1m23/98[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 0.0121 - mean_squared_error: 0.0121
[1m31/98[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0131 - mean_squared_error: 0.0131
[1m38/98[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0139 - mean_squared_error: 0.0139
[1m46/98[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0149 - mean_squared_error: 0.0149
[1m52/98[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0154 - mean_squared_error: 0.0154
[1m59/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0158 - mean_squared_error: 0.0158
[1m66/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0160 - mean_squared_error: 0.0160
[1m74/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0162 - mean_squared_error: 0.0162
[1m81/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0166 - mean_squared_error: 0.0166
[1m87/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0168 - mean_squared_error: 0.0168
[1m94/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 8ms/step - loss: 0.0170 - mean_squared_error: 0.0170
[1m98/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 9ms/step - loss: 0.0170 - mean_squared_error: 0.0170 - val_loss: 0.0141 - val_mean_squared_error: 0.0141
Epoch 5/5

[1m 1/98[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 31ms/step - loss: 0.0017 - mean_squared_error: 0.0017
[1m 8/98[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 0.0160 - mean_squared_error: 0.0160 
[1m16/98[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0179 - mean_squared_error: 0.0179
[1m23/98[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 0.0182 - mean_squared_error: 0.0182
[1m31/98[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0185 - mean_squared_error: 0.0185
[1m38/98[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0187 - mean_squared_error: 0.0187
[1m45/98[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 0.0187 - mean_squared_error: 0.0187
[1m52/98[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - loss: 0.0190 - mean_squared_error: 0.0190
[1m59/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0190 - mean_squared_error: 0.0190
[1m66/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0190 - mean_squared_error: 0.0190
[1m73/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 8ms/step - loss: 0.0189 - mean_squared_error: 0.0189
[1m80/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 9ms/step - loss: 0.0189 - mean_squared_error: 0.0189
[1m87/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 9ms/step - loss: 0.0189 - mean_squared_error: 0.0189
[1m95/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 9ms/step - loss: 0.0188 - mean_squared_error: 0.0188
[1m98/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 9ms/step - loss: 0.0188 - mean_squared_error: 0.0188 - val_loss: 0.0139 - val_mean_squared_error: 0.0139
(16992, 1, 5)
Model: "sequential_1199"
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer (type)                    â”‚ Output Shape           â”‚       Param # â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1stConvL (Conv1D)               â”‚ (None, 16992, 5)       â”‚           105 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1stPoolL (AveragePooling1D)     â”‚ (None, 4248, 5)        â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2ndConvL (Conv1D)               â”‚ (None, 4248, 6)        â”‚           306 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2ndPoolL (AveragePooling1D)     â”‚ (None, 1062, 6)        â”‚             0 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 2,209 (8.63 KB)
 Trainable params: 411 (1.61 KB)
 Non-trainable params: 0 (0.00 B)
 Optimizer params: 1,798 (7.03 KB)
Model: "valence_NN"
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer (type)        â”‚ Output Shape      â”‚    Param # â”‚ Connected to      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ inputGSR            â”‚ (None, 16992, 1)  â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ inputPPG            â”‚ (None, 16992, 1)  â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ sequential_1198     â”‚ (None, 1062, 6)   â”‚        411 â”‚ inputGSR[0][0]    â”‚
â”‚ (Sequential)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ sequential_1199     â”‚ (None, 1062, 6)   â”‚        411 â”‚ inputPPG[0][0]    â”‚
â”‚ (Sequential)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ concatenate_599     â”‚ (None, 1062, 12)  â”‚          0 â”‚ sequential_1198[â€¦ â”‚
â”‚ (Concatenate)       â”‚                   â”‚            â”‚ sequential_1199[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ permute_599         â”‚ (None, 12, 1062)  â”‚          0 â”‚ concatenate_599[â€¦ â”‚
â”‚ (Permute)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ flatten_599         â”‚ (None, 12744)     â”‚          0 â”‚ permute_599[0][0] â”‚
â”‚ (Flatten)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout_599         â”‚ (None, 12744)     â”‚          0 â”‚ flatten_599[0][0] â”‚
â”‚ (Dropout)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_599 (Dense)   â”‚ (None, 1)         â”‚     12,745 â”‚ dropout_599[0][0] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 13,567 (53.00 KB)
 Trainable params: 13,567 (53.00 KB)
 Non-trainable params: 0 (0.00 B)
Epoch 1/10

[1m 1/98[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2:09[0m 1s/step - binary_accuracy: 0.0000e+00 - loss: 0.7698
[1m 9/98[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.6733 - loss: 0.5562     
[1m17/98[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7354 - loss: 0.5283
[1m25/98[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7733 - loss: 0.4881
[1m33/98[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7834 - loss: 0.4924
[1m41/98[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7750 - loss: 0.5282
[1m48/98[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7690 - loss: 0.5467
[1m56/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7643 - loss: 0.5599
[1m64/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7599 - loss: 0.5695
[1m72/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7588 - loss: 0.5734
[1m80/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7566 - loss: 0.5787
[1m86/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7540 - loss: 0.5842
[1m94/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7510 - loss: 0.5899
[1m98/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m2s[0m 10ms/step - binary_accuracy: 0.7500 - loss: 0.5927 - val_binary_accuracy: 0.6364 - val_loss: 0.6408
Epoch 2/10

[1m 1/98[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 31ms/step - binary_accuracy: 1.0000 - loss: 0.5829
[1m 9/98[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.6132 - loss: 0.6432 
[1m18/98[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.5429 - loss: 0.6735
[1m26/98[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.5315 - loss: 0.6665
[1m34/98[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.5441 - loss: 0.6547
[1m43/98[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.5516 - loss: 0.6658
[1m51/98[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.5591 - loss: 0.6721
[1m59/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.5718 - loss: 0.6710
[1m68/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.5836 - loss: 0.6697
[1m76/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.5955 - loss: 0.6655
[1m85/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.6089 - loss: 0.6575
[1m93/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.6184 - loss: 0.6527
[1m98/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 8ms/step - binary_accuracy: 0.6244 - loss: 0.6506 - val_binary_accuracy: 0.7273 - val_loss: 0.5548
Epoch 3/10

[1m 1/98[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 31ms/step - binary_accuracy: 0.0000e+00 - loss: 1.3028
[1m 8/98[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.6446 - loss: 0.6510     
[1m16/98[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7112 - loss: 0.5824
[1m25/98[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7580 - loss: 0.5415
[1m33/98[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7685 - loss: 0.5414
[1m41/98[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7658 - loss: 0.5476
[1m47/98[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7608 - loss: 0.5513
[1m55/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7557 - loss: 0.5542
[1m64/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7507 - loss: 0.5562
[1m71/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7488 - loss: 0.5562
[1m80/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7456 - loss: 0.5569
[1m87/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7431 - loss: 0.5578
[1m94/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7420 - loss: 0.5576
[1m98/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 8ms/step - binary_accuracy: 0.7415 - loss: 0.5571 - val_binary_accuracy: 0.7273 - val_loss: 0.5524
Epoch 4/10

[1m 1/98[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 31ms/step - binary_accuracy: 1.0000 - loss: 0.6798
[1m 6/98[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.7806 - loss: 0.7810
[1m14/98[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7180 - loss: 0.7383 
[1m22/98[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7076 - loss: 0.7023
[1m30/98[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7045 - loss: 0.6749
[1m39/98[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7141 - loss: 0.6412
[1m46/98[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7171 - loss: 0.6320
[1m53/98[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7224 - loss: 0.6209
[1m61/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7285 - loss: 0.6113
[1m70/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7344 - loss: 0.6025
[1m78/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7405 - loss: 0.5936
[1m85/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7442 - loss: 0.5874
[1m92/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7474 - loss: 0.5820
[1m98/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 8ms/step - binary_accuracy: 0.7502 - loss: 0.5777 - val_binary_accuracy: 0.7273 - val_loss: 0.5440
Epoch 5/10

[1m 1/98[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 31ms/step - binary_accuracy: 1.0000 - loss: 0.1307
[1m10/98[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.9421 - loss: 0.3405 
[1m18/98[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.9049 - loss: 0.3527
[1m27/98[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.9014 - loss: 0.3634
[1m35/98[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.8971 - loss: 0.3766
[1m42/98[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8821 - loss: 0.3959
[1m51/98[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8649 - loss: 0.4177
[1m59/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8557 - loss: 0.4307
[1m67/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8494 - loss: 0.4403
[1m75/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8428 - loss: 0.4481
[1m83/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8350 - loss: 0.4586
[1m90/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8290 - loss: 0.4658
[1m98/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8229 - loss: 0.4724
[1m98/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 8ms/step - binary_accuracy: 0.8223 - loss: 0.4732 - val_binary_accuracy: 0.7273 - val_loss: 0.5340
Epoch 6/10

[1m 1/98[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 31ms/step - binary_accuracy: 1.0000 - loss: 0.1701
[1m 8/98[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.8478 - loss: 0.4261 
[1m16/98[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8542 - loss: 0.4008
[1m25/98[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8394 - loss: 0.4018
[1m33/98[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8382 - loss: 0.4048
[1m41/98[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8335 - loss: 0.4114
[1m50/98[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8291 - loss: 0.4166
[1m58/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8258 - loss: 0.4210
[1m66/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8236 - loss: 0.4253
[1m74/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8234 - loss: 0.4272
[1m82/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8243 - loss: 0.4270
[1m89/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8228 - loss: 0.4310
[1m97/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8197 - loss: 0.4364
[1m98/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 8ms/step - binary_accuracy: 0.8188 - loss: 0.4377 - val_binary_accuracy: 0.7273 - val_loss: 0.5732
Epoch 7/10

[1m 1/98[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 31ms/step - binary_accuracy: 1.0000 - loss: 0.3616
[1m 8/98[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.7528 - loss: 0.4495 
[1m17/98[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7022 - loss: 0.4739
[1m25/98[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.6932 - loss: 0.4958
[1m33/98[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.6864 - loss: 0.5270
[1m40/98[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.6858 - loss: 0.5440
[1m47/98[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.6919 - loss: 0.5483
[1m55/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7011 - loss: 0.5466
[1m63/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7060 - loss: 0.5451
[1m71/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7115 - loss: 0.5420
[1m79/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7174 - loss: 0.5370
[1m87/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7214 - loss: 0.5349
[1m95/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7262 - loss: 0.5316
[1m98/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 8ms/step - binary_accuracy: 0.7285 - loss: 0.5300 - val_binary_accuracy: 0.7273 - val_loss: 0.5647
Epoch 8/10

[1m 1/98[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 21ms/step - binary_accuracy: 1.0000 - loss: 0.2265
[1m 8/98[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 1.0000 - loss: 0.2185 
[1m14/98[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.9592 - loss: 0.2338
[1m21/98[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.9227 - loss: 0.2619 
[1m28/98[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.9018 - loss: 0.2930
[1m36/98[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step - binary_accuracy: 0.8911 - loss: 0.3129
[1m44/98[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8863 - loss: 0.3198
[1m53/98[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8817 - loss: 0.3254
[1m60/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8751 - loss: 0.3347
[1m67/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8692 - loss: 0.3414
[1m75/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8642 - loss: 0.3475
[1m83/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8609 - loss: 0.3512
[1m91/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8565 - loss: 0.3572
[1m98/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 8ms/step - binary_accuracy: 0.8527 - loss: 0.3640 - val_binary_accuracy: 0.5455 - val_loss: 0.6406
Epoch 9/10

[1m 1/98[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 31ms/step - binary_accuracy: 1.0000 - loss: 0.3738
[1m10/98[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.9789 - loss: 0.3314 
[1m18/98[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 7ms/step - binary_accuracy: 0.9271 - loss: 0.3546
[1m26/98[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8849 - loss: 0.3886
[1m34/98[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8655 - loss: 0.4043
[1m42/98[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8607 - loss: 0.4077
[1m50/98[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8555 - loss: 0.4092
[1m58/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8477 - loss: 0.4154
[1m67/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8404 - loss: 0.4213
[1m75/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8363 - loss: 0.4251
[1m83/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8315 - loss: 0.4306
[1m92/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8281 - loss: 0.4340
[1m98/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 8ms/step - binary_accuracy: 0.8260 - loss: 0.4358 - val_binary_accuracy: 0.7273 - val_loss: 0.5331
Epoch 10/10

[1m 1/98[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 31ms/step - binary_accuracy: 1.0000 - loss: 0.0979
[1m 9/98[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.9394 - loss: 0.1647 
[1m17/98[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8773 - loss: 0.2994
[1m24/98[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8505 - loss: 0.3563
[1m32/98[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8197 - loss: 0.3983
[1m40/98[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.8030 - loss: 0.4192
[1m48/98[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7970 - loss: 0.4255
[1m55/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7938 - loss: 0.4279
[1m63/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7891 - loss: 0.4333
[1m72/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7878 - loss: 0.4346
[1m80/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7875 - loss: 0.4350
[1m88/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7876 - loss: 0.4342
[1m96/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 8ms/step - binary_accuracy: 0.7860 - loss: 0.4355
[1m98/98[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 8ms/step - binary_accuracy: 0.7857 - loss: 0.4359 - val_binary_accuracy: 0.7273 - val_loss: 0.5716

[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 110ms/step
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 110ms/step
predicted [0.1906226  0.67947316 0.9082678  0.44152457 0.5612093  0.63734984
 0.8654469  0.3921616  0.82504255 0.89554137 0.7698421  0.8703914
 0.8605429  0.15237798 0.3182233  0.8619245  0.9378544  0.8072345
 0.7337494  0.81911    0.49271092 0.1999806  0.913559   0.905265
 0.6019753  0.6870297  0.38762406 0.17754185]
predicted [0 1 1 0 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 1 1 0 0]
expected [ True  True False False  True False  True  True  True False  True  True
  True  True  True False False  True  True  True False False  True False
  True False  True False]
accuracy: 0.5714285714285714
confusion matrix: 
[[ 4  7]
 [ 5 12]]
              precision    recall  f1-score   support

       False       0.44      0.36      0.40        11
        True       0.63      0.71      0.67        17

    accuracy                           0.57        28
   macro avg       0.54      0.53      0.53        28
weighted avg       0.56      0.57      0.56        28

macro avg f1-score: 0.5333333333333333
macro avg (UAR): 0.5347593582887701
Sensitivity:  0.36363636363636365
Specificity:  0.7058823529411765
g-mean:  0.5066403971048989
-------- Model Performance ----------: 
accuracy:  [0.71428571 0.5        0.64285714 0.67857143 0.60714286 0.53571429
 0.53571429 0.71428571 0.67857143 0.57142857]
gmean:  [0.67022225 0.5066404  0.62050523 0.61182641 0.52732804 0.51708769
 0.43876345 0.69758943 0.67022225 0.5066404 ]
f1_score:  [0.68888889 0.4974359  0.62566845 0.64153627 0.56187767 0.52042161
 0.48221906 0.70053476 0.66798419 0.53333333]
UAR:  [0.68449198 0.50802139 0.62566845 0.63903743 0.56417112 0.52139037
 0.48930481 0.70053476 0.67112299 0.53475936]
Cohen Kappa score:  [ 0.38121547  0.01507538  0.2513369   0.29213483  0.13483146  0.04210526
 -0.02247191  0.40106952  0.33684211  0.0718232 ]
arousal and valece = ok
------------- Evaluating model --------------
-------------------------------------
-------------------------------------
participant:  30
-------------------------------------
----- RESULTS ------
-------------------------------------
Window size (sec):  16.992
step (sec):  8.496
overlap:  True
perc. of overlap:  50.0
overlap duration (sec):  8.496
Number of windows / instances:  137
-rows: alg : KNN = 0; DT = 1; RF = 2; SVM = 3; GBM = 4; BDDAE = 5; DUMMY = 5
columns:
'val_cohen','val_uar', 'val_acc', 'val_gm',  'val_f1',  'aro_cohen','aro_uar', 'aro_acc', 'aro_gm',  'aro_f1'
-------------------------------------------------------------
  v_c   v_u   v_a   v_g   v_f1  a_c   a_u   a_a   a_g   a_f1
[[0.865 0.936 0.935 0.934 0.932 0.524 0.761 0.788 0.749 0.759]
 [0.626 0.828 0.834 0.808 0.823 0.393 0.718 0.753 0.681 0.716]
 [0.831 0.863 0.877 0.901 0.863 0.558 0.766 0.797 0.777 0.767]
 [0.664 0.82  0.848 0.803 0.828 0.    0.5   0.665 0.    0.399]
 [0.585 0.793 0.804 0.78  0.789 0.276 0.616 0.71  0.511 0.612]
 [0.19  0.594 0.618 0.577 0.592 0.2   0.589 0.696 0.48  0.579]
 [0.    0.5   0.613 0.    0.38  0.    0.5   0.665 0.    0.399]]
last participant performance loaded in numpy array
    
    
-------------------------------
LAST participant's saved data: 
30
-------------------------------
    
    
Saving performance metrics in csv files...
Performance metrics already saved in csv files
---------------------------
KNN performance:
[[0.60807978 0.80386905 0.80494505 0.79644705 0.80124072 0.27727457
  0.63090909 0.77417582 0.47955822 0.61906792]
 [0.506661   0.75892857 0.7510989  0.74514589 0.74683929 0.57875031
  0.78486111 0.81043956 0.75574537 0.78114717]
 [0.48068139 0.73458333 0.75494505 0.71382129 0.73446161 0.4160098
  0.70982143 0.70714286 0.70260197 0.70394047]
 [0.54344008 0.7702381  0.77417582 0.76339891 0.7694988  0.27404574
  0.64166667 0.75879121 0.43988142 0.61204798]
 [0.62051656 0.80097222 0.83241758 0.77849277 0.80523767 0.50299889
  0.75119048 0.7521978  0.74136114 0.74761433]
 [0.46792072 0.73363095 0.73626374 0.72052614 0.72928558 0.55661614
  0.77797619 0.78021978 0.769521   0.77550824]
 [0.34605353 0.67166667 0.69340659 0.6398188  0.66187449 0.28404846
  0.64166667 0.64230769 0.62849986 0.63596893]
 [0.86393479 0.92944444 0.94175824 0.92383109 0.93096233 0.65640776
  0.83791667 0.83241758 0.83310393 0.82574501]
 [0.12348807 0.55638889 0.67142857 0.39023643 0.54347991 0.24015628
  0.61444444 0.68681319 0.56794738 0.61284225]
 [0.25284808 0.62619048 0.62802198 0.61820895 0.62319972 0.31605095
  0.65744048 0.66428571 0.6397083  0.65055138]
 [0.22947236 0.60611111 0.67252747 0.51467118 0.59442698 0.5075186
  0.74736111 0.76703297 0.73247916 0.74946722]
 [0.68403353 0.83708333 0.85384615 0.82324785 0.83841416 0.58267674
  0.78097222 0.81758242 0.75392132 0.78507916]
 [0.49791239 0.75041667 0.7532967  0.74016703 0.7454783  0.25322329
  0.62690476 0.63461538 0.61378079 0.6213747 ]
 [0.16682133 0.57638889 0.62857143 0.54699168 0.57823486 0.40598557
  0.70119048 0.70659341 0.69102952 0.69950897]
 [0.24698764 0.61777778 0.68406593 0.56976551 0.61262793 0.29158971
  0.64861111 0.68516484 0.61692324 0.63922333]
 [0.36603546 0.6775     0.70714286 0.64182243 0.67386044 0.60162262
  0.79694444 0.82417582 0.78305706 0.79759601]
 [0.44411799 0.72291667 0.72912088 0.70448107 0.71454714 0.41957891
  0.70555556 0.72857143 0.68612833 0.70483105]
 [0.22758829 0.59545455 0.84065934 0.34725234 0.60458108 0.50135775
  0.75541667 0.76043956 0.74142352 0.74629891]
 [0.47135319 0.73111111 0.79395604 0.66178681 0.72965273 0.50348569
  0.75089286 0.75989011 0.72771488 0.74464987]
 [0.25575801 0.62638889 0.71428571 0.50317258 0.61333914 0.19393488
  0.59583333 0.64450549 0.53088115 0.59049942]
 [0.24337195 0.6080303  0.75714286 0.47770177 0.6118714  0.17178937
  0.58571429 0.58956044 0.5614463  0.57492174]
 [0.26037271 0.6297619  0.63351648 0.60896527 0.62181215 0.38789877
  0.69722222 0.73846154 0.62639002 0.6814054 ]
 [0.1691593  0.58680556 0.60604396 0.54299806 0.57938468 0.36977254
  0.66462121 0.78846154 0.57373261 0.67467227]
 [0.19340406 0.59761905 0.59725275 0.55730314 0.57660947 0.54273536
  0.76696429 0.78076923 0.7431047  0.76362   ]
 [0.53390385 0.76547619 0.77527473 0.75028131 0.76296631 0.60166831
  0.80238095 0.8010989  0.79429028 0.79819472]
 [0.47174716 0.73392857 0.73846154 0.70354864 0.72263556 0.43811893
  0.72053571 0.72307692 0.71317864 0.71653357]
 [0.52938315 0.75722222 0.8021978  0.73577965 0.75916174 0.65951065
  0.8297619  0.83021978 0.82542657 0.82847444]
 [0.35150089 0.675      0.7010989  0.65774833 0.67162727 0.57126248
  0.78194444 0.79450549 0.77059136 0.78258997]
 [0.06108142 0.52736111 0.57527473 0.47730515 0.52188911 0.28156456
  0.64077381 0.6456044  0.62091795 0.63302159]
 [0.86463917 0.93625    0.93461538 0.93395563 0.93161445 0.52361466
  0.76138889 0.78846154 0.74894255 0.75866897]]
KNN mean:
[0.40274226 0.69815055 0.73622711 0.65296243 0.69369383 0.43037561
 0.71362945 0.74058608 0.68044295 0.70850217]
---------------------------
---------------------------
DT performance:
[[0.51752495 0.76815476 0.76648352 0.76699612 0.76295219 0.30274577
  0.64113636 0.72362637 0.57682421 0.60659418]
 [0.53748788 0.76875    0.77252747 0.74110868 0.76657354 0.49031267
  0.74513889 0.75824176 0.71942195 0.74152403]
 [0.61671149 0.815      0.82032967 0.8182739  0.81258663 0.39636945
  0.67440476 0.67802198 0.65937695 0.67110331]
 [0.50384271 0.74136905 0.73791209 0.76848349 0.73362828 0.34719284
  0.6725     0.74285714 0.605482   0.65575214]
 [0.53393344 0.78333333 0.78736264 0.77627146 0.77718991 0.42039854
  0.70952381 0.70989011 0.70813772 0.7074205 ]
 [0.56449822 0.76279762 0.75934066 0.70616646 0.75158332 0.42352318
  0.74345238 0.74450549 0.71190061 0.74168498]
 [0.28884468 0.63069444 0.64945055 0.60657206 0.62351051 0.29723297
  0.66547619 0.66978022 0.63746185 0.65879929]
 [0.87342527 0.94638889 0.9489011  0.94950554 0.94161187 0.55032527
  0.79347222 0.8021978  0.77097669 0.79063988]
 [0.31058995 0.72388889 0.78076923 0.63339164 0.71547467 0.36220097
  0.67888889 0.72252747 0.65316587 0.67429075]
 [0.3531311  0.6702381  0.67252747 0.67745975 0.66403478 0.41920504
  0.73809524 0.74340659 0.71879915 0.73179206]
 [0.19880904 0.59861111 0.63571429 0.61321127 0.58727378 0.56684421
  0.75361111 0.76098901 0.80324153 0.74961921]
 [0.64273177 0.81722222 0.81758242 0.81090107 0.80892278 0.51626112
  0.73375    0.75384615 0.74082729 0.72998603]
 [0.32564697 0.68744048 0.68791209 0.68534182 0.67670727 0.21048481
  0.58904762 0.60384615 0.55576524 0.57538933]
 [0.10657673 0.51638889 0.54835165 0.54510318 0.50046902 0.36191799
  0.6952381  0.7021978  0.671532   0.68891124]
 [0.20152968 0.62694444 0.69395604 0.56106829 0.60719196 0.22069535
  0.615      0.67087912 0.61610102 0.61378145]
 [0.54248493 0.7925     0.80384615 0.73504257 0.79185309 0.53353463
  0.77583333 0.8032967  0.74728052 0.77523845]
 [0.62613491 0.82       0.82362637 0.79776443 0.81633137 0.54730164
  0.78791667 0.79505495 0.79146834 0.77133954]
 [0.5649714  0.75416667 0.89945055 0.69511062 0.75779153 0.381571
  0.68958333 0.70824176 0.71946208 0.69050396]
 [0.56711602 0.77916667 0.8032967  0.80922312 0.76387531 0.41626614
  0.70327381 0.70659341 0.70730268 0.69526512]
 [0.39551394 0.66055556 0.70824176 0.56476041 0.65652574 0.09562487
  0.54194444 0.6        0.56580512 0.53865393]
 [0.09627303 0.58333333 0.69835165 0.50547551 0.58076479 0.15102613
  0.53065476 0.53901099 0.54589597 0.52411866]
 [0.36690291 0.6547619  0.65549451 0.66356989 0.65062687 0.3094445
  0.66       0.68736264 0.626366   0.64124583]
 [0.24546767 0.60694444 0.61978022 0.62500269 0.60278657 0.21155896
  0.64643939 0.71538462 0.58464224 0.61844257]
 [0.14179444 0.61369048 0.61978022 0.61309523 0.6106071  0.51045919
  0.7514881  0.75274725 0.74347192 0.74613165]
 [0.55381226 0.72916667 0.73186813 0.75072353 0.72411367 0.63459552
  0.82261905 0.82527473 0.80000367 0.82134047]
 [0.43276123 0.69285714 0.68791209 0.64460858 0.68018516 0.52276088
  0.7952381  0.79725275 0.78380693 0.79230937]
 [0.53328343 0.78027778 0.81758242 0.69205706 0.77693253 0.63845938
  0.80357143 0.80384615 0.80855551 0.80045594]
 [0.26423479 0.59236111 0.63461538 0.63761235 0.58315769 0.40425904
  0.74458333 0.73791209 0.71659428 0.73156095]
 [0.19379162 0.59638889 0.62142857 0.53965973 0.59089127 0.24351403
  0.62380952 0.62307692 0.64601657 0.60989569]
 [0.62600876 0.8275     0.83351648 0.80755224 0.82318327 0.39288686
  0.71777778 0.7532967  0.68132966 0.71590518]]
DT mean:
[0.42419451 0.7113631  0.73459707 0.69137042 0.70464455 0.39596577
 0.70144895 0.72117216 0.68723385 0.69365652]
---------------------------
---------------------------
RF performance:
[[0.592803   0.79821429 0.79835165 0.80033319 0.79147408 0.34773074
  0.67090909 0.78131868 0.57872836 0.64600243]
 [0.58283012 0.80178571 0.8021978  0.75548236 0.79354813 0.56369141
  0.84083333 0.83351648 0.75148973 0.82742514]
 [0.51611208 0.76333333 0.78406593 0.77644137 0.76005737 0.51357429
  0.72232143 0.72142857 0.68524783 0.71509248]
 [0.47594837 0.75803571 0.75384615 0.74318678 0.75100549 0.04070055
  0.53333333 0.67967033 0.3766011  0.51103984]
 [0.56383599 0.79291667 0.81813187 0.77186933 0.79493269 0.46902644
  0.81071429 0.81043956 0.77200585 0.80739469]
 [0.59553911 0.76130952 0.75934066 0.73222204 0.75681152 0.54690906
  0.76428571 0.76538462 0.75420277 0.76100899]
 [0.39543297 0.70375    0.72197802 0.70325917 0.70059433 0.3535284
  0.65238095 0.65549451 0.70662609 0.64627414]
 [0.87987669 0.95388889 0.9489011  0.95463721 0.94207086 0.62194008
  0.82486111 0.84010989 0.82972682 0.82541187]
 [0.31466505 0.62166667 0.70549451 0.58991706 0.60665135 0.33004117
  0.70111111 0.75879121 0.56830809 0.70100099]
 [0.51064687 0.64642857 0.65054945 0.70579137 0.63893773 0.39086457
  0.7047619  0.72252747 0.66077413 0.6975046 ]
 [0.23130542 0.62638889 0.67197802 0.67783227 0.62402266 0.75948918
  0.81402778 0.83296703 0.80952678 0.81622396]
 [0.68112768 0.85708333 0.86813187 0.84892812 0.85750251 0.3985163
  0.75388889 0.78131868 0.7887014  0.75255613]
 [0.49936608 0.76291667 0.76813187 0.68699993 0.75752744 0.2308575
  0.70952381 0.72197802 0.67915011 0.6999649 ]
 [0.15450419 0.59388889 0.64505495 0.54405729 0.59485507 0.33549074
  0.67767857 0.67912088 0.64409639 0.67249248]
 [0.37616972 0.61583333 0.67142857 0.68516357 0.60151521 0.34126488
  0.63027778 0.68681319 0.53142404 0.62070575]
 [0.41189657 0.66986111 0.69505495 0.69128741 0.6675338  0.60421265
  0.78388889 0.81043956 0.74458083 0.7826385 ]
 [0.71503639 0.85333333 0.86098901 0.88615143 0.85021554 0.67988939
  0.77486111 0.79450549 0.74383639 0.77714931]
 [0.33183951 0.67083333 0.86318681 0.4120824  0.67579877 0.53941487
  0.75819444 0.77527473 0.7302801  0.75650859]
 [0.62104542 0.76861111 0.81043956 0.78831958 0.76053185 0.51934728
  0.73005952 0.73736264 0.728916   0.72419284]
 [0.22877077 0.66916667 0.72087912 0.61256161 0.65222898 0.24412356
  0.65847222 0.70769231 0.62473    0.65958253]
 [0.18412686 0.56522727 0.72032967 0.37840105 0.55124679 0.11672778
  0.52172619 0.52527473 0.62721059 0.51185478]
 [0.44354185 0.64285714 0.64285714 0.7310366  0.63719538 0.40079836
  0.69402778 0.73846154 0.65433617 0.68476399]
 [0.24638935 0.67555556 0.68681319 0.63468875 0.66801754 0.17737226
  0.65969697 0.78076923 0.57965107 0.65814187]
 [0.34151558 0.60863095 0.60549451 0.67272918 0.59692957 0.53717255
  0.75684524 0.75934066 0.80256358 0.75226552]
 [0.52263189 0.725      0.73736264 0.71152332 0.7226725  0.65957216
  0.81547619 0.81703297 0.83725602 0.81138886]
 [0.45829238 0.73482143 0.73681319 0.72955152 0.72877148 0.49731961
  0.7827381  0.78241758 0.75216653 0.77766761]
 [0.47976838 0.72472222 0.78681319 0.76325371 0.72822972 0.63082854
  0.79404762 0.79505495 0.76988965 0.79202756]
 [0.39493054 0.62541667 0.67197802 0.57165329 0.61580951 0.62213721
  0.70194444 0.71483516 0.73403919 0.69809039]
 [0.31030192 0.65041667 0.67087912 0.67861165 0.64100982 0.30550268
  0.66904762 0.67307692 0.58428505 0.66207458]
 [0.8311268  0.86291667 0.87747253 0.90060697 0.86265727 0.55750074
  0.76638889 0.7967033  0.77722984 0.76740103]]
RF mean:
[0.46304592 0.71682702 0.74849817 0.70461932 0.71101183 0.44451817
 0.72261081 0.74930403 0.69425268 0.71719488]
---------------------------
---------------------------
SVM performance:
[[ 0.22971932  0.61160714  0.63406593  0.46963708  0.56953559  0.
   0.5         0.75934066  0.          0.43143478]
 [ 0.38599483  0.68779762  0.70769231  0.64679143  0.67862538  0.33992586
   0.65791667  0.73131868  0.4761318   0.62830112]
 [ 0.47823691  0.725       0.76868132  0.62210779  0.70812011  0.36599026
   0.68511905  0.68461538  0.67159874  0.67738152]
 [ 0.39859137  0.69642857  0.70714286  0.65518212  0.6835956   0.
   0.5         0.73076923  0.          0.42210145]
 [ 0.58164375  0.77208333  0.81813187  0.7463416   0.78570335  0.48913684
   0.7452381   0.74450549  0.72605159  0.7362742 ]
 [ 0.22837408  0.61071429  0.62142857  0.50390133  0.57347504  0.57535095
   0.78928571  0.78846154  0.78385571  0.78588745]
 [ 0.          0.5         0.62032967  0.          0.38266516  0.23612926
   0.61666667  0.62142857  0.57524985  0.59957064]
 [ 0.73122178  0.85444444  0.89010989  0.84075856  0.8638137   0.42967978
   0.70125     0.75274725  0.64472409  0.69803823]
 [ 0.          0.5         0.70054945  0.          0.41185771  0.
   0.5         0.69340659  0.          0.40932148]
 [ 0.26574271  0.63214286  0.63461538  0.60685081  0.6222078   0.
   0.5         0.56153846  0.          0.35954545]
 [ 0.          0.5         0.65769231  0.          0.39664032  0.14571757
   0.56208333  0.64340659  0.28295582  0.49380952]
 [ 0.1283478   0.55444444  0.65714286  0.24213099  0.48623     0.
   0.5         0.62747253  0.          0.38543196]
 [ 0.24828407  0.61375     0.67142857  0.42590694  0.56552821  0.
   0.5         0.57692308  0.          0.36573593]
 [ 0.          0.5         0.66483516  0.          0.39917655  0.2100559
   0.59880952  0.62857143  0.43151835  0.53882623]
 [ 0.          0.5         0.69340659  0.          0.40932148  0.
   0.5         0.66483516  0.          0.39917655]
 [ 0.          0.5         0.5989011   0.          0.37436477  0.
   0.5         0.65769231  0.          0.39664032]
 [ 0.          0.5         0.58461538  0.          0.36883117  0.
   0.5         0.5989011   0.          0.37436477]
 [ 0.          0.5         0.85384615  0.          0.46057692  0.06645839
   0.52833333  0.62087912  0.13026755  0.42739883]
 [ 0.          0.5         0.68626374  0.          0.40678524 -0.02727273
   0.4875      0.53296703  0.          0.34712121]
 [ 0.          0.5         0.67912088  0.          0.40424901  0.
   0.5         0.64230769  0.          0.39101261]
 [ 0.          0.5         0.76648352  0.          0.43376812  0.
   0.5         0.52582418  0.          0.34439394]
 [ 0.31635407  0.65952381  0.66263736  0.59145169  0.63745395  0.
   0.5         0.65        0.          0.39382646]
 [ 0.          0.5         0.59175824  0.          0.37159797  0.
   0.5         0.74505495  0.          0.42676812]
 [ 0.          0.5         0.53296703  0.          0.34742424  0.4198454
   0.70119048  0.73021978  0.61992792  0.6864376 ]
 [ 0.          0.5         0.5543956   0.          0.35651515  0.42217871
   0.71071429  0.71428571  0.68425741  0.70052626]
 [ 0.          0.5         0.53296703  0.          0.34742424  0.4409129
   0.71577381  0.73131868  0.68844442  0.71113268]
 [ 0.11764706  0.55        0.72197802  0.14142136  0.4835639   0.6
   0.8         0.80054945  0.79320205  0.79753937]
 [ 0.          0.5         0.64230769  0.          0.39101261  0.27909074
   0.62666667  0.68626374  0.5218878   0.60402485]
 [ 0.          0.5         0.61318681  0.          0.37989836  0.05496829
   0.525       0.57582418  0.09855986  0.40116883]
 [ 0.66426099  0.81972222  0.8478022   0.80293514  0.8283786   0.
   0.5         0.66483516  0.          0.39917655]]
SVM mean:
[0.15914729 0.57625529 0.67721612 0.24318056 0.50427801 0.16827227
 0.58171825 0.66954212 0.27095443 0.51107896]
---------------------------
---------------------------
GBM performance:
[[ 0.52444302  0.76577381  0.77472527  0.72522094  0.75989098  0.3074717
   0.63333333  0.81923077  0.35485474  0.61259731]
 [ 0.29511917  0.66666667  0.68461538  0.60142385  0.65040062  0.36215961
   0.66361111  0.71593407  0.56879011  0.64189396]
 [ 0.5060521   0.74291667  0.77692308  0.65506923  0.7266      0.39770174
   0.69970238  0.7         0.66837663  0.68424219]
 [ 0.34630516  0.68214286  0.68736264  0.64359252  0.66597697  0.04990512
   0.52        0.73791209  0.09743416  0.45982213]
 [ 0.61670885  0.77625     0.82527473  0.77111691  0.79185728  0.5053444
   0.75357143  0.7532967   0.75075276  0.74894047]
 [ 0.52238755  0.75416667  0.7510989   0.75214273  0.74767857  0.46873761
   0.73571429  0.73626374  0.73140928  0.73038226]
 [ 0.26245451  0.61083333  0.67802198  0.52500441  0.60101086  0.32591036
   0.65595238  0.65549451  0.66081361  0.65110549]
 [ 0.8796787   0.93388889  0.94175824  0.94637142  0.93208806  0.50029671
   0.73986111  0.77527473  0.71293241  0.74434775]
 [ 0.18776921  0.57444444  0.72967033  0.34561289  0.54680783 -0.02580645
   0.5         0.68626374  0.04472136  0.42269433]
 [ 0.38287831  0.68928571  0.69505495  0.65508643  0.67071115  0.33734859
   0.66934524  0.69230769  0.611803    0.6551164 ]
 [ 0.32687946  0.63055556  0.71648352  0.51494321  0.61070691  0.61212948
   0.80833333  0.82637363  0.80179643  0.81282609]
 [ 0.69612748  0.83152778  0.86758242  0.81154879  0.84370364  0.64282325
   0.81125     0.83241758  0.78955176  0.81196312]
 [ 0.33271701  0.66833333  0.69505495  0.60866829  0.66007352  0.2635899
   0.60702381  0.64230769  0.50965519  0.57812319]
 [ 0.17093967  0.57416667  0.69450549  0.36010935  0.54188717  0.28944662
   0.6422619   0.65659341  0.59424752  0.62631738]
 [ 0.02167751  0.50944444  0.69340659  0.04472136  0.43848108  0.04278834
   0.50666667  0.64230769  0.24756478  0.45386579]
 [ 0.03128482  0.51958333  0.60769231  0.14615504  0.43059341  0.40036237
   0.69416667  0.76703297  0.62162165  0.69718368]
 [ 0.68995042  0.83041667  0.84725275  0.82504067  0.83371365  0.50722166
   0.74        0.77912088  0.69088466  0.73797641]
 [ 0.15715539  0.54166667  0.8543956   0.20912168  0.51842865  0.50237451
   0.73194444  0.76703297  0.67699338  0.72579026]
 [ 0.29222143  0.64277778  0.74615385  0.45751783  0.62302536  0.4223864
   0.6889881   0.69945055  0.68092152  0.68199364]
 [ 0.25806386  0.61611111  0.72857143  0.52135323  0.60843915  0.26163126
   0.60666667  0.7         0.49206729  0.59281385]
 [-0.01304348  0.495       0.75879121  0.          0.43119895  0.12111199
   0.5610119   0.56813187  0.51399843  0.54495764]
 [ 0.27029119  0.63571429  0.63406593  0.60983374  0.62636738  0.29456198
   0.64277778  0.73021978  0.46909736  0.6223865 ]
 [ 0.29716745  0.62611111  0.67197802  0.54426365  0.60523933  0.15209642
   0.5775      0.75274725  0.27508712  0.54319239]
 [ 0.29634847  0.64494048  0.65714286  0.60863806  0.6337728   0.53299443
   0.76815476  0.76813187  0.75728255  0.76222923]
 [ 0.35887254  0.67857143  0.69505495  0.62285394  0.65958461  0.67629247
   0.84404762  0.8467033   0.83468852  0.84265458]
 [ 0.57478071  0.78541667  0.79010989  0.75920716  0.77659637  0.47503943
   0.70208333  0.71593407  0.69651775  0.69664105]
 [ 0.49120628  0.7225      0.81098901  0.6626909   0.73205368  0.55628227
   0.7702381   0.77252747  0.76532304  0.76944139]
 [ 0.16437605  0.57486111  0.66428571  0.41258815  0.54799863  0.49872476
   0.75236111  0.77912088  0.71537156  0.74649387]
 [ 0.15368865  0.56083333  0.63516484  0.41575262  0.52997613  0.27094698
   0.6639881   0.67142857  0.59821918  0.64607273]
 [ 0.58532872  0.79291667  0.8043956   0.77994058  0.78904132  0.27632476
   0.61611111  0.70989011  0.51056932  0.61177015]]
GBM mean:
[0.35599434 0.66926058 0.73725275 0.55118632 0.65113014 0.36760662
 0.67688889 0.72998168 0.5814449  0.66186117]
---------------------------
---------------------------
BDDAE performance:
[[-0.01504813  0.49282051  0.49285714  0.48324898  0.48756035 -0.01406863
   0.4952381   0.72142857  0.08715676  0.44688704]
 [ 0.31206698  0.66041667  0.65357143  0.64980885  0.64874455  0.5355676
   0.75935829  0.78571429  0.74628532  0.7654904 ]
 [ 0.25187349  0.621875    0.64642857  0.58812301  0.61633895  0.21705845
   0.60794872  0.61071429  0.59702441  0.60370438]
 [ 0.07279037  0.53615385  0.53928571  0.52793712  0.53303095  0.1386383
   0.5575      0.71071429  0.41633166  0.54572488]
 [ 0.35754548  0.68333333  0.69285714  0.65890752  0.66625616  0.27142857
   0.63571429  0.63571429  0.62304285  0.62964036]
 [ 0.56682641  0.78153846  0.78571429  0.77146747  0.7803436   0.05306924
   0.52794872  0.525       0.50025144  0.5121515 ]
 [ 0.13984121  0.57379679  0.58571429  0.53616127  0.5555623  -0.06428571
   0.46785714  0.46785714  0.43977335  0.45397654]
 [ 0.53064661  0.74590643  0.81785714  0.70467475  0.75789046  0.04145069
   0.52085561  0.54285714  0.50029083  0.51685348]
 [ 0.4066415   0.6875      0.78928571  0.62097471  0.69350537  0.43553778
   0.68654971  0.79285714  0.61058919  0.70131966]
 [ 0.12857143  0.56428571  0.56428571  0.55076123  0.55781728  0.11257902
   0.55520833  0.57142857  0.53863474  0.55268987]
 [ 0.09673301  0.54222222  0.61428571  0.46637097  0.53309703  0.15863732
   0.57433155  0.62142857  0.51681206  0.56490036]
 [ 0.09714279  0.54491979  0.58571429  0.49834844  0.53834141  0.25314804
   0.63333333  0.64285714  0.62489925  0.62222042]
 [ 0.13098895  0.565625    0.56785714  0.55544207  0.5591065   0.26907515
   0.634375    0.64285714  0.61966671  0.62908894]
 [-0.05034592  0.47602339  0.57857143  0.33053487  0.46415141  0.16188904
   0.58076923  0.58214286  0.56577469  0.57391754]
 [ 0.01044925  0.50380117  0.59642857  0.36463073  0.48479425  0.19743559
   0.5877193   0.67857143  0.5170516   0.58808075]
 [ 0.07796686  0.53930481  0.55357143  0.48264024  0.51354378  0.12150381
   0.55166667  0.66071429  0.34340357  0.51103286]
 [ 0.51037892  0.75833333  0.75714286  0.74099057  0.7476147   0.3942542
   0.69010695  0.725       0.65391329  0.68708969]
 [ 0.12368338  0.57083333  0.78214286  0.42690205  0.55909995 -0.04186819
   0.47994652  0.53214286  0.39916917  0.4628064 ]
 [ 0.28979554  0.64181287  0.69642857  0.61202346  0.64001797  0.26697771
   0.63384615  0.63571429  0.61763595  0.62664372]
 [ 0.08949093  0.54181287  0.66785714  0.32168698  0.50804717  0.25421774
   0.61944444  0.68214286  0.57229945  0.62031751]
 [-0.04241695  0.48571429  0.69285714  0.1009756   0.440458    0.04861173
   0.52410256  0.52857143  0.50198677  0.51473243]
 [ 0.12142857  0.56071429  0.56071429  0.54666614  0.55386211  0.09863008
   0.54722222  0.63214286  0.40883413  0.52162498]
 [-0.07399182  0.46256684  0.48571429  0.44197253  0.45929168  0.44462529
   0.7         0.81428571  0.65539127  0.71846725]
 [-0.01925088  0.49102564  0.49642857  0.47795678  0.487094    0.24428536
   0.61979167  0.63571429  0.60440539  0.61847381]
 [-0.04922592  0.475       0.49285714  0.44129397  0.46579897  0.09285714
   0.54642857  0.54642857  0.53632191  0.54147909]
 [ 0.18688455  0.59230769  0.6         0.57782001  0.58899295  0.15953293
   0.57708333  0.6         0.54350016  0.57023783]
 [ 0.50392915  0.74210526  0.79285714  0.7238236   0.75003491  0.4
   0.7         0.7         0.67396026  0.68894949]
 [-0.11003542  0.44555556  0.49285714  0.4016662   0.44152073  0.30317627
   0.64893048  0.675       0.62845852  0.64729742]
 [ 0.0760274   0.5368984   0.56428571  0.51700315  0.53532159  0.25331605
   0.62291667  0.64285714  0.60200752  0.62130882]
 [ 0.19039622  0.59385027  0.61785714  0.57668255  0.59199001  0.19995436
   0.58918129  0.69642857  0.47983974  0.57856418]]
BDDAE mean:
[0.16372613 0.58060179 0.62547619 0.52324986 0.5719743  0.20024117
 0.59584583 0.64130952 0.5374904  0.58785572]
---------------------------
---------------------------
DUMMY performance:
[[0.         0.5        0.53296703 0.         0.34742424 0.
  0.5        0.75934066 0.         0.43143478]
 [0.         0.5        0.5543956  0.         0.35651515 0.
  0.5        0.62032967 0.         0.38266516]
 [0.         0.5        0.58461538 0.         0.36883117 0.
  0.5        0.53296703 0.         0.34742424]
 [0.         0.5        0.53296703 0.         0.34742424 0.
  0.5        0.73076923 0.         0.42210145]
 [0.         0.5        0.62747253 0.         0.38543196 0.
  0.5        0.50384615 0.         0.33491228]
 [0.         0.5        0.52582418 0.         0.34439394 0.
  0.5        0.53296703 0.         0.34742424]
 [0.         0.5        0.62032967 0.         0.38266516 0.
  0.5        0.51153846 0.         0.33833333]
 [0.         0.5        0.68626374 0.         0.40678524 0.
  0.5        0.61318681 0.         0.37989836]
 [0.         0.5        0.70054945 0.         0.41185771 0.
  0.5        0.69340659 0.         0.40932148]
 [0.         0.5        0.51153846 0.         0.33833333 0.
  0.5        0.56153846 0.         0.35954545]
 [0.         0.5        0.65769231 0.         0.39664032 0.
  0.5        0.5989011  0.         0.37436477]
 [0.         0.5        0.62032967 0.         0.38266516 0.
  0.5        0.62747253 0.         0.38543196]
 [0.         0.5        0.57692308 0.         0.36573593 0.
  0.5        0.57692308 0.         0.36573593]
 [0.         0.5        0.66483516 0.         0.39917655 0.
  0.5        0.54010989 0.         0.35045455]
 [0.         0.5        0.69340659 0.         0.40932148 0.
  0.5        0.66483516 0.         0.39917655]
 [0.         0.5        0.5989011  0.         0.37436477 0.
  0.5        0.65769231 0.         0.39664032]
 [0.         0.5        0.58461538 0.         0.36883117 0.
  0.5        0.5989011  0.         0.37436477]
 [0.         0.5        0.85384615 0.         0.46057692 0.
  0.5        0.5989011  0.         0.37436477]
 [0.         0.5        0.68626374 0.         0.40678524 0.
  0.5        0.54725275 0.         0.35348485]
 [0.         0.5        0.67912088 0.         0.40424901 0.
  0.5        0.64230769 0.         0.39101261]
 [0.         0.5        0.76648352 0.         0.43376812 0.
  0.5        0.52582418 0.         0.34439394]
 [0.         0.5        0.48846154 0.         0.32807018 0.
  0.5        0.65       0.         0.39382646]
 [0.         0.5        0.59175824 0.         0.37159797 0.
  0.5        0.74505495 0.         0.42676812]
 [0.         0.5        0.53296703 0.         0.34742424 0.
  0.5        0.56153846 0.         0.35954545]
 [0.         0.5        0.5543956  0.         0.35651515 0.
  0.5        0.51153846 0.         0.33833333]
 [0.         0.5        0.53296703 0.         0.34742424 0.
  0.5        0.5543956  0.         0.35651515]
 [0.         0.5        0.69340659 0.         0.40932148 0.
  0.5        0.48846154 0.         0.32807018]
 [0.         0.5        0.64230769 0.         0.39101261 0.
  0.5        0.59175824 0.         0.37159797]
 [0.         0.5        0.61318681 0.         0.37989836 0.
  0.5        0.5543956  0.         0.35651515]
 [0.         0.5        0.61318681 0.         0.37989836 0.
  0.5        0.66483516 0.         0.39917655]]
DUMMY mean:
[0.         0.5        0.61739927 0.         0.38009798 0.
 0.5        0.59869963 0.         0.37309447]
---------------------------
Current folder: C:\Users\Javier\Dropbox\c_sldl_1_2_43
-------------------------------------
----- RESULTS from .csv files ------
-------------------------------------
---------------------------
ALG Means: 
-rows: alg : KNN = 0; DT = 1; RF = 2; SVM = 3; GBM = 4; BDDAE = 5; DUMMY = 5
columns:
'val_cohen','val_uar', 'val_acc', 'val_gm',  'val_f1',  'aro_cohen','aro_uar', 'aro_acc', 'aro_gm',  'aro_f1'
-------------------------------------------------------------
  v_c   v_u   v_a   v_g   v_f1  a_c   a_u   a_a   a_g   a_f1
[[0.403 0.698 0.736 0.653 0.694 0.43  0.714 0.741 0.68  0.709]
 [0.424 0.711 0.735 0.691 0.705 0.396 0.701 0.721 0.687 0.694]
 [0.463 0.717 0.748 0.705 0.711 0.445 0.723 0.749 0.694 0.717]
 [0.159 0.576 0.677 0.243 0.504 0.168 0.582 0.67  0.271 0.511]
 [0.356 0.669 0.737 0.551 0.651 0.368 0.677 0.73  0.581 0.662]
 [0.164 0.581 0.625 0.523 0.572 0.2   0.596 0.641 0.537 0.588]
 [0.    0.5   0.617 0.    0.38  0.    0.5   0.599 0.    0.373]]
-------------------------------------------------------------
Standard Deviation of each metric:
[[0.202 0.102 0.09  0.14  0.104 0.142 0.072 0.065 0.099 0.074]
 [0.188 0.095 0.091 0.101 0.097 0.138 0.073 0.066 0.077 0.076]
 [0.177 0.092 0.082 0.123 0.094 0.173 0.077 0.066 0.101 0.081]
 [0.22  0.106 0.09  0.307 0.152 0.206 0.102 0.073 0.31  0.148]
 [0.212 0.105 0.078 0.227 0.123 0.177 0.088 0.063 0.199 0.105]
 [0.189 0.092 0.1   0.138 0.097 0.145 0.069 0.082 0.123 0.078]
 [0.    0.    0.08  0.    0.03  0.    0.    0.072 0.    0.028]]
-------------------------------------------------------------
std_dev/mean [percentage]:
[[ 50.  15.  12.  21.  15.  33.  10.   9.  15.  10.]
 [ 44.  13.  12.  15.  14.  35.  10.   9.  11.  11.]
 [ 38.  13.  11.  17.  13.  39.  11.   9.  15.  11.]
 [138.  18.  13. 126.  30. 122.  18.  11. 114.  29.]
 [ 60.  16.  11.  41.  19.  48.  13.   9.  34.  16.]
 [115.  16.  16.  26.  17.  72.  12.  13.  23.  13.]
 [  0.   0.  13.   0.   8.   0.   0.  12.   0.   8.]]
-------------------------------------
Current folder: C:\Users\Javier\Dropbox\c_sldl_1_2_43
-------------------------------------
----- RESULTS ------
-------------------------------------
Window size (sec):  16.992
step (sec):  8.496
overlap:  True
perc. of overlap:  50.0
overlap duration (sec):  8.496
Number of windows / instances:  137
Elapsed time: 955.2394835750262 minutes
Elapsed time: 15.92065805958377 hours
