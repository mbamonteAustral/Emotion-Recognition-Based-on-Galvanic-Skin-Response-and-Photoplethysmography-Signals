2024-05-13 03:41:15.581841: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-05-13 03:41:19.179213: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-05-13 03:41:28.130572: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
    
    
-------------------------------
participant:  1
-------------------------------
    
    
participant:  1
corriendo en PC gamer:
Window size (sec):  18.0
step (sec):  9.0
overlap:  True
perc. of overlap:  50.0
overlap duration (sec):  9.0
['gsr_chunks', 'ppg_chunks', 'val_chunks', 'aro_chunks', 'time_chunks', 'tag_chunks', 'video']
C:\Users\Javier\Dropbox\c_sldl_1_2_43_3\functions.py:880: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!
You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.
A typical example is when you are setting values in a column of a DataFrame, like:

df["col"][row_indexer] = value

0179 - val_mean_squared_error: 0.0179
Epoch 3/5

[1m 1/92[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 28ms/step - loss: 0.0056 - mean_squared_error: 0.0056
[1m 6/92[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 12ms/step - loss: 0.0201 - mean_squared_error: 0.0201
[1m11/92[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 13ms/step - loss: 0.0203 - mean_squared_error: 0.0203
[1m15/92[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 13ms/step - loss: 0.0194 - mean_squared_error: 0.0194
[1m20/92[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - loss: 0.0184 - mean_squared_error: 0.0184
[1m24/92[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - loss: 0.0184 - mean_squared_error: 0.0184
[1m29/92[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - loss: 0.0186 - mean_squared_error: 0.0186
[1m33/92[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - loss: 0.0191 - mean_squared_error: 0.0191
[1m38/92[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - loss: 0.0197 - mean_squared_error: 0.0197
[1m42/92[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - loss: 0.0200 - mean_squared_error: 0.0200
[1m47/92[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - loss: 0.0204 - mean_squared_error: 0.0204
[1m51/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - loss: 0.0207 - mean_squared_error: 0.0207
[1m56/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - loss: 0.0210 - mean_squared_error: 0.0210
[1m61/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - loss: 0.0211 - mean_squared_error: 0.0211
[1m65/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 14ms/step - loss: 0.0211 - mean_squared_error: 0.0211
[1m69/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 14ms/step - loss: 0.0210 - mean_squared_error: 0.0210
[1m74/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 14ms/step - loss: 0.0209 - mean_squared_error: 0.0209
[1m79/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 13ms/step - loss: 0.0208 - mean_squared_error: 0.0208
[1m83/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 14ms/step - loss: 0.0208 - mean_squared_error: 0.0208
[1m88/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 14ms/step - loss: 0.0206 - mean_squared_error: 0.0206
[1m92/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 14ms/step - loss: 0.0206 - mean_squared_error: 0.0206
[1m92/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 14ms/step - loss: 0.0205 - mean_squared_error: 0.0205 - val_loss: 0.0172 - val_mean_squared_error: 0.0172
Epoch 4/5

[1m 1/92[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 31ms/step - loss: 0.0052 - mean_squared_error: 0.0052
[1m 5/92[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 14ms/step - loss: 0.0349 - mean_squared_error: 0.0349
[1m10/92[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - loss: 0.0292 - mean_squared_error: 0.0292
[1m14/92[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 13ms/step - loss: 0.0266 - mean_squared_error: 0.0266
[1m19/92[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - loss: 0.0246 - mean_squared_error: 0.0246
[1m24/92[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - loss: 0.0239 - mean_squared_error: 0.0239
[1m29/92[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - loss: 0.0235 - mean_squared_error: 0.0235
[1m34/92[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - loss: 0.0234 - mean_squared_error: 0.0234
[1m39/92[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - loss: 0.0233 - mean_squared_error: 0.0233
[1m44/92[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - loss: 0.0234 - mean_squared_error: 0.0234
[1m49/92[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - loss: 0.0234 - mean_squared_error: 0.0234
[1m54/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - loss: 0.0234 - mean_squared_error: 0.0234
[1m59/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - loss: 0.0232 - mean_squared_error: 0.0232
[1m64/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - loss: 0.0230 - mean_squared_error: 0.0230
[1m69/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 13ms/step - loss: 0.0228 - mean_squared_error: 0.0228
[1m74/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 13ms/step - loss: 0.0226 - mean_squared_error: 0.0226
[1m79/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 13ms/step - loss: 0.0224 - mean_squared_error: 0.0224
[1m84/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 13ms/step - loss: 0.0221 - mean_squared_error: 0.0221
[1m89/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 13ms/step - loss: 0.0219 - mean_squared_error: 0.0219
[1m92/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 13ms/step - loss: 0.0217 - mean_squared_error: 0.0217 - val_loss: 0.0165 - val_mean_squared_error: 0.0165
Epoch 5/5

[1m 1/92[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 31ms/step - loss: 0.0031 - mean_squared_error: 0.0031
[1m 6/92[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 13ms/step - loss: 0.0105 - mean_squared_error: 0.0105
[1m10/92[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 13ms/step - loss: 0.0136 - mean_squared_error: 0.0136
[1m14/92[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 13ms/step - loss: 0.0159 - mean_squared_error: 0.0159
[1m19/92[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - loss: 0.0168 - mean_squared_error: 0.0168
[1m24/92[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - loss: 0.0179 - mean_squared_error: 0.0179
[1m29/92[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - loss: 0.0187 - mean_squared_error: 0.0187
[1m34/92[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - loss: 0.0191 - mean_squared_error: 0.0191
[1m39/92[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - loss: 0.0192 - mean_squared_error: 0.0192
[1m44/92[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - loss: 0.0194 - mean_squared_error: 0.0194
[1m48/92[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - loss: 0.0195 - mean_squared_error: 0.0195
[1m54/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - loss: 0.0196 - mean_squared_error: 0.0196
[1m59/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - loss: 0.0196 - mean_squared_error: 0.0196
[1m64/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - loss: 0.0197 - mean_squared_error: 0.0197
[1m69/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 13ms/step - loss: 0.0198 - mean_squared_error: 0.0198
[1m74/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 13ms/step - loss: 0.0198 - mean_squared_error: 0.0198
[1m78/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 13ms/step - loss: 0.0198 - mean_squared_error: 0.0198
[1m83/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 13ms/step - loss: 0.0198 - mean_squared_error: 0.0198
[1m88/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 13ms/step - loss: 0.0197 - mean_squared_error: 0.0197
[1m92/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 13ms/step - loss: 0.0197 - mean_squared_error: 0.0197
[1m92/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 13ms/step - loss: 0.0197 - mean_squared_error: 0.0197 - val_loss: 0.0165 - val_mean_squared_error: 0.0165
(18000, 1, 5)
Model: "sequential_1199"
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer (type)                    â”‚ Output Shape           â”‚       Param # â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1stConvL (Conv1D)               â”‚ (None, 18000, 5)       â”‚           105 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1stPoolL (AveragePooling1D)     â”‚ (None, 4500, 5)        â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2ndConvL (Conv1D)               â”‚ (None, 4500, 6)        â”‚           306 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2ndPoolL (AveragePooling1D)     â”‚ (None, 1125, 6)        â”‚             0 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 2,209 (8.63 KB)
 Trainable params: 411 (1.61 KB)
 Non-trainable params: 0 (0.00 B)
 Optimizer params: 1,798 (7.03 KB)
Model: "valence_NN"
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer (type)        â”‚ Output Shape      â”‚    Param # â”‚ Connected to      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ inputGSR            â”‚ (None, 18000, 1)  â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ inputPPG            â”‚ (None, 18000, 1)  â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ sequential_1198     â”‚ (None, 1125, 6)   â”‚        411 â”‚ inputGSR[0][0]    â”‚
â”‚ (Sequential)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ sequential_1199     â”‚ (None, 1125, 6)   â”‚        411 â”‚ inputPPG[0][0]    â”‚
â”‚ (Sequential)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ concatenate_599     â”‚ (None, 1125, 12)  â”‚          0 â”‚ sequential_1198[â€¦ â”‚
â”‚ (Concatenate)       â”‚                   â”‚            â”‚ sequential_1199[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ permute_599         â”‚ (None, 12, 1125)  â”‚          0 â”‚ concatenate_599[â€¦ â”‚
â”‚ (Permute)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ flatten_599         â”‚ (None, 13500)     â”‚          0 â”‚ permute_599[0][0] â”‚
â”‚ (Flatten)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout_599         â”‚ (None, 13500)     â”‚          0 â”‚ flatten_599[0][0] â”‚
â”‚ (Dropout)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_599 (Dense)   â”‚ (None, 1)         â”‚     13,501 â”‚ dropout_599[0][0] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 14,323 (55.95 KB)
 Trainable params: 14,323 (55.95 KB)
 Non-trainable params: 0 (0.00 B)
Epoch 1/10

[1m 1/92[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2:18[0m 2s/step - binary_accuracy: 0.0000e+00 - loss: 0.7568
[1m 5/92[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 16ms/step - binary_accuracy: 0.2967 - loss: 0.8736    
[1m10/92[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 13ms/step - binary_accuracy: 0.4446 - loss: 0.8209
[1m15/92[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.5061 - loss: 0.7784
[1m21/92[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.5491 - loss: 0.7490
[1m26/92[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.5652 - loss: 0.7341
[1m32/92[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.5883 - loss: 0.7134
[1m37/92[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.6038 - loss: 0.6992
[1m42/92[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.6182 - loss: 0.6842
[1m47/92[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.6304 - loss: 0.6730
[1m51/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.6380 - loss: 0.6674
[1m55/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.6433 - loss: 0.6646
[1m60/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.6471 - loss: 0.6634
[1m66/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.6534 - loss: 0.6617
[1m71/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.6578 - loss: 0.6610
[1m75/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.6598 - loss: 0.6611
[1m80/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.6618 - loss: 0.6616
[1m85/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.6647 - loss: 0.6610
[1m90/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.6673 - loss: 0.6602
[1m92/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m3s[0m 14ms/step - binary_accuracy: 0.6685 - loss: 0.6599 - val_binary_accuracy: 0.5455 - val_loss: 0.7701
Epoch 2/10

[1m 1/92[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 32ms/step - binary_accuracy: 0.0000e+00 - loss: 1.5140
[1m 6/92[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 12ms/step - binary_accuracy: 0.2889 - loss: 1.1134    
[1m11/92[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 13ms/step - binary_accuracy: 0.4567 - loss: 0.9264
[1m16/92[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.5463 - loss: 0.8328
[1m22/92[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.6094 - loss: 0.7599
[1m27/92[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.6418 - loss: 0.7199
[1m31/92[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.6585 - loss: 0.6956
[1m36/92[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.6716 - loss: 0.6760
[1m42/92[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.6836 - loss: 0.6557
[1m47/92[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.6885 - loss: 0.6453
[1m53/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.6923 - loss: 0.6368
[1m58/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.6958 - loss: 0.6311
[1m63/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.6991 - loss: 0.6261
[1m69/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.7026 - loss: 0.6210
[1m74/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.7058 - loss: 0.6167
[1m80/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.7091 - loss: 0.6127
[1m85/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.7106 - loss: 0.6114
[1m91/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.7115 - loss: 0.6103
[1m92/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 12ms/step - binary_accuracy: 0.7116 - loss: 0.6099 - val_binary_accuracy: 0.6364 - val_loss: 0.6152
Epoch 3/10

[1m 1/92[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 31ms/step - binary_accuracy: 1.0000 - loss: 0.3157
[1m 6/92[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 13ms/step - binary_accuracy: 0.8694 - loss: 0.4769
[1m10/92[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 14ms/step - binary_accuracy: 0.8259 - loss: 0.4936
[1m16/92[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.7810 - loss: 0.5094
[1m21/92[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.7702 - loss: 0.5072
[1m26/92[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.7695 - loss: 0.5027
[1m31/92[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.7656 - loss: 0.5028
[1m35/92[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.7616 - loss: 0.5039
[1m40/92[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.7599 - loss: 0.5045
[1m45/92[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.7556 - loss: 0.5074
[1m51/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.7483 - loss: 0.5135
[1m56/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.7430 - loss: 0.5184
[1m61/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.7383 - loss: 0.5228
[1m66/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.7354 - loss: 0.5264
[1m72/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.7312 - loss: 0.5313
[1m77/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.7296 - loss: 0.5334
[1m82/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.7289 - loss: 0.5347
[1m87/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.7287 - loss: 0.5352
[1m92/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 12ms/step - binary_accuracy: 0.7284 - loss: 0.5354
[1m92/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 13ms/step - binary_accuracy: 0.7284 - loss: 0.5354 - val_binary_accuracy: 0.5455 - val_loss: 0.8593
Epoch 4/10

[1m 1/92[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 31ms/step - binary_accuracy: 1.0000 - loss: 0.1822
[1m 7/92[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.8473 - loss: 0.4232
[1m12/92[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 13ms/step - binary_accuracy: 0.8259 - loss: 0.4211
[1m17/92[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.8340 - loss: 0.3942
[1m22/92[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.8375 - loss: 0.3899
[1m28/92[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.8470 - loss: 0.3784
[1m33/92[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.8506 - loss: 0.3760
[1m39/92[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.8511 - loss: 0.3788
[1m43/92[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.8498 - loss: 0.3821
[1m49/92[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.8464 - loss: 0.3870
[1m54/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.8428 - loss: 0.3928
[1m58/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.8414 - loss: 0.3964
[1m64/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.8395 - loss: 0.4010
[1m68/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.8375 - loss: 0.4042
[1m73/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.8357 - loss: 0.4083
[1m77/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.8344 - loss: 0.4115
[1m82/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.8320 - loss: 0.4158
[1m87/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.8299 - loss: 0.4195
[1m91/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8285 - loss: 0.4219
[1m92/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 13ms/step - binary_accuracy: 0.8278 - loss: 0.4233 - val_binary_accuracy: 0.6364 - val_loss: 0.6519
Epoch 5/10

[1m 1/92[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 31ms/step - binary_accuracy: 1.0000 - loss: 0.6551
[1m 5/92[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 16ms/step - binary_accuracy: 0.8433 - loss: 0.6116
[1m10/92[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 15ms/step - binary_accuracy: 0.7925 - loss: 0.5625
[1m15/92[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 13ms/step - binary_accuracy: 0.8098 - loss: 0.5165
[1m19/92[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 14ms/step - binary_accuracy: 0.8257 - loss: 0.4882
[1m24/92[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - binary_accuracy: 0.8355 - loss: 0.4645
[1m30/92[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8407 - loss: 0.4482
[1m34/92[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8369 - loss: 0.4469
[1m38/92[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8339 - loss: 0.4460
[1m42/92[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8321 - loss: 0.4444
[1m47/92[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8306 - loss: 0.4433
[1m52/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8280 - loss: 0.4435
[1m56/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8249 - loss: 0.4448
[1m61/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8218 - loss: 0.4457
[1m66/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8185 - loss: 0.4463
[1m71/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8147 - loss: 0.4468
[1m75/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8117 - loss: 0.4473
[1m80/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8089 - loss: 0.4476
[1m85/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8058 - loss: 0.4484
[1m90/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8029 - loss: 0.4500
[1m92/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 14ms/step - binary_accuracy: 0.8015 - loss: 0.4507 - val_binary_accuracy: 0.6364 - val_loss: 0.6428
Epoch 6/10

[1m 1/92[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 31ms/step - binary_accuracy: 1.0000 - loss: 0.2318
[1m 5/92[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 16ms/step - binary_accuracy: 1.0000 - loss: 0.1662
[1m10/92[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 14ms/step - binary_accuracy: 1.0000 - loss: 0.1627
[1m15/92[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 13ms/step - binary_accuracy: 1.0000 - loss: 0.1508
[1m20/92[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.9809 - loss: 0.1825
[1m25/92[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.9569 - loss: 0.2189
[1m29/92[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.9416 - loss: 0.2395
[1m33/92[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.9266 - loss: 0.2581
[1m38/92[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.9114 - loss: 0.2776
[1m43/92[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8990 - loss: 0.2929
[1m48/92[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8891 - loss: 0.3054
[1m52/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8839 - loss: 0.3128
[1m57/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8766 - loss: 0.3220
[1m63/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8694 - loss: 0.3319
[1m68/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8656 - loss: 0.3383
[1m73/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8623 - loss: 0.3432
[1m78/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8590 - loss: 0.3481
[1m83/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8557 - loss: 0.3530
[1m88/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8522 - loss: 0.3579
[1m92/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8492 - loss: 0.3616
[1m92/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 13ms/step - binary_accuracy: 0.8484 - loss: 0.3626 - val_binary_accuracy: 0.7273 - val_loss: 0.6336
Epoch 7/10

[1m 1/92[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 31ms/step - binary_accuracy: 1.0000 - loss: 0.5689
[1m 5/92[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 16ms/step - binary_accuracy: 1.0000 - loss: 0.4634
[1m10/92[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 14ms/step - binary_accuracy: 0.9664 - loss: 0.3962
[1m15/92[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 13ms/step - binary_accuracy: 0.9516 - loss: 0.3886
[1m20/92[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.9446 - loss: 0.3840
[1m25/92[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.9382 - loss: 0.3813
[1m30/92[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.9284 - loss: 0.3822
[1m33/92[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.9235 - loss: 0.3824
[1m38/92[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.9160 - loss: 0.3826
[1m44/92[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.9105 - loss: 0.3798
[1m49/92[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.9053 - loss: 0.3770
[1m54/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.9016 - loss: 0.3729
[1m58/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8999 - loss: 0.3689
[1m63/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8972 - loss: 0.3676
[1m69/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8930 - loss: 0.3684
[1m74/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8907 - loss: 0.3679
[1m80/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8871 - loss: 0.3683
[1m85/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8845 - loss: 0.3688
[1m90/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8819 - loss: 0.3695
[1m92/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 13ms/step - binary_accuracy: 0.8798 - loss: 0.3704 - val_binary_accuracy: 0.6364 - val_loss: 0.5018
Epoch 8/10

[1m 1/92[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 32ms/step - binary_accuracy: 1.0000 - loss: 0.2609
[1m 6/92[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 13ms/step - binary_accuracy: 0.7583 - loss: 0.5445
[1m10/92[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 14ms/step - binary_accuracy: 0.8071 - loss: 0.4806
[1m15/92[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 14ms/step - binary_accuracy: 0.8455 - loss: 0.4172
[1m20/92[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8650 - loss: 0.3830
[1m26/92[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8665 - loss: 0.3844
[1m31/92[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8713 - loss: 0.3764
[1m36/92[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8721 - loss: 0.3716
[1m40/92[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8719 - loss: 0.3686
[1m44/92[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8707 - loss: 0.3664
[1m49/92[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8709 - loss: 0.3632
[1m53/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8685 - loss: 0.3636
[1m58/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8660 - loss: 0.3646
[1m62/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8637 - loss: 0.3657
[1m66/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8617 - loss: 0.3671
[1m72/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8590 - loss: 0.3693
[1m77/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8578 - loss: 0.3705
[1m82/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8571 - loss: 0.3712
[1m87/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8561 - loss: 0.3718
[1m92/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8554 - loss: 0.3722
[1m92/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 13ms/step - binary_accuracy: 0.8552 - loss: 0.3723 - val_binary_accuracy: 0.7273 - val_loss: 0.6591
Epoch 9/10

[1m 1/92[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 31ms/step - binary_accuracy: 1.0000 - loss: 0.0519
[1m 5/92[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 16ms/step - binary_accuracy: 1.0000 - loss: 0.0977
[1m11/92[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 13ms/step - binary_accuracy: 0.9157 - loss: 0.2150
[1m16/92[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8844 - loss: 0.2547
[1m21/92[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8741 - loss: 0.2822
[1m25/92[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8738 - loss: 0.2928
[1m30/92[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8769 - loss: 0.2976
[1m36/92[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8825 - loss: 0.2997
[1m41/92[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8874 - loss: 0.2998
[1m46/92[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8898 - loss: 0.3011
[1m51/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8926 - loss: 0.3020
[1m56/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8936 - loss: 0.3042
[1m61/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8928 - loss: 0.3067
[1m65/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8917 - loss: 0.3098
[1m70/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8910 - loss: 0.3131
[1m74/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8909 - loss: 0.3155
[1m80/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8914 - loss: 0.3178
[1m84/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8919 - loss: 0.3188
[1m89/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8928 - loss: 0.3198
[1m92/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 13ms/step - binary_accuracy: 0.8932 - loss: 0.3205 - val_binary_accuracy: 0.7273 - val_loss: 0.6655
Epoch 10/10

[1m 1/92[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 31ms/step - binary_accuracy: 1.0000 - loss: 0.1205
[1m 6/92[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 13ms/step - binary_accuracy: 1.0000 - loss: 0.1632
[1m12/92[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.9450 - loss: 0.1945
[1m17/92[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.9106 - loss: 0.2239
[1m21/92[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.8982 - loss: 0.2350
[1m26/92[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.8922 - loss: 0.2422
[1m31/92[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.8818 - loss: 0.2533
[1m37/92[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.8727 - loss: 0.2616
[1m43/92[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.8681 - loss: 0.2650
[1m48/92[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.8656 - loss: 0.2673
[1m53/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.8616 - loss: 0.2719
[1m58/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.8597 - loss: 0.2747
[1m63/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.8578 - loss: 0.2787
[1m68/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.8571 - loss: 0.2817
[1m73/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.8572 - loss: 0.2841
[1m78/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.8571 - loss: 0.2866
[1m84/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.8577 - loss: 0.2886
[1m88/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.8582 - loss: 0.2897
[1m92/92[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 13ms/step - binary_accuracy: 0.8583 - loss: 0.2920 - val_binary_accuracy: 0.6364 - val_loss: 0.5932

[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 110ms/step
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 110ms/step
predicted [0.0229933  0.9851787  0.3997642  0.31583068 0.39827693 0.9800794
 0.7924128  0.03473375 0.73386264 0.88171643 0.7194792  0.57556224
 0.8469254  0.7132226  0.6694142  0.7992635  0.14370602 0.81435734
 0.5567871  0.7168025  0.8543619  0.96079826 0.02238455 0.93169475
 0.3766549  0.06143028]
predicted [0 1 0 0 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 0 0]
expected [False  True  True False False False  True  True  True  True  True False
  True  True  True False  True  True False  True  True False False  True
  True False]
accuracy: 0.6538461538461539
confusion matrix: 
[[ 5  5]
 [ 4 12]]
              precision    recall  f1-score   support

       False       0.56      0.50      0.53        10
        True       0.71      0.75      0.73        16

    accuracy                           0.65        26
   macro avg       0.63      0.62      0.63        26
weighted avg       0.65      0.65      0.65        26

macro avg f1-score: 0.6267942583732058
macro avg (UAR): 0.625
Sensitivity:  0.5
Specificity:  0.75
g-mean:  0.6123724356957945
-------- Model Performance ----------: 
accuracy:  [0.65384615 0.61538462 0.76923077 0.57692308 0.76923077 0.65384615
 0.46153846 0.69230769 0.61538462 0.65384615]
gmean:  [0.61237244 0.54772256 0.75415516 0.47434165 0.77459667 0.64226163
 0.4472136  0.67082039 0.58630197 0.61237244]
f1_score:  [0.62679426 0.5751634  0.75625    0.51932773 0.76363636 0.640553
 0.44848485 0.675      0.59375    0.62679426]
UAR:  [0.625   0.575   0.75625 0.525   0.775   0.64375 0.45    0.675   0.59375
 0.625  ]
Cohen Kappa score:  [ 0.25477707  0.15584416  0.5125      0.05298013  0.53012048  0.28220859
 -0.09638554  0.35        0.1875      0.25477707]
arousal and valece = ok
------------- Evaluating model --------------
-------------------------------------
-------------------------------------
participant:  30
-------------------------------------
----- RESULTS ------
-------------------------------------
Window size (sec):  18.0
step (sec):  8.992
overlap:  True
perc. of overlap:  50.044444444444444
overlap duration (sec):  9.008
Number of windows / instances:  129
-rows: alg : KNN = 0; DT = 1; RF = 2; SVM = 3; GBM = 4; BDDAE = 5; DUMMY = 5
columns:
'val_cohen','val_uar', 'val_acc', 'val_gm',  'val_f1',  'aro_cohen','aro_uar', 'aro_acc', 'aro_gm',  'aro_f1'
-------------------------------------------------------------
  v_c   v_u   v_a   v_g   v_f1  a_c   a_u   a_a   a_g   a_f1
[[0.825 0.918 0.915 0.912 0.911 0.371 0.685 0.735 0.604 0.681]
 [0.687 0.819 0.83  0.81  0.819 0.481 0.766 0.797 0.752 0.77 ]
 [0.684 0.884 0.891 0.815 0.881 0.488 0.786 0.829 0.738 0.79 ]
 [0.664 0.816 0.853 0.791 0.826 0.    0.5   0.659 0.    0.397]
 [0.686 0.851 0.868 0.82  0.854 0.374 0.685 0.774 0.516 0.666]
 [0.248 0.624 0.646 0.612 0.623 0.047 0.519 0.635 0.294 0.482]
 [0.    0.5   0.621 0.    0.383 0.    0.5   0.659 0.    0.397]]
last participant performance loaded in numpy array
    
    
-------------------------------
LAST participant's saved data: 
30
-------------------------------
    
    
Saving performance metrics in csv files...
Performance metrics already saved in csv files
---------------------------
KNN performance:
[[0.51957657 0.75952381 0.76025641 0.75253685 0.75715659 0.30232158
  0.64166667 0.80576923 0.42653594 0.62665349]
 [0.53036646 0.76690476 0.76730769 0.75823741 0.76230894 0.39501547
  0.6925     0.73653846 0.61100265 0.67772305]
 [0.61814198 0.80553571 0.82179487 0.78817631 0.80467769 0.51532781
  0.75833333 0.75897436 0.73882425 0.75001541]
 [0.40118493 0.69880952 0.70512821 0.67181343 0.68969958 0.25517259
  0.61861111 0.73782051 0.48921368 0.60855498]
 [0.52327397 0.76194444 0.79166667 0.70089528 0.75103228 0.53590716
  0.7702381  0.76858974 0.75525922 0.76197011]
 [0.4734556  0.73809524 0.73653846 0.71917397 0.72892539 0.5643677
  0.78214286 0.78397436 0.77074644 0.77807942]
 [0.29733754 0.64279762 0.66794872 0.61190861 0.63696131 0.25167213
  0.62619048 0.62692308 0.61821711 0.62220072]
 [0.90567993 0.94444444 0.96153846 0.94145728 0.95262114 0.72599838
  0.87142857 0.86602564 0.86657242 0.86157287]
 [0.24895224 0.61527778 0.73589744 0.47723279 0.60537866 0.24874411
  0.61791667 0.72115385 0.45076298 0.60203716]
 [0.32667363 0.66190476 0.66730769 0.64704492 0.65806885 0.30483464
  0.65214286 0.65833333 0.63540729 0.64713246]
 [0.2780634  0.64083333 0.67435897 0.58200185 0.63024767 0.29487285
  0.64035714 0.675      0.60283616 0.63704627]
 [0.73122604 0.85569444 0.88397436 0.84054154 0.86243609 0.56170298
  0.775      0.7974359  0.75560872 0.77510066]
 [0.51240613 0.7585119  0.76153846 0.74831358 0.75273127 0.30093196
  0.64779762 0.65576923 0.63021574 0.64142619]
 [0.11313255 0.56       0.63589744 0.44092602 0.54248821 0.42968814
  0.71190476 0.72051282 0.69027674 0.70685857]
 [0.25884756 0.62       0.70512821 0.57563083 0.62262181 0.25583482
  0.63527778 0.65064103 0.55189951 0.59784266]
 [0.49178633 0.74636905 0.75961538 0.73538633 0.74352371 0.48288659
  0.73472222 0.78269231 0.70196947 0.73362487]
 [0.40930897 0.70690476 0.71538462 0.68713046 0.69844051 0.34571712
  0.66815476 0.70705128 0.6121368  0.6570336 ]
 [0.13220779 0.56318182 0.81410256 0.23779272 0.55507905 0.53229536
  0.7672619  0.77435897 0.75393756 0.76100316]
 [0.42433962 0.70291667 0.76666667 0.6325577  0.69958742 0.47233672
  0.73440476 0.74423077 0.71469144 0.72941028]
 [0.24281499 0.61652778 0.68076923 0.54622113 0.61192626 0.44888838
  0.72583333 0.75128205 0.66537177 0.70910884]
 [0.13314586 0.5675     0.70512821 0.38743087 0.55602269 0.17987897
  0.58928571 0.59679487 0.54625707 0.57131982]
 [0.34467357 0.67380952 0.67307692 0.65349289 0.66345599 0.4882737
  0.74097222 0.76730769 0.7248547  0.7403325 ]
 [0.3540624  0.67958333 0.68333333 0.65546318 0.66863647 0.31740455
  0.63944444 0.79102564 0.50539311 0.64888015]
 [0.24992851 0.62619048 0.62692308 0.60406832 0.61530018 0.56109083
  0.77845238 0.79038462 0.77141459 0.77953474]
 [0.48501087 0.74       0.74294872 0.71105852 0.72907765 0.58302923
  0.79642857 0.78910256 0.78790584 0.78779387]
 [0.53893278 0.76666667 0.77371795 0.73550794 0.75632846 0.47904083
  0.74184524 0.74423077 0.72983421 0.7356968 ]
 [0.56052369 0.78444444 0.81474359 0.76838942 0.77673823 0.63904691
  0.81904762 0.82051282 0.81483831 0.81836996]
 [0.34368123 0.67833333 0.70448718 0.64518489 0.66604009 0.58782334
  0.78904762 0.80641026 0.77862952 0.7913648 ]
 [0.0686932  0.53160714 0.57435897 0.46500498 0.52402151 0.36346047
  0.68321429 0.69038462 0.61407944 0.65880495]
 [0.82519303 0.9175     0.91474359 0.91177176 0.91073303 0.3708277
  0.68486111 0.73461538 0.60403848 0.68078111]]
KNN mean:
[0.41142071 0.70439376 0.74087607 0.65441173 0.69774222 0.42647977
 0.71114947 0.74179487 0.6639577  0.70324245]
---------------------------
---------------------------
DT performance:
[[0.52393332 0.78333333 0.78461538 0.76731791 0.7803509  0.38327697
  0.70777778 0.78269231 0.66029378 0.69059145]
 [0.48134113 0.755      0.75833333 0.72724571 0.75154735 0.48074789
  0.7225     0.74487179 0.69668749 0.71219046]
 [0.36112069 0.67315476 0.67435897 0.65634865 0.66138944 0.3747979
  0.71190476 0.71410256 0.63999054 0.70739386]
 [0.26303051 0.62380952 0.6275641  0.55191225 0.60152594 0.31001523
  0.65833333 0.70641026 0.66026235 0.63750928]
 [0.53632495 0.75819444 0.76666667 0.76094025 0.74364671 0.50463458
  0.75357143 0.75320513 0.7683219  0.74838661]
 [0.39853584 0.67738095 0.67435897 0.69335771 0.66353903 0.41144739
  0.77380952 0.77435897 0.74181412 0.77257451]
 [0.37356084 0.64863095 0.65128205 0.62431531 0.63436463 0.3261699
  0.66428571 0.66602564 0.64901762 0.66076605]
 [0.86418815 0.92777778 0.93846154 0.90917434 0.92734655 0.59557087
  0.76857143 0.775      0.76846644 0.76569444]
 [0.31119853 0.62166667 0.68141026 0.57140797 0.60325581 0.35061451
  0.73652778 0.77628205 0.68867307 0.73615675]
 [0.35003153 0.68095238 0.69038462 0.67977631 0.66968158 0.21786096
  0.64619048 0.65       0.62657249 0.6432863 ]
 [0.2922121  0.67763889 0.70576923 0.65258861 0.67518172 0.53675422
  0.73184524 0.74423077 0.74525852 0.72254669]
 [0.70848668 0.84763889 0.86858974 0.84642238 0.84904227 0.56257354
  0.79125    0.79807692 0.77063125 0.78548606]
 [0.3906585  0.6575     0.66858974 0.70391003 0.6567169  0.2798061
  0.66755952 0.66538462 0.62076236 0.65708472]
 [0.30750424 0.62694444 0.675      0.58129192 0.61690218 0.26538256
  0.6297619  0.63525641 0.61153536 0.62177962]
 [0.21813439 0.625      0.675      0.5600864  0.61547424 0.25619101
  0.70555556 0.72948718 0.58179727 0.69258888]
 [0.12689873 0.57755952 0.58653846 0.5506275  0.56218283 0.47414171
  0.74819444 0.76602564 0.73011209 0.74116287]
 [0.53780947 0.77244048 0.77692308 0.7625561  0.76850762 0.48435509
  0.76440476 0.77692308 0.75209144 0.76061366]
 [0.34857694 0.71363636 0.86089744 0.54560311 0.70849191 0.42061569
  0.7164881  0.73589744 0.69390837 0.71224967]
 [0.56061798 0.80486111 0.83717949 0.77146186 0.80846216 0.46828969
  0.72315476 0.7224359  0.70390341 0.71870713]
 [0.28650918 0.64180556 0.68141026 0.62140397 0.63734765 0.33300558
  0.64583333 0.66794872 0.64337348 0.63785396]
 [0.09224503 0.55583333 0.67435897 0.39893037 0.5486675  0.21273595
  0.6452381  0.64358974 0.53117113 0.63159091]
 [0.45504361 0.7047619  0.70705128 0.71147622 0.70276307 0.42809531
  0.6875     0.71346154 0.66850361 0.67865406]
 [0.26745711 0.62202381 0.63461538 0.60045728 0.61710526 0.23069915
  0.62638889 0.71282051 0.54605552 0.61211667]
 [0.28292911 0.67619048 0.68333333 0.61812726 0.66677378 0.4544814
  0.73369048 0.73589744 0.68842982 0.72974578]
 [0.47531329 0.71720238 0.71410256 0.712033   0.70928197 0.44558849
  0.73571429 0.72820513 0.69358926 0.72560107]
 [0.4337795  0.73214286 0.73525641 0.7216433  0.72196163 0.57885461
  0.75761905 0.75961538 0.75742255 0.75229827]
 [0.49158273 0.72111111 0.775      0.73183693 0.72079807 0.59523937
  0.79047619 0.79102564 0.79304541 0.78840992]
 [0.06563731 0.54541667 0.56602564 0.48141406 0.52932967 0.56607496
  0.73785714 0.75064103 0.71470772 0.72607352]
 [0.18446382 0.59910714 0.62179487 0.55988155 0.58405863 0.26748352
  0.60613095 0.60384615 0.62303023 0.59608392]
 [0.68688276 0.81875    0.83012821 0.81009953 0.81905165 0.48091288
  0.76611111 0.7974359  0.75179018 0.76962418]]
DT mean:
[0.38920027 0.69291552 0.7175     0.66278826 0.68515829 0.40988057
 0.7118082  0.72737179 0.68404063 0.70449404]
---------------------------
---------------------------
RF performance:
[[0.6287844  0.84404762 0.84615385 0.84222764 0.83508696 0.49941884
  0.70444444 0.81282051 0.49744493 0.69762328]
 [0.44662781 0.76690476 0.76730769 0.72201998 0.76243506 0.49647976
  0.7625     0.78397436 0.77144571 0.7627057 ]
 [0.49611318 0.72589286 0.73653846 0.71901028 0.71444589 0.49977537
  0.72738095 0.72820513 0.71756693 0.72276904]
 [0.39097553 0.6702381  0.675      0.67868178 0.66281993 0.15558627
  0.70361111 0.77435897 0.53930866 0.68359915]
 [0.50629366 0.81625    0.83717949 0.7551292  0.8125879  0.59926842
  0.7952381  0.79166667 0.78365451 0.78821262]
 [0.46196471 0.73928571 0.73589744 0.68317878 0.72786713 0.53684987
  0.775      0.775      0.74631565 0.76620033]
 [0.39579382 0.64327381 0.66794872 0.62216272 0.64080147 0.27115439
  0.68928571 0.68910256 0.62223143 0.68363886]
 [0.88897181 0.93333333 0.94615385 0.931231   0.93690538 0.74187276
  0.85196429 0.86025641 0.75020509 0.85254154]
 [0.37270183 0.61555556 0.70320513 0.54317158 0.61430439 0.30293513
  0.705      0.76858974 0.6225104  0.69788923]
 [0.48135399 0.74166667 0.74423077 0.67573088 0.73150244 0.37468596
  0.63357143 0.64358974 0.66941546 0.6240444 ]
 [0.13332062 0.60208333 0.61923077 0.56888254 0.58647756 0.5851171
  0.70857143 0.72179487 0.78492317 0.70611117]
 [0.67442894 0.85569444 0.86858974 0.83388901 0.85405277 0.55198326
  0.76375    0.78269231 0.76596236 0.75483161]
 [0.2676003  0.73630952 0.74487179 0.62137126 0.73262856 0.32193406
  0.65470238 0.65961538 0.58810238 0.64403885]
 [0.0148982  0.59680556 0.66794872 0.39108982 0.5914376  0.39364951
  0.65119048 0.65128205 0.72423012 0.64570195]
 [0.31784177 0.69305556 0.74487179 0.54196484 0.69204627 0.09954849
  0.6225     0.65961538 0.59118523 0.60682269]
 [0.43182139 0.66642857 0.69102564 0.59118209 0.66077344 0.56298404
  0.70111111 0.75961538 0.66694666 0.69067216]
 [0.69626363 0.8347619  0.84487179 0.84080476 0.83292168 0.61278192
  0.77375    0.79102564 0.77027026 0.76856626]
 [0.17381036 0.59318182 0.83012821 0.33313313 0.57050494 0.48281271
  0.75357143 0.775      0.7506312  0.75302613]
 [0.55685885 0.78125    0.81410256 0.78658911 0.77324377 0.57007367
  0.7347619  0.73782051 0.78240744 0.72573762]
 [0.44209169 0.65652778 0.70512821 0.64609444 0.65133828 0.34265585
  0.67152778 0.6974359  0.63899574 0.66696319]
 [0.00370533 0.50833333 0.68076923 0.33651419 0.48516046 0.13345232
  0.5547619  0.55       0.51337681 0.54769397]
 [0.39688617 0.70595238 0.70641026 0.69163611 0.70118022 0.4048829
  0.71347222 0.75128205 0.66624287 0.71250671]
 [0.2548574  0.64119048 0.64358974 0.59088144 0.63252841 0.27570668
  0.68472222 0.78333333 0.65439109 0.69051302]
 [0.35829032 0.66666667 0.66474359 0.6853296  0.65925824 0.54426878
  0.73869048 0.74358974 0.73162795 0.73180651]
 [0.44753197 0.71779762 0.72179487 0.76251788 0.71378692 0.51929994
  0.8047619  0.79871795 0.77625117 0.79627581]
 [0.30029452 0.69642857 0.6974359  0.71295809 0.69278846 0.47954266
  0.68452381 0.69038462 0.68309305 0.67372015]
 [0.56057052 0.76138889 0.82179487 0.70983815 0.76792607 0.57929342
  0.79047619 0.79038462 0.78805885 0.78522394]
 [0.27240675 0.62013889 0.66602564 0.56626589 0.61296449 0.55819971
  0.72255952 0.74358974 0.75339719 0.71386285]
 [0.24398912 0.62660714 0.65961538 0.49868089 0.6197601  0.36752769
  0.67833333 0.68397436 0.73555849 0.66795049]
 [0.68401677 0.88375    0.89102564 0.81509615 0.8812796  0.48804091
  0.78583333 0.82884615 0.73816684 0.78992303]]
RF mean:
[0.41003551 0.71136003 0.74478632 0.65657544 0.70502715 0.44505941
 0.71805225 0.7409188  0.69413059 0.71170574]
---------------------------
---------------------------
SVM performance:
[[0.15338032 0.57238095 0.60512821 0.35820962 0.49786132 0.
  0.5        0.76730769 0.         0.43416149]
 [0.40116079 0.695      0.71346154 0.65270424 0.68574766 0.23766638
  0.605      0.69871795 0.34557998 0.55277987]
 [0.45246452 0.71166667 0.75961538 0.63214241 0.69923319 0.40406571
  0.70238095 0.70448718 0.68846598 0.69672301]
 [0.40529071 0.69880952 0.71217949 0.65194442 0.68364692 0.
  0.5        0.73653846 0.         0.42388481]
 [0.5397703  0.75944444 0.80705128 0.6697872  0.74618114 0.44542538
  0.725      0.72115385 0.69283002 0.7071541 ]
 [0.25212748 0.62261905 0.63461538 0.49640932 0.57631886 0.60942255
  0.8047619  0.80576923 0.79778195 0.8023539 ]
 [0.         0.5        0.60448718 0.         0.37660401 0.12937258
  0.56547619 0.57371795 0.41349401 0.51135056]
 [0.70865947 0.825      0.89102564 0.79746915 0.84989557 0.37580066
  0.67833333 0.73653846 0.52087495 0.65505817]
 [0.         0.5        0.71346154 0.         0.4161773  0.
  0.5        0.68205128 0.         0.40536797]
 [0.18492153 0.59047619 0.60384615 0.48402046 0.5537449  0.03794304
  0.51785714 0.55833333 0.11944611 0.39493108]
 [0.         0.5        0.62820513 0.         0.385671   0.14117647
  0.56       0.65064103 0.26832816 0.48803258]
 [0.10216718 0.5425     0.66666667 0.18416408 0.46614719 0.
  0.5        0.62051282 0.         0.38285714]
 [0.2681791  0.62577381 0.66666667 0.5005454  0.59358519 0.
  0.5        0.56602564 0.         0.36112782]
 [0.         0.5        0.68205128 0.         0.40536797 0.31348996
  0.65119048 0.67371795 0.53366561 0.60582314]
 [0.         0.5        0.70576923 0.         0.41360813 0.
  0.5        0.65128205 0.         0.39411255]
 [0.         0.5        0.59679487 0.         0.37350877 0.
  0.5        0.66666667 0.         0.39974026]
 [0.         0.5        0.57371795 0.         0.36422306 0.
  0.5        0.59679487 0.         0.37350877]
 [0.         0.5        0.84487179 0.         0.45795455 0.04705882
  0.52       0.61217949 0.08944272 0.41065163]
 [0.         0.5        0.68205128 0.         0.40536797 0.
  0.5        0.55064103 0.         0.35493734]
 [0.         0.5        0.67435897 0.         0.40255411 0.
  0.5        0.62820513 0.         0.385671  ]
 [0.         0.5        0.75961538 0.         0.43159232 0.
  0.5        0.51923077 0.         0.34149123]
 [0.39985036 0.70119048 0.69679487 0.67639363 0.68683344 0.
  0.5        0.65128205 0.         0.39411255]
 [0.         0.5        0.56602564 0.         0.36112782 0.
  0.5        0.75961538 0.         0.43159232]
 [0.         0.5        0.52692308 0.         0.34491228 0.28151646
  0.63452381 0.675      0.52696696 0.61095742]
 [0.         0.5        0.55064103 0.         0.35493734 0.42542692
  0.71428571 0.71217949 0.69196979 0.70308206]
 [0.         0.5        0.52692308 0.         0.34491228 0.44458134
  0.71678571 0.73653846 0.68223607 0.71038844]
 [0.03157895 0.5125     0.71346154 0.05       0.43555618 0.59315609
  0.79761905 0.7974359  0.79345156 0.79510989]
 [0.         0.5        0.63589744 0.         0.38848485 0.09952963
  0.54285714 0.63461538 0.19740963 0.46139098]
 [0.         0.5        0.61217949 0.         0.37969925 0.02352941
  0.51       0.56602564 0.04472136 0.37660401]
 [0.66373419 0.81625    0.8525641  0.79149175 0.82612229 0.
  0.5        0.65897436 0.         0.39692641]]
SVM mean:
[0.1521095  0.5724537  0.67356838 0.23150939 0.49691923 0.15363871
 0.57486905 0.66373932 0.24688883 0.49872942]
---------------------------
---------------------------
GBM performance:
[[6.19697722e-01 7.83333333e-01 7.92307692e-01 7.61875269e-01
  7.75565701e-01 3.13371616e-01 6.28333333e-01 8.21153846e-01
  3.60419028e-01 6.17967250e-01]
 [4.03929149e-01 6.96190476e-01 7.12179487e-01 6.55492890e-01
  6.88318161e-01 3.49951299e-01 6.51250000e-01 7.12820513e-01
  5.20779581e-01 6.29475583e-01]
 [4.79168744e-01 7.28690476e-01 7.67307692e-01 6.69825998e-01
  7.20904651e-01 3.49874484e-01 6.65476190e-01 6.73076923e-01
  6.13418290e-01 6.56232387e-01]
 [3.18687292e-01 6.50000000e-01 6.58974359e-01 6.03920711e-01
  6.31888846e-01 1.05491991e-01 5.40833333e-01 7.51923077e-01
  1.65470054e-01 4.97216262e-01]
 [5.81187069e-01 7.82500000e-01 8.20512821e-01 7.04726478e-01
  7.70198413e-01 6.29387454e-01 7.98809524e-01 7.98076923e-01
  8.08722712e-01 7.95270147e-01]
 [3.80778669e-01 6.77380952e-01 6.75000000e-01 6.46110791e-01
  6.57799978e-01 4.33853908e-01 7.22619048e-01 7.27564103e-01
  6.98423484e-01 7.14808908e-01]
 [3.27349905e-01 6.54880952e-01 7.05769231e-01 5.61532995e-01
  6.40341294e-01 2.97761204e-01 6.57142857e-01 6.58974359e-01
  6.49485023e-01 6.53970343e-01]
 [8.88971808e-01 9.16666667e-01 9.23076923e-01 9.30785301e-01
  9.12692884e-01 6.07571988e-01 8.09047619e-01 8.21794872e-01
  8.08300056e-01 8.10075545e-01]
 [1.36740072e-01 5.78333333e-01 7.44230769e-01 2.20710678e-01
  5.39894949e-01 2.26811168e-01 5.99166667e-01 7.21153846e-01
  4.32248370e-01 5.81425534e-01]
 [3.44864669e-01 6.70238095e-01 6.82692308e-01 6.01913562e-01
  6.52559834e-01 2.89980226e-01 6.42142857e-01 6.58333333e-01
  6.06946428e-01 6.33491174e-01]
 [2.19156613e-01 6.08194444e-01 6.73717949e-01 4.79806995e-01
  5.90270284e-01 5.73656073e-01 7.56130952e-01 7.91025641e-01
  7.52694161e-01 7.60680478e-01]
 [7.05896359e-01 8.51944444e-01 8.83974359e-01 8.32331161e-01
  8.59420566e-01 6.44830230e-01 8.28750000e-01 8.44230769e-01
  8.17806383e-01 8.30874607e-01]
 [2.91955474e-01 6.46250000e-01 6.75641026e-01 5.87546353e-01
  6.40940782e-01 1.69257441e-01 5.83035714e-01 6.02564103e-01
  5.21172616e-01 5.64619956e-01]
 [1.32568138e-01 5.39166667e-01 6.83333333e-01 2.52034578e-01
  5.03643579e-01 3.35825271e-01 6.55952381e-01 6.66025641e-01
  6.13744167e-01 6.48390351e-01]
 [7.51879699e-04 5.05555556e-01 6.98717949e-01 5.77350269e-02
  4.35123283e-01 7.84108899e-02 5.36388889e-01 6.58333333e-01
  2.53212806e-01 4.88338650e-01]
 [9.02226723e-02 5.44940476e-01 6.27564103e-01 2.58514887e-01
  4.71660401e-01 3.83232410e-01 6.76944444e-01 7.75641026e-01
  5.35328947e-01 6.67660914e-01]
 [6.36349806e-01 8.20119048e-01 8.23076923e-01 8.18300167e-01
  8.16202425e-01 2.64164506e-01 6.24464286e-01 6.67948718e-01
  5.46506379e-01 6.17367868e-01]
 [0.00000000e+00 5.00000000e-01 8.44871795e-01 7.07106781e-02
  4.57954545e-01 4.76420079e-01 7.24345238e-01 7.51282051e-01
  7.03904714e-01 7.23878809e-01]
 [3.07763072e-01 6.37916667e-01 7.35256410e-01 5.22663336e-01
  6.17897406e-01 4.33443482e-01 7.09642857e-01 7.28846154e-01
  6.84388559e-01 7.00843463e-01]
 [3.00350493e-01 6.29305556e-01 7.20512821e-01 5.37156732e-01
  6.27600865e-01 2.30696052e-01 6.03333333e-01 6.75000000e-01
  4.90298487e-01 5.87141444e-01]
 [6.92722372e-02 5.28333333e-01 7.67948718e-01 1.12507283e-01
  4.78114060e-01 1.84753143e-01 6.01190476e-01 6.02564103e-01
  5.82292834e-01 5.93361916e-01]
 [3.89527710e-01 6.94047619e-01 6.98717949e-01 6.75796240e-01
  6.88224969e-01 4.17067630e-01 7.08888889e-01 7.75000000e-01
  6.39332173e-01 7.13678939e-01]
 [2.08133287e-01 5.98869048e-01 6.35256410e-01 4.71118841e-01
  5.60443628e-01 1.56228759e-01 5.73333333e-01 7.83333333e-01
  2.12507283e-01 5.32066629e-01]
 [3.23646726e-01 6.63095238e-01 6.66666667e-01 6.35825325e-01
  6.54859413e-01 5.43941410e-01 7.70535714e-01 7.75641026e-01
  7.34161878e-01 7.64407006e-01]
 [2.68181165e-01 6.30476190e-01 6.50641026e-01 5.83795328e-01
  6.16968514e-01 4.90443935e-01 7.50000000e-01 7.42948718e-01
  7.26134587e-01 7.39402264e-01]
 [5.07067814e-01 7.50000000e-01 7.58333333e-01 7.29196701e-01
  7.45870535e-01 4.91279145e-01 7.51964286e-01 7.59615385e-01
  7.23312125e-01 7.49016278e-01]
 [4.29651784e-01 6.76666667e-01 7.82692308e-01 6.00763447e-01
  6.90050125e-01 6.08627484e-01 8.03571429e-01 8.06410256e-01
  7.87231472e-01 8.02531635e-01]
 [1.17331430e-01 5.43750000e-01 6.51282051e-01 2.72893912e-01
  4.92489758e-01 4.49230903e-01 7.11726190e-01 7.50641026e-01
  6.69749978e-01 7.11465836e-01]
 [2.48578129e-01 6.11607143e-01 6.82692308e-01 4.75537663e-01
  5.81736203e-01 4.21868241e-01 7.25773810e-01 7.37179487e-01
  6.89330836e-01 7.19902026e-01]
 [6.85835351e-01 8.51250000e-01 8.67948718e-01 8.20071633e-01
  8.53997220e-01 3.73558122e-01 6.84583333e-01 7.74358974e-01
  5.16089380e-01 6.66161393e-01]]
GBM mean:
[0.34712051 0.66565675 0.73369658 0.53837337 0.64578778 0.37769968
 0.68317923 0.73378205 0.59544709 0.67239079]
---------------------------
---------------------------
BDDAE performance:
[[-0.10231188  0.44880952  0.45384615  0.43619646  0.4448814   0.04094515
   0.51833333  0.73461538  0.1990598   0.49012856]
 [ 0.21217297  0.60833333  0.60384615  0.59883104  0.60079406  0.49721571
   0.74375     0.76538462  0.73537045  0.7471769 ]
 [ 0.0462352   0.52181818  0.54615385  0.48519886  0.51348394  0.33724892
   0.66785714  0.67307692  0.65684124  0.66478522]
 [ 0.11309816  0.55654762  0.56153846  0.54619993  0.55325966  0.23007837
   0.61390977  0.71923077  0.50913907  0.60059972]
 [ 0.38554066  0.685       0.72307692  0.65556065  0.68678061  0.37692308
   0.68846154  0.68846154  0.67949015  0.68438566]
 [ 0.54505823  0.7702381   0.77692308  0.75454653  0.76698152 -0.04414233
   0.47857143  0.47307692  0.4506864   0.46181425]
 [ 0.19176954  0.6         0.61153846  0.57815161  0.58785717 -0.01538462
   0.49230769  0.49230769  0.47915014  0.48580897]
 [ 0.37329158  0.66319444  0.76923077  0.59213274  0.67474841  0.02607796
   0.514375    0.55        0.45458131  0.50546153]
 [ 0.43441639  0.71390977  0.77307692  0.6957649   0.71313406  0.64929458
   0.80555556  0.86538462  0.77747183  0.81941808]
 [ 0.09678942  0.54880952  0.55        0.53920058  0.54403057  0.20192855
   0.6         0.60384615  0.58666648  0.59517382]
 [ 0.14560623  0.569375    0.61538462  0.52191315  0.56407339  0.22998484
   0.61        0.65384615  0.55965277  0.60308798]
 [ 0.15414956  0.57875817  0.62692308  0.53805676  0.57284443  0.36212304
   0.68125     0.7         0.66752988  0.67776642]
 [ 0.04803792  0.52575758  0.52692308  0.51747122  0.51935319  0.23574897
   0.61787879  0.63461538  0.59106795  0.61041093]
 [ 0.08280607  0.53194444  0.63076923  0.43640791  0.52981543  0.16023639
   0.58095238  0.58076923  0.57096101  0.57529249]
 [-0.10013703  0.45208333  0.57307692  0.30455761  0.44007549  0.22363058
   0.61111111  0.66923077  0.5476289   0.59904695]
 [ 0.13103867  0.561875    0.60384615  0.46962711  0.54033471  0.1523632
   0.56143791  0.66923077  0.40877111  0.54224466]
 [ 0.56088551  0.78181818  0.78461538  0.76407355  0.77323015  0.19034846
   0.590625    0.63461538  0.51720236  0.57156526]
 [ 0.22261825  0.61477273  0.81538462  0.46975269  0.60437504 -0.03396357
   0.484375    0.51538462  0.43713268  0.4723316 ]
 [ 0.29091131  0.65347222  0.68846154  0.63706674  0.64324696  0.31443657
   0.65595238  0.66153846  0.64029448  0.65098415]
 [ 0.17193779  0.57916667  0.67692308  0.50054613  0.57451677 -0.04590808
   0.47875     0.51538462  0.43010828  0.46906302]
 [ 0.21315147  0.6         0.73461538  0.53413869  0.60501076  0.18065613
   0.59047619  0.59230769  0.58473854  0.58782029]
 [ 0.01538462  0.50769231  0.50769231  0.4711107   0.49075615  0.14458542
   0.56732026  0.64615385  0.46461852  0.55412032]
 [ 0.01707931  0.50939394  0.51923077  0.49217619  0.50316497  0.49555753
   0.725       0.84615385  0.67285203  0.7420138 ]
 [ 0.11957925  0.56011905  0.56153846  0.55013447  0.55519976  0.3501871
   0.67454545  0.68461538  0.66473679  0.67236798]
 [ 0.06407138  0.53214286  0.53461538  0.52070064  0.52738108 -0.03076923
   0.48461538  0.48461538  0.47707434  0.48096437]
 [ 0.22336342  0.60952381  0.61923077  0.58689078  0.60319872  0.06318906
   0.53151515  0.54615385  0.49911939  0.52181825]
 [ 0.44395931  0.72569444  0.76923077  0.69905851  0.71714142  0.51538462
   0.75769231  0.75769231  0.73908434  0.75044708]
 [-0.0548923   0.47058824  0.52307692  0.42286867  0.46421687  0.42642124
   0.704375    0.74230769  0.6755272   0.70672285]
 [ 0.29576119  0.65125     0.66538462  0.63180257  0.6418652   0.36727144
   0.68242424  0.69230769  0.67294574  0.68093357]
 [ 0.2484322   0.624375    0.64615385  0.61221585  0.62257539  0.0474948
   0.51928105  0.63461538  0.29375226  0.48183531]]
BDDAE mean:
[0.18632681 0.59188212 0.63307692 0.55207844 0.58594424 0.2216388
 0.60775664 0.6475641  0.55477518 0.60018633]
---------------------------
---------------------------
DUMMY performance:
[[0.         0.5        0.54294872 0.         0.35184211 0.
  0.5        0.76730769 0.         0.43416149]
 [0.         0.5        0.54294872 0.         0.35184211 0.
  0.5        0.62051282 0.         0.38285714]
 [0.         0.5        0.58141026 0.         0.3673183  0.
  0.5        0.52692308 0.         0.34491228]
 [0.         0.5        0.53461538 0.         0.34833333 0.
  0.5        0.73653846 0.         0.42388481]
 [0.         0.5        0.62820513 0.         0.385671   0.
  0.5        0.51153846 0.         0.33807018]
 [0.         0.5        0.52692308 0.         0.34491228 0.
  0.5        0.53461538 0.         0.34833333]
 [0.         0.5        0.60448718 0.         0.37660401 0.
  0.5        0.51153846 0.         0.33807018]
 [0.         0.5        0.68974359 0.         0.40818182 0.
  0.5        0.60448718 0.         0.37660401]
 [0.         0.5        0.71346154 0.         0.4161773  0.
  0.5        0.68205128 0.         0.40536797]
 [0.         0.5        0.51923077 0.         0.34149123 0.
  0.5        0.54294872 0.         0.35184211]
 [0.         0.5        0.62820513 0.         0.385671   0.
  0.5        0.60448718 0.         0.37660401]
 [0.         0.5        0.63589744 0.         0.38848485 0.
  0.5        0.62051282 0.         0.38285714]
 [0.         0.5        0.56602564 0.         0.36112782 0.
  0.5        0.56602564 0.         0.36112782]
 [0.         0.5        0.68205128 0.         0.40536797 0.
  0.5        0.53461538 0.         0.34833333]
 [0.         0.5        0.70576923 0.         0.41360813 0.
  0.5        0.65128205 0.         0.39411255]
 [0.         0.5        0.59679487 0.         0.37350877 0.
  0.5        0.66666667 0.         0.39974026]
 [0.         0.5        0.57371795 0.         0.36422306 0.
  0.5        0.59679487 0.         0.37350877]
 [0.         0.5        0.84487179 0.         0.45795455 0.
  0.5        0.59679487 0.         0.37350877]
 [0.         0.5        0.68205128 0.         0.40536797 0.
  0.5        0.55064103 0.         0.35493734]
 [0.         0.5        0.67435897 0.         0.40255411 0.
  0.5        0.62820513 0.         0.385671  ]
 [0.         0.5        0.75961538 0.         0.43159232 0.
  0.5        0.51923077 0.         0.34149123]
 [0.         0.5        0.50384615 0.         0.33464912 0.
  0.5        0.65128205 0.         0.39411255]
 [0.         0.5        0.56602564 0.         0.36112782 0.
  0.5        0.75961538 0.         0.43159232]
 [0.         0.5        0.52692308 0.         0.34491228 0.
  0.5        0.56602564 0.         0.36112782]
 [0.         0.5        0.55064103 0.         0.35493734 0.
  0.5        0.46538462 0.         0.31754386]
 [0.         0.5        0.52692308 0.         0.34491228 0.
  0.5        0.55833333 0.         0.35803258]
 [0.         0.5        0.70576923 0.         0.41360813 0.
  0.5        0.50384615 0.         0.33464912]
 [0.         0.5        0.63589744 0.         0.38848485 0.
  0.5        0.60448718 0.         0.37660401]
 [0.         0.5        0.61217949 0.         0.37969925 0.
  0.5        0.55833333 0.         0.35803258]
 [0.         0.5        0.62051282 0.         0.38285714 0.
  0.5        0.65897436 0.         0.39692641]]
DUMMY mean:
[0.         0.5        0.61606838 0.         0.37956741 0.
 0.5        0.59666667 0.         0.3721539 ]
---------------------------
Current folder: C:\Users\Javier\Dropbox\c_sldl_1_2_43_3
-------------------------------------
----- RESULTS from .csv files ------
-------------------------------------
---------------------------
ALG Means: 
-rows: alg : KNN = 0; DT = 1; RF = 2; SVM = 3; GBM = 4; BDDAE = 5; DUMMY = 5
columns:
'val_cohen','val_uar', 'val_acc', 'val_gm',  'val_f1',  'aro_cohen','aro_uar', 'aro_acc', 'aro_gm',  'aro_f1'
-------------------------------------------------------------
  v_c   v_u   v_a   v_g   v_f1  a_c   a_u   a_a   a_g   a_f1
[[0.411 0.704 0.741 0.654 0.698 0.426 0.711 0.742 0.664 0.703]
 [0.389 0.693 0.717 0.663 0.685 0.41  0.712 0.727 0.684 0.704]
 [0.41  0.711 0.745 0.657 0.705 0.445 0.718 0.741 0.694 0.712]
 [0.152 0.572 0.674 0.232 0.497 0.154 0.575 0.664 0.247 0.499]
 [0.347 0.666 0.734 0.538 0.646 0.378 0.683 0.734 0.595 0.672]
 [0.186 0.592 0.633 0.552 0.586 0.222 0.608 0.648 0.555 0.6  ]
 [0.    0.5   0.616 0.    0.38  0.    0.5   0.597 0.    0.372]]
-------------------------------------------------------------
Standard Deviation of each metric:
[[0.198 0.099 0.083 0.148 0.102 0.136 0.07  0.061 0.11  0.074]
 [0.178 0.087 0.086 0.11  0.091 0.118 0.051 0.052 0.067 0.054]
 [0.196 0.097 0.082 0.143 0.1   0.151 0.061 0.065 0.084 0.063]
 [0.219 0.104 0.093 0.3   0.151 0.198 0.099 0.075 0.294 0.142]
 [0.215 0.106 0.077 0.229 0.123 0.156 0.079 0.063 0.17  0.09 ]
 [0.17  0.085 0.097 0.1   0.086 0.186 0.09  0.098 0.131 0.097]
 [0.    0.    0.08  0.    0.03  0.    0.    0.075 0.    0.029]]
-------------------------------------------------------------
std_dev/mean [percentage]:
[[ 48.  14.  11.  23.  15.  32.  10.   8.  17.  11.]
 [ 46.  13.  12.  17.  13.  29.   7.   7.  10.   8.]
 [ 48.  14.  11.  22.  14.  34.   8.   9.  12.   9.]
 [144.  18.  14. 130.  30. 129.  17.  11. 119.  28.]
 [ 62.  16.  10.  43.  19.  41.  12.   9.  29.  13.]
 [ 91.  14.  15.  18.  15.  84.  15.  15.  24.  16.]
 [  0.   0.  13.   0.   8.   0.   0.  13.   0.   8.]]
-------------------------------------
Current folder: C:\Users\Javier\Dropbox\c_sldl_1_2_43_3
-------------------------------------
----- RESULTS ------
-------------------------------------
Window size (sec):  18.0
step (sec):  8.992
overlap:  True
perc. of overlap:  50.044444444444444
overlap duration (sec):  9.008
Number of windows / instances:  129
Elapsed time: 1032.1795364499092 minutes
Elapsed time: 17.202992274165155 hours
