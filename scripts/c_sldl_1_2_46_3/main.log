2024-05-16 09:43:49.346742: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-05-16 09:43:53.117526: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-05-16 09:44:02.781746: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
    
    
-------------------------------
participant:  1
-------------------------------
    
    
participant:  1
corriendo en PC gamer:
Window size (sec):  20.0
step (sec):  10.0
overlap:  True
perc. of overlap:  50.0
overlap duration (sec):  10.0
['gsr_chunks', 'ppg_chunks', 'val_chunks', 'aro_chunks', 'time_chunks', 'tag_chunks', 'video']
C:\Users\Javier\Dropbox\c_sldl_1_2_46_3\functions.py:880: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!
You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.
A typical example is when you are setting values in a column of a DataFrame, like:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer (type)        â”‚ Output Shape      â”‚    Param # â”‚ Connected to      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ inputGSR            â”‚ (None, 20000, 1)  â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ inputPPG            â”‚ (None, 20000, 1)  â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ sequential_1198     â”‚ (None, 1250, 6)   â”‚        411 â”‚ inputGSR[0][0]    â”‚
â”‚ (Sequential)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ sequential_1199     â”‚ (None, 1250, 6)   â”‚        411 â”‚ inputPPG[0][0]    â”‚
â”‚ (Sequential)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ concatenate_599     â”‚ (None, 1250, 12)  â”‚          0 â”‚ sequential_1198[â€¦ â”‚
â”‚ (Concatenate)       â”‚                   â”‚            â”‚ sequential_1199[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ permute_599         â”‚ (None, 12, 1250)  â”‚          0 â”‚ concatenate_599[â€¦ â”‚
â”‚ (Permute)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ flatten_599         â”‚ (None, 15000)     â”‚          0 â”‚ permute_599[0][0] â”‚
â”‚ (Flatten)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout_599         â”‚ (None, 15000)     â”‚          0 â”‚ flatten_599[0][0] â”‚
â”‚ (Dropout)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_599 (Dense)   â”‚ (None, 1)         â”‚     15,001 â”‚ dropout_599[0][0] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 15,823 (61.81 KB)
 Trainable params: 15,823 (61.81 KB)
 Non-trainable params: 0 (0.00 B)
Epoch 1/10

[1m 1/82[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1:41[0m 1s/step - binary_accuracy: 1.0000 - loss: 0.6145
[1m 6/82[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.6778 - loss: 0.7112
[1m11/82[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.6300 - loss: 0.7194
[1m17/82[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.6174 - loss: 0.7121
[1m22/82[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.6202 - loss: 0.7146
[1m27/82[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.6269 - loss: 0.7173
[1m32/82[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.6237 - loss: 0.7294
[1m36/82[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.6244 - loss: 0.7314
[1m41/82[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.6283 - loss: 0.7278
[1m46/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.6311 - loss: 0.7221
[1m51/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.6325 - loss: 0.7187
[1m55/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.6320 - loss: 0.7177
[1m60/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.6300 - loss: 0.7172
[1m65/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.6272 - loss: 0.7167
[1m70/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.6232 - loss: 0.7168
[1m76/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.6196 - loss: 0.7167
[1m81/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.6185 - loss: 0.7158
[1m82/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m2s[0m 15ms/step - binary_accuracy: 0.6183 - loss: 0.7153 - val_binary_accuracy: 0.7000 - val_loss: 0.7052
Epoch 2/10

[1m 1/82[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 47ms/step - binary_accuracy: 1.0000 - loss: 0.1631
[1m 5/82[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 13ms/step - binary_accuracy: 0.4567 - loss: 1.0605
[1m 9/82[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - binary_accuracy: 0.4433 - loss: 1.0234
[1m14/82[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.4695 - loss: 0.9728
[1m18/82[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - binary_accuracy: 0.4829 - loss: 0.9430
[1m23/82[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.5062 - loss: 0.9044
[1m29/82[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.5366 - loss: 0.8616
[1m34/82[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.5514 - loss: 0.8375
[1m38/82[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.5597 - loss: 0.8232
[1m43/82[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.5695 - loss: 0.8066
[1m48/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.5768 - loss: 0.7932
[1m53/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.5838 - loss: 0.7805
[1m59/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.5904 - loss: 0.7691
[1m64/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.5972 - loss: 0.7593
[1m68/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.6032 - loss: 0.7507
[1m73/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.6099 - loss: 0.7419
[1m78/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.6145 - loss: 0.7357
[1m82/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 13ms/step - binary_accuracy: 0.6188 - loss: 0.7301 - val_binary_accuracy: 0.7000 - val_loss: 0.5987
Epoch 3/10

[1m 1/82[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 47ms/step - binary_accuracy: 0.0000e+00 - loss: 0.7891
[1m 6/82[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.5917 - loss: 0.5291    
[1m11/82[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.6980 - loss: 0.4946
[1m16/82[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.7247 - loss: 0.5005
[1m21/82[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.7455 - loss: 0.5005
[1m26/82[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.7465 - loss: 0.5100
[1m31/82[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.7484 - loss: 0.5166
[1m36/82[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.7482 - loss: 0.5201
[1m41/82[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.7483 - loss: 0.5207
[1m46/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.7485 - loss: 0.5214
[1m51/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.7491 - loss: 0.5214
[1m55/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.7490 - loss: 0.5221
[1m60/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.7484 - loss: 0.5238
[1m65/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.7470 - loss: 0.5256
[1m69/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.7453 - loss: 0.5273
[1m75/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.7420 - loss: 0.5296
[1m80/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.7395 - loss: 0.5308
[1m82/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 13ms/step - binary_accuracy: 0.7379 - loss: 0.5317 - val_binary_accuracy: 0.7000 - val_loss: 0.6396
Epoch 4/10

[1m 1/82[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 31ms/step - binary_accuracy: 1.0000 - loss: 0.4024
[1m 6/82[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.7583 - loss: 0.4950
[1m11/82[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.7990 - loss: 0.4663
[1m16/82[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.7903 - loss: 0.4752
[1m21/82[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.7580 - loss: 0.4977
[1m26/82[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.7402 - loss: 0.5079
[1m31/82[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.7375 - loss: 0.5089
[1m36/82[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.7371 - loss: 0.5079
[1m41/82[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.7354 - loss: 0.5086
[1m46/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.7336 - loss: 0.5092
[1m51/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.7305 - loss: 0.5095
[1m56/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.7277 - loss: 0.5100
[1m61/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.7245 - loss: 0.5118
[1m66/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.7217 - loss: 0.5143
[1m71/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.7209 - loss: 0.5160
[1m76/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.7209 - loss: 0.5172
[1m81/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.7214 - loss: 0.5176
[1m82/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 13ms/step - binary_accuracy: 0.7217 - loss: 0.5175 - val_binary_accuracy: 0.7000 - val_loss: 0.7003
Epoch 5/10

[1m 1/82[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 47ms/step - binary_accuracy: 0.0000e+00 - loss: 1.0065
[1m 7/82[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.3565 - loss: 0.6355    
[1m12/82[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - binary_accuracy: 0.3995 - loss: 0.6092
[1m17/82[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.4079 - loss: 0.6026
[1m22/82[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.4128 - loss: 0.6060
[1m27/82[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.4222 - loss: 0.6050
[1m32/82[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.4394 - loss: 0.5996
[1m37/82[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.4610 - loss: 0.5891
[1m42/82[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.4829 - loss: 0.5767
[1m48/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.5017 - loss: 0.5727
[1m53/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.5154 - loss: 0.5691
[1m58/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.5294 - loss: 0.5648
[1m63/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.5418 - loss: 0.5612
[1m68/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.5530 - loss: 0.5578
[1m73/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.5628 - loss: 0.5546
[1m78/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.5707 - loss: 0.5525
[1m82/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 13ms/step - binary_accuracy: 0.5787 - loss: 0.5500 - val_binary_accuracy: 0.5000 - val_loss: 0.6997
Epoch 6/10

[1m 1/82[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 31ms/step - binary_accuracy: 1.0000 - loss: 0.2585
[1m 5/82[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 16ms/step - binary_accuracy: 0.6533 - loss: 0.5480
[1m10/82[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 14ms/step - binary_accuracy: 0.6975 - loss: 0.5463
[1m15/82[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.7062 - loss: 0.5321
[1m19/82[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - binary_accuracy: 0.7197 - loss: 0.5174
[1m24/82[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - binary_accuracy: 0.7401 - loss: 0.4975
[1m28/82[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - binary_accuracy: 0.7556 - loss: 0.4849
[1m34/82[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - binary_accuracy: 0.7708 - loss: 0.4740
[1m39/82[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - binary_accuracy: 0.7733 - loss: 0.4735
[1m44/82[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.7731 - loss: 0.4746
[1m49/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.7697 - loss: 0.4788
[1m54/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.7661 - loss: 0.4836
[1m59/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.7639 - loss: 0.4868
[1m64/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.7635 - loss: 0.4871
[1m69/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.7620 - loss: 0.4874
[1m74/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.7606 - loss: 0.4871
[1m78/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.7595 - loss: 0.4868
[1m82/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 14ms/step - binary_accuracy: 0.7591 - loss: 0.4854 - val_binary_accuracy: 0.7000 - val_loss: 0.7888
Epoch 7/10

[1m 1/82[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 31ms/step - binary_accuracy: 1.0000 - loss: 0.1624
[1m 5/82[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 16ms/step - binary_accuracy: 0.7433 - loss: 0.6747
[1m10/82[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 14ms/step - binary_accuracy: 0.6610 - loss: 0.6799
[1m15/82[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.6658 - loss: 0.6419
[1m20/82[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.6795 - loss: 0.6125
[1m25/82[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.6915 - loss: 0.5909
[1m30/82[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.6929 - loss: 0.5910
[1m35/82[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.6900 - loss: 0.5917
[1m40/82[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.6912 - loss: 0.5875
[1m45/82[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.6945 - loss: 0.5825
[1m50/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.6996 - loss: 0.5764
[1m55/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.7043 - loss: 0.5713
[1m61/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.7084 - loss: 0.5656
[1m65/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.7109 - loss: 0.5621
[1m69/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.7130 - loss: 0.5587
[1m75/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.7165 - loss: 0.5530
[1m81/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.7192 - loss: 0.5478
[1m82/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 13ms/step - binary_accuracy: 0.7201 - loss: 0.5460 - val_binary_accuracy: 0.7000 - val_loss: 0.7696
Epoch 8/10

[1m 1/82[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 31ms/step - binary_accuracy: 1.0000 - loss: 0.2703
[1m 6/82[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.8417 - loss: 0.3344
[1m11/82[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8147 - loss: 0.3565
[1m15/82[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.7801 - loss: 0.3771
[1m21/82[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.7495 - loss: 0.3936
[1m26/82[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.7369 - loss: 0.4048
[1m31/82[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.7225 - loss: 0.4188
[1m36/82[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.7120 - loss: 0.4308
[1m41/82[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.7065 - loss: 0.4395
[1m46/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.7037 - loss: 0.4448
[1m51/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.7040 - loss: 0.4470
[1m56/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.7039 - loss: 0.4482
[1m61/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.7054 - loss: 0.4474
[1m66/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.7067 - loss: 0.4469
[1m70/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.7067 - loss: 0.4473
[1m75/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.7069 - loss: 0.4475
[1m80/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.7055 - loss: 0.4486
[1m82/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 13ms/step - binary_accuracy: 0.7051 - loss: 0.4490 - val_binary_accuracy: 0.6000 - val_loss: 0.7884
Epoch 9/10

[1m 1/82[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 31ms/step - binary_accuracy: 1.0000 - loss: 0.0572
[1m 5/82[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 16ms/step - binary_accuracy: 0.9100 - loss: 0.2555
[1m11/82[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.8839 - loss: 0.2997
[1m15/82[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8751 - loss: 0.3169
[1m20/82[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8758 - loss: 0.3212
[1m24/82[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8743 - loss: 0.3219
[1m29/82[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8743 - loss: 0.3171
[1m34/82[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8662 - loss: 0.3231
[1m39/82[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8557 - loss: 0.3308
[1m44/82[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8477 - loss: 0.3379
[1m49/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8420 - loss: 0.3443
[1m54/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8388 - loss: 0.3488
[1m59/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8361 - loss: 0.3521
[1m64/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8348 - loss: 0.3543
[1m69/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8331 - loss: 0.3572
[1m74/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8317 - loss: 0.3598
[1m80/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.8307 - loss: 0.3619
[1m82/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 13ms/step - binary_accuracy: 0.8299 - loss: 0.3632 - val_binary_accuracy: 0.7000 - val_loss: 0.9293
Epoch 10/10

[1m 1/82[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 47ms/step - binary_accuracy: 1.0000 - loss: 0.0643
[1m 7/82[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - binary_accuracy: 0.9796 - loss: 0.1622
[1m11/82[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - binary_accuracy: 0.9482 - loss: 0.1748
[1m15/82[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.9329 - loss: 0.1937
[1m20/82[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.9087 - loss: 0.2281
[1m25/82[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8819 - loss: 0.2652
[1m30/82[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8658 - loss: 0.2895
[1m35/82[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8564 - loss: 0.3065
[1m39/82[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8466 - loss: 0.3203
[1m44/82[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8369 - loss: 0.3354
[1m49/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8301 - loss: 0.3464
[1m55/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8258 - loss: 0.3536
[1m60/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8233 - loss: 0.3569
[1m64/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8224 - loss: 0.3582
[1m69/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8216 - loss: 0.3593
[1m74/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8207 - loss: 0.3613
[1m79/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 13ms/step - binary_accuracy: 0.8206 - loss: 0.3627
[1m82/82[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 13ms/step - binary_accuracy: 0.8203 - loss: 0.3636 - val_binary_accuracy: 0.5000 - val_loss: 0.8516

[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 110ms/step
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 110ms/step
predicted [0.7676074  0.9027056  0.34983099 0.254065   0.5889665  0.04228193
 0.40808108 0.33140147 0.79492503 0.7423086  0.3557267  0.682768
 0.87382895 0.52065086 0.6116758  0.7797873  0.73659706 0.02802833
 0.7422422  0.886512   0.09825231 0.17938535 0.3338957 ]
predicted [1 1 0 0 1 0 0 0 1 1 0 1 1 1 1 1 1 0 1 1 0 0 0]
expected [ True  True  True False  True  True False False  True  True  True  True
  True False False  True False False  True False False  True  True]
accuracy: 0.6086956521739131
confusion matrix: 
[[5 4]
 [5 9]]
              precision    recall  f1-score   support

       False       0.50      0.56      0.53         9
        True       0.69      0.64      0.67        14

    accuracy                           0.61        23
   macro avg       0.60      0.60      0.60        23
weighted avg       0.62      0.61      0.61        23

macro avg f1-score: 0.5964912280701754
macro avg (UAR): 0.5992063492063493
Sensitivity:  0.5555555555555556
Specificity:  0.6428571428571429
g-mean:  0.5976143046671969
-------- Model Performance ----------: 
accuracy:  [0.56521739 0.73913043 0.69565217 0.39130435 0.43478261 0.56521739
 0.47826087 0.60869565 0.73913043 0.60869565]
gmean:  [0.53452248 0.72374686 0.6172134  0.25197632 0.35634832 0.53452248
 0.48795004 0.5976143  0.69006556 0.5976143 ]
f1_score:  [0.54365079 0.72619048 0.65376344 0.32916667 0.39350913 0.54365079
 0.47727273 0.59649123 0.7125     0.59649123]
UAR:  [0.54365079 0.72619048 0.65079365 0.34126984 0.3968254  0.54365079
 0.49206349 0.59920635 0.70634921 0.59920635]
Cohen Kappa score:  [ 0.08730159  0.45238095  0.32067511 -0.33057851 -0.21052632  0.08730159
 -0.01470588  0.19455253  0.42975207  0.19455253]
arousal and valece = ok
------------- Evaluating model --------------
-------------------------------------
-------------------------------------
participant:  30
-------------------------------------
----- RESULTS ------
-------------------------------------
Window size (sec):  20.0
step (sec):  10.0
overlap:  True
perc. of overlap:  50.0
overlap duration (sec):  10.0
Number of windows / instances:  115
-rows: alg : KNN = 0; DT = 1; RF = 2; SVM = 3; GBM = 4; BDDAE = 5; DUMMY = 5
columns:
'val_cohen','val_uar', 'val_acc', 'val_gm',  'val_f1',  'aro_cohen','aro_uar', 'aro_acc', 'aro_gm',  'aro_f1'
-------------------------------------------------------------
  v_c   v_u   v_a   v_g   v_f1  a_c   a_u   a_a   a_g   a_f1
[[ 0.838  0.925  0.921  0.922  0.918  0.424  0.708  0.755  0.648  0.704]
 [ 0.625  0.836  0.842  0.848  0.833  0.571  0.75   0.783  0.741  0.745]
 [ 0.73   0.818  0.834  0.841  0.808  0.534  0.776  0.808  0.767  0.774]
 [ 0.509  0.744  0.79   0.66   0.734  0.     0.5    0.661  0.     0.398]
 [ 0.53   0.776  0.795  0.707  0.76   0.454  0.709  0.782  0.654  0.715]
 [ 0.121  0.56   0.583  0.539  0.557 -0.013  0.493  0.613  0.245  0.447]
 [ 0.     0.5    0.61   0.     0.379  0.     0.5    0.661  0.     0.398]]
last participant performance loaded in numpy array
    
    
-------------------------------
LAST participant's saved data: 
30
-------------------------------
    
    
Saving performance metrics in csv files...
Performance metrics already saved in csv files
---------------------------
KNN performance:
[[0.63168711 0.81285714 0.81742424 0.80071127 0.81193556 0.33808068
  0.65694444 0.79242424 0.5378072  0.65915893]
 [0.49862775 0.75190476 0.7469697  0.74051982 0.74276335 0.40129538
  0.695      0.74015152 0.61619018 0.6834081 ]
 [0.57380303 0.77809524 0.79772727 0.75023275 0.77779887 0.3590169
  0.68166667 0.67727273 0.66438487 0.67087357]
 [0.44655852 0.72       0.72878788 0.70236597 0.71771132 0.29152357
  0.63819444 0.7469697  0.55667501 0.63584156]
 [0.6652829  0.81875    0.85227273 0.79731097 0.82801587 0.52528247
  0.76333333 0.76515152 0.74294371 0.75442557]
 [0.41715347 0.71190476 0.70606061 0.70053239 0.7025974  0.68221826
  0.83833333 0.84393939 0.82654742 0.83704407]
 [0.30109596 0.65607143 0.68560606 0.57466252 0.63056094 0.36111559
  0.67833333 0.68636364 0.65412977 0.67150849]
 [0.87369015 0.92916667 0.94848485 0.92445255 0.93639472 0.612645
  0.80928571 0.81515152 0.80199663 0.80421458]
 [0.26335068 0.62083333 0.7469697  0.43583123 0.60095656 0.14370219
  0.56875    0.66969697 0.39842577 0.56091036]
 [0.33158114 0.66690476 0.66893939 0.6516686  0.65996281 0.25463232
  0.6297619  0.63333333 0.61091068 0.62014277]
 [0.31546263 0.65910714 0.68636364 0.62587609 0.64935909 0.45320827
  0.7225     0.75984848 0.67538831 0.71257564]
 [0.73733001 0.86607143 0.88636364 0.84586069 0.86365718 0.69467913
  0.83642857 0.86136364 0.82346471 0.84450514]
 [0.56882098 0.78309524 0.78939394 0.77801279 0.78343212 0.04357567
  0.52059524 0.53787879 0.49871999 0.51577617]
 [0.05627285 0.5264881  0.5969697  0.37118254 0.50057398 0.44498738
  0.71785714 0.72878788 0.69234369 0.71298174]
 [0.26325494 0.62916667 0.725      0.46354468 0.60558553 0.22136216
  0.60922619 0.66136364 0.56717139 0.60227048]
 [0.20016164 0.59464286 0.64393939 0.49605374 0.57600733 0.44963887
  0.72053571 0.76818182 0.67951944 0.71636629]
 [0.43047699 0.7147619  0.72121212 0.69434488 0.70632548 0.44468032
  0.71785714 0.74848485 0.66004061 0.71308123]
 [0.2025     0.605      0.86363636 0.26324555 0.58156414 0.50361238
  0.75464286 0.76439394 0.7265921  0.74255189]
 [0.48345001 0.75327381 0.77651515 0.70556832 0.73422306 0.52858739
  0.76619048 0.76439394 0.75222051 0.757891  ]
 [0.38108925 0.68035714 0.73863636 0.63950724 0.6805824  0.29210641
  0.64714286 0.6719697  0.61694895 0.63687639]
 [0.12775412 0.57083333 0.69772727 0.42191675 0.55273797 0.16670611
  0.58333333 0.58712121 0.55751943 0.57236944]
 [0.42987057 0.71666667 0.71212121 0.69354201 0.70311022 0.49404213
  0.74410714 0.76742424 0.73587443 0.74564507]
 [0.24217967 0.6172619  0.65151515 0.54261931 0.60615663 0.28643459
  0.62708333 0.76742424 0.45517507 0.62226842]
 [0.09835565 0.5502381  0.5469697  0.54520555 0.54517483 0.61068075
  0.80357143 0.80909091 0.79627627 0.80347569]
 [0.67167948 0.83190476 0.84318182 0.81938252 0.83253483 0.67950088
  0.83833333 0.84318182 0.82060079 0.83379176]
 [0.35725093 0.68       0.67651515 0.64543116 0.66137918 0.56368729
  0.78095238 0.78409091 0.772568   0.77845793]
 [0.52646959 0.75208333 0.81515152 0.7218204  0.75960434 0.53512642
  0.76833333 0.76742424 0.76419081 0.76583472]
 [0.27279325 0.63767857 0.67272727 0.57733025 0.62846244 0.61451383
  0.80988095 0.81666667 0.7900041  0.80073964]
 [0.07655783 0.53625    0.60151515 0.3973077  0.51739729 0.27999023
  0.63809524 0.64469697 0.61486349 0.62853896]
 [0.83790185 0.92464286 0.92121212 0.92189772 0.91810134 0.42449839
  0.7077381  0.75530303 0.64811325 0.7037712 ]]
KNN mean:
[0.40941543 0.7032004  0.74219697 0.64159793 0.69382223 0.42337103
 0.7091336  0.73931818 0.66858689 0.70357656]
---------------------------
---------------------------
DT performance:
[[0.56381168 0.77452381 0.775      0.76731847 0.77248973 0.22124683
  0.61736111 0.72954545 0.57562937 0.62005725]
 [0.581635   0.73571429 0.73939394 0.77120025 0.73140693 0.38401991
  0.72678571 0.74848485 0.74137825 0.72625566]
 [0.47451356 0.74321429 0.75757576 0.73499327 0.74358059 0.27844733
  0.685      0.68409091 0.63530923 0.68172994]
 [0.39329596 0.71833333 0.72954545 0.65263808 0.7052467  0.25511657
  0.56944444 0.64242424 0.48006712 0.53952381]
 [0.69701488 0.83678571 0.85227273 0.82068737 0.83908388 0.56484418
  0.73333333 0.72878788 0.73966864 0.72189255]
 [0.48658824 0.71785714 0.71969697 0.61738662 0.70848235 0.48958309
  0.77166667 0.77348485 0.73518554 0.76808941]
 [0.40077059 0.62875    0.65530303 0.66693767 0.62641789 0.38890541
  0.69666667 0.69772727 0.69266831 0.68920746]
 [0.82047503 0.93333333 0.94015152 0.94241794 0.92997082 0.58251038
  0.76642857 0.78787879 0.76462957 0.76673443]
 [0.30031565 0.62916667 0.67727273 0.59335545 0.6213352  0.34119924
  0.67827381 0.70984848 0.63875822 0.67163906]
 [0.45646606 0.6852381  0.68787879 0.71744047 0.68155594 0.34915979
  0.68666667 0.69393939 0.59565303 0.67281718]
 [0.15931969 0.63732143 0.66136364 0.56163377 0.62585034 0.4504787
  0.73803571 0.75530303 0.72558525 0.72996436]
 [0.63176229 0.805      0.82424242 0.81341815 0.79949843 0.40858924
  0.72017857 0.73939394 0.72409052 0.71699245]
 [0.23789232 0.62857143 0.63257576 0.61059541 0.62449412 0.05264704
  0.56107143 0.57348485 0.53784361 0.55789488]
 [0.04037173 0.5235119  0.58030303 0.44027632 0.51644141 0.28422802
  0.66761905 0.66893939 0.62087747 0.66077561]
 [0.3579553  0.69583333 0.74772727 0.6011496  0.69225957 0.27473877
  0.63869048 0.67348485 0.61609349 0.63638081]
 [0.30211475 0.64607143 0.67121212 0.61916905 0.64131911 0.54279417
  0.72589286 0.775      0.74137816 0.7250687 ]
 [0.76796748 0.89464286 0.89621212 0.87245362 0.89243534 0.54624996
  0.80559524 0.80909091 0.78426493 0.79876638]
 [0.55385338 0.695      0.86439394 0.5475566  0.64749146 0.4028161
  0.71619048 0.72272727 0.69704574 0.70306138]
 [0.46107435 0.73333333 0.79090909 0.70049636 0.71442577 0.58665994
  0.77785714 0.775      0.75962779 0.76872849]
 [0.3556686  0.69553571 0.73712121 0.62967206 0.69010295 0.34803956
  0.65821429 0.6719697  0.63909418 0.64735317]
 [0.06413459 0.53680556 0.67878788 0.3111436  0.52934591 0.08732981
  0.50833333 0.51060606 0.46557246 0.49172189]
 [0.29697278 0.71666667 0.71893939 0.7040682  0.71045899 0.42380489
  0.69660714 0.7219697  0.63023674 0.67573049]
 [0.38699752 0.67488095 0.68106061 0.72861584 0.66888195 0.38724509
  0.70138889 0.76666667 0.64614644 0.69709715]
 [0.4035608  0.7097619  0.70757576 0.68516104 0.70366855 0.47776545
  0.75928571 0.75454545 0.75584147 0.7508153 ]
 [0.34769234 0.69797619 0.70909091 0.65923743 0.69800339 0.6006427
  0.76666667 0.76742424 0.76343797 0.76323621]
 [0.4278707  0.71333333 0.71515152 0.73746786 0.70730297 0.33756747
  0.63761905 0.63636364 0.6499396  0.62322233]
 [0.44293528 0.72291667 0.775      0.61221868 0.71878305 0.63496818
  0.815      0.81666667 0.78862617 0.81184676]
 [0.24548926 0.61535714 0.62878788 0.58346506 0.60378968 0.42156128
  0.70428571 0.71590909 0.65921661 0.69066074]
 [0.17857212 0.61160714 0.62878788 0.58229966 0.5982036  0.38353676
  0.65857143 0.66136364 0.61619016 0.65471861]
 [0.62499396 0.83571429 0.84242424 0.84817457 0.83288129 0.57137736
  0.74970238 0.78333333 0.74111747 0.74521069]]
DT mean:
[0.41540286 0.70642526 0.73419192 0.67108828 0.6991736  0.40260244
 0.69794775 0.71651515 0.67203912 0.69023977]
---------------------------
---------------------------
RF performance:
[[ 0.69840027  0.83452381  0.83560606  0.82078994  0.8321806   0.49581297
   0.73541667  0.81969697  0.67436998  0.74654621]
 [ 0.54559122  0.74404762  0.75075758  0.78387547  0.7276433   0.53111038
   0.73339286  0.77348485  0.75449965  0.73130135]
 [ 0.4076068   0.70857143  0.72348485  0.68396141  0.70956474  0.43780746
   0.77166667  0.775       0.73994739  0.77164724]
 [ 0.52171147  0.72785714  0.73787879  0.76068574  0.72103147  0.13701482
   0.60972222  0.74848485  0.31301467  0.62001419]
 [ 0.59697869  0.80642857  0.83333333  0.81087695  0.8069106   0.53454258
   0.74666667  0.74848485  0.74487927  0.73745671]
 [ 0.48264654  0.72738095  0.72954545  0.7021492   0.72605395  0.51027469
   0.77833333  0.78181818  0.7794008   0.774498  ]
 [ 0.27207632  0.6875      0.71136364  0.622813    0.68069893  0.37153906
   0.66333333  0.66287879  0.62858993  0.6589677 ]
 [ 0.87589603  0.90625     0.93030303  0.95533507  0.90808123  0.57703728
   0.74642857  0.77272727  0.79542416  0.74543184]
 [ 0.32055061  0.67916667  0.74924242  0.60184243  0.68211759  0.37797777
   0.57827381  0.65227273  0.55442023  0.5761788 ]
 [ 0.48220166  0.77619048  0.77272727  0.71679919  0.76816517  0.40518167
   0.645       0.65984848  0.70187814  0.64158023]
 [ 0.22793556  0.70214286  0.72272727  0.5861505   0.69285535  0.56147181
   0.80892857  0.81666667  0.77449407  0.80400165]
 [ 0.64344782  0.86839286  0.87727273  0.8248509   0.85962053  0.55678259
   0.80160714  0.81212121  0.73135134  0.79914646]
 [ 0.47181059  0.64119048  0.65        0.68612121  0.63257937  0.25426983
   0.60607143  0.61590909  0.5946354   0.59697955]
 [ 0.00227037  0.52916667  0.59772727  0.48128052  0.51926507  0.38229649
   0.71190476  0.71287879  0.71192231  0.70080753]
 [ 0.41018635  0.66041667  0.72272727  0.49561841  0.6511543   0.26832975
   0.62678571  0.68181818  0.56665248  0.61735591]
 [ 0.29576735  0.62892857  0.65075758  0.66127955  0.61420761  0.58097689
   0.76964286  0.80151515  0.6933325   0.76552653]
 [ 0.73551366  0.87595238  0.88030303  0.89297277  0.87572039  0.67747388
   0.78321429  0.79242424  0.75917491  0.77808928]
 [ 0.00921053  0.635       0.88030303  0.25652476  0.61686147  0.39407156
   0.7497619   0.76439394  0.6254684   0.74142039]
 [ 0.53699701  0.78541667  0.82045455  0.64072198  0.77945845  0.53785123
   0.81714286  0.81893939  0.76958567  0.81502803]
 [ 0.43750113  0.7922619   0.80984848  0.63851092  0.78713936  0.22632086
   0.61071429  0.64469697  0.61782838  0.60850382]
 [ 0.14826362  0.54861111  0.71590909  0.2840305   0.53145535 -0.03768456
   0.55333333  0.55378788  0.47529142  0.53804473]
 [ 0.39094952  0.715       0.71439394  0.69613005  0.70549811  0.54628442
   0.70767857  0.73030303  0.72894531  0.70173901]
 [ 0.21990672  0.69059524  0.70606061  0.6393102   0.68322095  0.2216687
   0.62291667  0.73030303  0.66677714  0.62360153]
 [ 0.45852775  0.63738095  0.63484848  0.65797145  0.63304196  0.57544613
   0.72809524  0.73106061  0.7194855   0.71730825]
 [ 0.52045546  0.76404762  0.76590909  0.76056643  0.7569013   0.56007587
   0.82833333  0.83409091  0.83604412  0.82698218]
 [ 0.3899672   0.69        0.68863636  0.69278833  0.68006716  0.4179942
   0.68761905  0.69621212  0.71825394  0.68003413]
 [ 0.51946085  0.79375     0.825       0.71712518  0.78396359  0.63255812
   0.78666667  0.79015152  0.81020726  0.78536103]
 [ 0.19056917  0.63696429  0.65757576  0.51925135  0.63327655  0.39347918
   0.76238095  0.77272727  0.78921848  0.75433105]
 [ 0.24897061  0.60428571  0.64469697  0.58962027  0.59616444  0.30269378
   0.65261905  0.65454545  0.67948686  0.64777556]
 [ 0.73000789  0.81785714  0.83409091  0.84106138  0.80801542  0.53419925
   0.77559524  0.80833333  0.76681755  0.77424424]]
RF mean:
[0.42637929 0.72050926 0.75244949 0.66736717 0.71343048 0.43216196
 0.7133082  0.73858586 0.69071324 0.7093301 ]
---------------------------
---------------------------
SVM performance:
[[0.15210754 0.57166667 0.59242424 0.27097277 0.47440126 0.
  0.5        0.775      0.         0.43639098]
 [0.34019207 0.66452381 0.68636364 0.59914146 0.64447928 0.25685364
  0.6125     0.70530303 0.41812031 0.5759162 ]
 [0.42823869 0.7        0.74848485 0.58491537 0.67844108 0.45616614
  0.72833333 0.73106061 0.71298843 0.72295177]
 [0.42025241 0.705      0.7219697  0.65298988 0.68954989 0.
  0.5        0.74772727 0.         0.42770677]
 [0.61147515 0.78285714 0.83333333 0.7516611  0.7988457  0.54602357
  0.77333333 0.775      0.75426477 0.76557803]
 [0.20836727 0.60119048 0.61742424 0.48075063 0.54903361 0.64555159
  0.82       0.82575758 0.80430574 0.81682706]
 [0.         0.5        0.62651515 0.         0.38497076 0.16125
  0.58166667 0.59242424 0.38546385 0.51308123]
 [0.57586453 0.7625     0.85378788 0.6722274  0.77182491 0.3207858
  0.64392857 0.71363636 0.55335159 0.63232935]
 [0.         0.5        0.70530303 0.         0.41338346 0.
  0.5        0.68787879 0.         0.40730994]
 [0.16115288 0.57666667 0.60227273 0.32378065 0.48790653 0.
  0.5        0.56439394 0.         0.36068111]
 [0.         0.5        0.62651515 0.         0.38497076 0.02978723
  0.5125     0.63560606 0.05       0.40725834]
 [0.05957447 0.525      0.6530303  0.1        0.43270382 0.
  0.5        0.62651515 0.         0.38497076]
 [0.15426163 0.57166667 0.62651515 0.29986602 0.49455059 0.
  0.5        0.58257576 0.         0.36787066]
 [0.         0.5        0.66060606 0.         0.39766082 0.22117941
  0.605      0.63409091 0.37342915 0.52971172]
 [0.         0.5        0.6969697  0.         0.41052632 0.
  0.5        0.66060606 0.         0.39766082]
 [0.         0.5        0.60984848 0.         0.37865497 0.
  0.5        0.65151515 0.         0.39444444]
 [0.         0.5        0.58257576 0.         0.36787066 0.
  0.5        0.60075758 0.         0.3750602 ]
 [0.         0.5        0.87121212 0.         0.46536797 0.02978723
  0.5125     0.60984848 0.05       0.39734778]
 [0.         0.5        0.68787879 0.         0.40730994 0.
  0.5        0.55606061 0.         0.35717234]
 [0.         0.5        0.66969697 0.         0.40087719 0.
  0.5        0.62651515 0.         0.38497076]
 [0.         0.5        0.76590909 0.         0.43349624 0.
  0.5        0.51363636 0.         0.33909314]
 [0.29567792 0.64666667 0.64469697 0.56627064 0.60790598 0.
  0.5        0.64318182 0.         0.39128655]
 [0.         0.5        0.58257576 0.         0.36787066 0.
  0.5        0.73863636 0.         0.42481203]
 [0.         0.5        0.53106061 0.         0.34664603 0.48203886
  0.7352381  0.75075758 0.69622991 0.72746337]
 [0.         0.5        0.57348485 0.         0.36427589 0.45680031
  0.72666667 0.73712121 0.64314098 0.70023668]
 [0.         0.5        0.51363636 0.         0.33909314 0.41785576
  0.7002381  0.725      0.64933249 0.69058428]
 [0.         0.5        0.6969697  0.         0.41052632 0.56326096
  0.78       0.78257576 0.77330013 0.77925713]
 [0.         0.5        0.62651515 0.         0.38497076 0.18682518
  0.58166667 0.6530303  0.34569959 0.52270032]
 [0.         0.5        0.62651515 0.         0.38497076 0.
  0.5        0.55606061 0.         0.35717234]
 [0.50944473 0.74357143 0.79015152 0.65988492 0.73439174 0.
  0.5        0.66060606 0.         0.39766082]]
SVM mean:
[0.13055364 0.56171032 0.66747475 0.19874869 0.48024923 0.15913886
 0.57711905 0.66876263 0.2403209  0.4995169 ]
---------------------------
---------------------------
GBM performance:
[[ 0.55593185  0.76666667  0.775       0.75159023  0.76108142  0.3711693
   0.65277778  0.83636364  0.46368485  0.66173768]
 [ 0.43460483  0.71690476  0.72348485  0.7057932   0.71418359  0.38276165
   0.69178571  0.74015152  0.66908115  0.69596639]
 [ 0.4919245   0.73571429  0.77348485  0.66843517  0.72210901  0.42403723
   0.71166667  0.71363636  0.67383771  0.70557054]
 [ 0.40426244  0.69833333  0.71287879  0.65130202  0.67799253 -0.01578947
   0.49375     0.73863636  0.          0.42449039]
 [ 0.67537095  0.81875     0.85984848  0.79481656  0.83271825  0.559958
   0.78        0.78181818  0.76453764  0.77463453]
 [ 0.4729473   0.73857143  0.73787879  0.71606684  0.72943556  0.64945991
   0.82333333  0.82651515  0.81619502  0.8197916 ]
 [ 0.27226672  0.65089286  0.71439394  0.45559058  0.61569436  0.40821371
   0.695       0.69621212  0.68295669  0.69023282]
 [ 0.84047503  0.91875     0.93939394  0.91307009  0.91975257  0.5167776
   0.73357143  0.76515152  0.68434204  0.7321018 ]
 [ 0.22037843  0.60625     0.75681818  0.35142415  0.59162133 -0.01688837
   0.49375     0.66212121  0.09007199  0.42607106]
 [ 0.37506788  0.66619048  0.67121212  0.64593893  0.65941864  0.38842977
   0.67404762  0.68863636  0.64208227  0.66544386]
 [ 0.41345436  0.69839286  0.74848485  0.61786129  0.68945219  0.577561
   0.7825      0.80909091  0.74803938  0.78166783]
 [ 0.65351301  0.81107143  0.85151515  0.78118426  0.82184266  0.56889224
   0.77071429  0.8030303   0.73821709  0.77260662]
 [ 0.34427935  0.66047619  0.67575758  0.64793518  0.6596473   0.25874211
   0.62285714  0.66287879  0.57494153  0.61655148]
 [ 0.16173316  0.57113095  0.68560606  0.285515    0.53411507  0.30676326
   0.65238095  0.66060606  0.61518097  0.63770757]
 [-0.01688837  0.50625     0.68787879  0.04677072  0.44181287  0.17143645
   0.57291667  0.68863636  0.33545557  0.53940746]
 [-0.02737195  0.48785714  0.57424242  0.14570996  0.41364373  0.36639864
   0.66785714  0.75909091  0.53918517  0.65511505]
 [ 0.74807566  0.87892857  0.88712121  0.86975533  0.88022741  0.46839022
   0.73714286  0.76893939  0.68639367  0.73516106]
 [-0.01        0.495       0.86212121  0.          0.46274892  0.5104548
   0.74154762  0.76439394  0.7217337   0.73826161]
 [ 0.23666653  0.60208333  0.73030303  0.43912223  0.59135523  0.53293534
   0.76904762  0.78030303  0.73102276  0.76436508]
 [ 0.24839867  0.60863095  0.70984848  0.40415746  0.58058099  0.3925895
   0.68178571  0.74242424  0.58655425  0.67282538]
 [ 0.05357143  0.50555556  0.75757576  0.05773503  0.45492481  0.03592627
   0.50833333  0.51136364  0.48151008  0.49472611]
 [ 0.43125706  0.71666667  0.71287879  0.68101368  0.70140859  0.44349978
   0.70821429  0.77424242  0.58284087  0.69362162]
 [ 0.30941055  0.65916667  0.69772727  0.54000845  0.63464286  0.01052632
   0.50416667  0.71287879  0.10487548  0.45244115]
 [ 0.46233899  0.72952381  0.73257576  0.68244432  0.71701604  0.68803842
   0.84928571  0.84242424  0.83320569  0.84115773]
 [ 0.36532337  0.67380952  0.70681818  0.62805744  0.66900749  0.70340452
   0.86        0.86136364  0.85248887  0.85784299]
 [ 0.3554275   0.67833333  0.67878788  0.63763683  0.66479409  0.37838028
   0.70214286  0.71666667  0.66958929  0.69296814]
 [ 0.34944382  0.64583333  0.75681818  0.50841986  0.63626493  0.66960644
   0.835       0.83484848  0.81582526  0.82804862]
 [ 0.2290331   0.61        0.6719697   0.53047134  0.59473156  0.46510645
   0.71595238  0.75075758  0.64639059  0.7075852 ]
 [ 0.30955073  0.65232143  0.7219697   0.54513474  0.6436718   0.3555323
   0.65952381  0.6719697   0.61639037  0.64922741]
 [ 0.53010267  0.77607143  0.79545455  0.70694257  0.76000125  0.45423046
   0.70863095  0.78181818  0.65392911  0.71479293]]
GBM mean:
[0.36301832 0.67613757 0.74366162 0.54699678 0.65919657 0.4008848
 0.69332275 0.74489899 0.6006853  0.68140406]
---------------------------
---------------------------
BDDAE performance:
[[-1.96904303e-01  4.01893939e-01  4.04347826e-01  3.86925331e-01
   3.96115225e-01  4.19178566e-02  5.20000000e-01  7.34782609e-01
   2.44818819e-01  5.03020070e-01]
 [ 3.05199099e-01  6.53409091e-01  6.52173913e-01  6.42661864e-01
   6.47536068e-01  5.45861373e-01  7.73809524e-01  7.82608696e-01
   7.62460517e-01  7.69114108e-01]
 [ 8.12937789e-02  5.39230769e-01  5.65217391e-01  4.70315840e-01
   5.18617537e-01  1.05795507e-01  5.52272727e-01  5.56521739e-01
   5.26983077e-01  5.42000658e-01]
 [ 3.83754498e-02  5.18560606e-01  5.21739130e-01  4.99365395e-01
   5.10556757e-01  5.18577615e-02  5.22058824e-01  7.00000000e-01
   2.78787575e-01  5.03777215e-01]
 [ 4.00777512e-01  7.00396825e-01  7.17391304e-01  6.87188949e-01
   6.97573149e-01  4.99842668e-01  7.51893939e-01  7.47826087e-01
   7.42804664e-01  7.45290200e-01]
 [ 6.12896331e-01  8.03787879e-01  8.08695652e-01  7.87917929e-01
   8.01215383e-01  3.28922138e-03  5.01893939e-01  5.00000000e-01
   4.76299076e-01  4.88102919e-01]
 [ 1.30490236e-01  5.65079365e-01  5.91304348e-01  5.40116910e-01
   5.60506873e-01 -2.12703878e-02  4.88636364e-01  4.91304348e-01
   4.66992086e-01  4.79909210e-01]
 [ 3.92583328e-01  6.78571429e-01  7.65217391e-01  6.35939757e-01
   6.90699889e-01  1.71874504e-02  5.06746032e-01  5.34782609e-01
   4.70920897e-01  5.00353013e-01]
 [ 4.51502865e-01  7.11160714e-01  7.82608696e-01  6.78846632e-01
   7.21944474e-01  4.81692643e-01  7.04017857e-01  8.17391304e-01
   6.34904981e-01  7.27114387e-01]
 [ 1.62382381e-02  5.07954545e-01  5.08695652e-01  5.01010138e-01
   5.04678541e-01  1.55219164e-01  5.74230769e-01  5.95652174e-01
   5.45670778e-01  5.69977982e-01]
 [-2.91639029e-03  4.95238095e-01  5.30434783e-01  4.49394527e-01
   4.85626643e-01  1.48826339e-01  5.66666667e-01  6.39130435e-01
   4.41184063e-01  5.38159879e-01]
 [ 1.19903441e-01  5.57500000e-01  6.13043478e-01  5.17123054e-01
   5.54638663e-01  2.20337922e-01  6.17857143e-01  6.21739130e-01
   5.66912811e-01  5.96138544e-01]
 [ 4.41973641e-02  5.22307692e-01  5.17391304e-01  5.17933394e-01
   5.15498292e-01  3.16755012e-01  6.58846154e-01  6.65217391e-01
   6.47176945e-01  6.54072167e-01]
 [ 2.00201524e-01  6.03750000e-01  6.39130435e-01  5.41312110e-01
   5.86508681e-01  2.90246157e-01  6.45833333e-01  6.43478261e-01
   6.41106671e-01  6.42064921e-01]
 [-3.40932041e-02  4.84375000e-01  5.95652174e-01  3.44786392e-01
   4.75991627e-01  2.07614871e-01  5.98750000e-01  6.47826087e-01
   5.66831868e-01  5.97838901e-01]
 [ 3.14868513e-02  5.11904762e-01  5.43478261e-01  4.60227635e-01
   4.97871363e-01  1.45930785e-01  5.67083333e-01  6.52173913e-01
   3.92968831e-01  5.33463467e-01]
 [ 4.56445515e-01  7.30769231e-01  7.34782609e-01  7.09199295e-01
   7.20283614e-01  1.44498814e-01  5.69047619e-01  6.13043478e-01
   5.13975603e-01  5.58714410e-01]
 [ 1.30235874e-01  5.83333333e-01  8.17391304e-01  3.23932912e-01
   5.53203819e-01 -1.58232216e-01  4.26984127e-01  4.95652174e-01
   2.32340331e-01  3.88832613e-01]
 [ 7.54239498e-04  4.97321429e-01  5.91304348e-01  4.00088636e-01
   4.89929797e-01  2.54598306e-01  6.28461538e-01  6.34782609e-01
   6.16332383e-01  6.23733065e-01]
 [ 1.10178202e-01  5.51250000e-01  6.39130435e-01  4.28748060e-01
   5.34680491e-01 -1.02647672e-01  4.52777778e-01  5.17391304e-01
   2.57296511e-01  4.10959246e-01]
 [-7.42785004e-03  5.00000000e-01  6.69565217e-01  2.75885738e-01
   4.71393564e-01  1.97362192e-01  5.98484848e-01  6.00000000e-01
   5.88131587e-01  5.94167145e-01]
 [ 1.87984054e-01  5.93560606e-01  5.95652174e-01  5.77426343e-01
   5.86802941e-01  4.54313898e-02  5.22083333e-01  6.08695652e-01
   3.97254078e-01  5.03708971e-01]
 [-1.25506185e-01  4.38846154e-01  4.60869565e-01  3.91284270e-01
   4.27794602e-01  4.16758384e-01  6.89705882e-01  8.04347826e-01
   6.05876256e-01  6.98167578e-01]
 [ 2.21169187e-01  6.09848485e-01  6.13043478e-01  6.00086126e-01
   6.06971141e-01  1.87735191e-01  5.93560606e-01  5.95652174e-01
   5.89031029e-01  5.92223548e-01]
 [ 1.21249145e-01  5.58846154e-01  5.78260870e-01  5.30309829e-01
   5.52893385e-01  1.06519412e-01  5.53409091e-01  5.56521739e-01
   5.37588970e-01  5.46909156e-01]
 [ 2.20134077e-01  6.09090909e-01  6.13043478e-01  5.92096524e-01
   6.03247891e-01  1.64231370e-01  5.80000000e-01  5.95652174e-01
   5.58184990e-01  5.76295668e-01]
 [ 4.02547469e-01  6.85714286e-01  7.69565217e-01  6.44417264e-01
   6.96593105e-01  5.05202729e-01  7.49621212e-01  7.56521739e-01
   7.26566097e-01  7.43999796e-01]
 [ 5.94822438e-02  5.30555556e-01  5.56521739e-01  5.08952020e-01
   5.27505662e-01  3.85245619e-01  6.86904762e-01  7.13043478e-01
   6.65262164e-01  6.87578524e-01]
 [ 2.52845875e-01  6.23809524e-01  6.43478261e-01  6.08335838e-01
   6.21292903e-01  3.00556590e-01  6.48076923e-01  6.60869565e-01
   6.31244353e-01  6.45191522e-01]
 [ 1.21070565e-01  5.59920635e-01  5.82608696e-01  5.39157407e-01
   5.57268648e-01 -1.28260220e-02  4.93333333e-01  6.13043478e-01
   2.44988022e-01  4.47168903e-01]]
BDDAE mean:
[0.15807982 0.57759957 0.62072464 0.5263662  0.57051469 0.18818461
 0.59143492 0.63652174 0.51902987 0.58026826]
---------------------------
---------------------------
DUMMY performance:
[[0.         0.5        0.53106061 0.         0.34664603 0.
  0.5        0.775      0.         0.43639098]
 [0.         0.5        0.53939394 0.         0.3501548  0.
  0.5        0.61818182 0.         0.38181287]
 [0.         0.5        0.58257576 0.         0.36787066 0.
  0.5        0.52272727 0.         0.34313725]
 [0.         0.5        0.53106061 0.         0.34664603 0.
  0.5        0.74772727 0.         0.42770677]
 [0.         0.5        0.62651515 0.         0.38497076 0.
  0.5        0.51363636 0.         0.33909314]
 [0.         0.5        0.53106061 0.         0.34664603 0.
  0.5        0.52272727 0.         0.34313725]
 [0.         0.5        0.62651515 0.         0.38497076 0.
  0.5        0.51363636 0.         0.33909314]
 [0.         0.5        0.6969697  0.         0.41052632 0.
  0.5        0.61818182 0.         0.38181287]
 [0.         0.5        0.70530303 0.         0.41338346 0.
  0.5        0.68787879 0.         0.40730994]
 [0.         0.5        0.53106061 0.         0.34664603 0.
  0.5        0.56439394 0.         0.36068111]
 [0.         0.5        0.62651515 0.         0.38497076 0.
  0.5        0.62651515 0.         0.38497076]
 [0.         0.5        0.63484848 0.         0.38812865 0.
  0.5        0.62651515 0.         0.38497076]
 [0.         0.5        0.56439394 0.         0.36068111 0.
  0.5        0.58257576 0.         0.36787066]
 [0.         0.5        0.66060606 0.         0.39766082 0.
  0.5        0.53939394 0.         0.3501548 ]
 [0.         0.5        0.6969697  0.         0.41052632 0.
  0.5        0.66060606 0.         0.39766082]
 [0.         0.5        0.60984848 0.         0.37865497 0.
  0.5        0.65151515 0.         0.39444444]
 [0.         0.5        0.58257576 0.         0.36787066 0.
  0.5        0.60075758 0.         0.3750602 ]
 [0.         0.5        0.87121212 0.         0.46536797 0.
  0.5        0.60075758 0.         0.3750602 ]
 [0.         0.5        0.68787879 0.         0.40730994 0.
  0.5        0.55606061 0.         0.35717234]
 [0.         0.5        0.66969697 0.         0.40087719 0.
  0.5        0.62651515 0.         0.38497076]
 [0.         0.5        0.76590909 0.         0.43349624 0.
  0.5        0.51363636 0.         0.33909314]
 [0.         0.5        0.47727273 0.         0.32291667 0.
  0.5        0.64318182 0.         0.39128655]
 [0.         0.5        0.58257576 0.         0.36787066 0.
  0.5        0.73863636 0.         0.42481203]
 [0.         0.5        0.53106061 0.         0.34664603 0.
  0.5        0.53939394 0.         0.3501548 ]
 [0.         0.5        0.57348485 0.         0.36427589 0.
  0.5        0.51363636 0.         0.33909314]
 [0.         0.5        0.51363636 0.         0.33909314 0.
  0.5        0.55606061 0.         0.35717234]
 [0.         0.5        0.6969697  0.         0.41052632 0.
  0.5        0.50454545 0.         0.33504902]
 [0.         0.5        0.62651515 0.         0.38497076 0.
  0.5        0.59166667 0.         0.37146543]
 [0.         0.5        0.62651515 0.         0.38497076 0.
  0.5        0.55606061 0.         0.35717234]
 [0.         0.5        0.60984848 0.         0.37865497 0.
  0.5        0.66060606 0.         0.39766082]]
DUMMY mean:
[0.         0.5        0.61699495 0.         0.37979769 0.
 0.5        0.59909091 0.         0.37318236]
---------------------------
Current folder: C:\Users\Javier\Dropbox\c_sldl_1_2_46_3
-------------------------------------
----- RESULTS from .csv files ------
-------------------------------------
---------------------------
ALG Means: 
-rows: alg : KNN = 0; DT = 1; RF = 2; SVM = 3; GBM = 4; BDDAE = 5; DUMMY = 5
columns:
'val_cohen','val_uar', 'val_acc', 'val_gm',  'val_f1',  'aro_cohen','aro_uar', 'aro_acc', 'aro_gm',  'aro_f1'
-------------------------------------------------------------
  v_c   v_u   v_a   v_g   v_f1  a_c   a_u   a_a   a_g   a_f1
[[0.409 0.703 0.742 0.642 0.694 0.423 0.709 0.739 0.669 0.704]
 [0.415 0.706 0.734 0.671 0.699 0.403 0.698 0.717 0.672 0.69 ]
 [0.426 0.721 0.752 0.667 0.713 0.432 0.713 0.739 0.691 0.709]
 [0.131 0.562 0.667 0.199 0.48  0.159 0.577 0.669 0.24  0.5  ]
 [0.363 0.676 0.744 0.547 0.659 0.401 0.693 0.745 0.601 0.681]
 [0.158 0.578 0.621 0.526 0.571 0.188 0.591 0.637 0.519 0.58 ]
 [0.    0.5   0.617 0.    0.38  0.    0.5   0.599 0.    0.373]]
-------------------------------------------------------------
Standard Deviation of each metric:
[[0.215 0.107 0.095 0.163 0.114 0.166 0.084 0.075 0.112 0.085]
 [0.186 0.091 0.084 0.126 0.093 0.142 0.07  0.067 0.085 0.073]
 [0.205 0.092 0.083 0.152 0.095 0.159 0.077 0.07  0.108 0.078]
 [0.195 0.092 0.088 0.272 0.135 0.214 0.106 0.078 0.306 0.151]
 [0.211 0.105 0.074 0.236 0.121 0.197 0.1   0.071 0.21  0.114]
 [0.183 0.089 0.101 0.119 0.094 0.181 0.088 0.089 0.149 0.098]
 [0.    0.    0.083 0.    0.031 0.    0.    0.073 0.    0.028]]
-------------------------------------------------------------
std_dev/mean [percentage]:
[[ 53.  15.  13.  25.  16.  39.  12.  10.  17.  12.]
 [ 45.  13.  11.  19.  13.  35.  10.   9.  13.  11.]
 [ 48.  13.  11.  23.  13.  37.  11.   9.  16.  11.]
 [149.  16.  13. 137.  28. 134.  18.  12. 127.  30.]
 [ 58.  16.  10.  43.  18.  49.  14.  10.  35.  17.]
 [116.  15.  16.  23.  16.  96.  15.  14.  29.  17.]
 [  0.   0.  13.   0.   8.   0.   0.  12.   0.   8.]]
-------------------------------------
Current folder: C:\Users\Javier\Dropbox\c_sldl_1_2_46_3
-------------------------------------
----- RESULTS ------
-------------------------------------
Window size (sec):  20.0
step (sec):  10.0
overlap:  True
perc. of overlap:  50.0
overlap duration (sec):  10.0
Number of windows / instances:  115
Elapsed time: 1087.8526890079181 minutes
Elapsed time: 18.130878150131966 hours
