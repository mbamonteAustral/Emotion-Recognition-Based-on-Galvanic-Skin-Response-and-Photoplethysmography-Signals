2024-05-05 21:12:24.766327: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-05-05 21:12:25.100516: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-05-05 21:12:25.100757: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-05-05 21:12:25.101123: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-05-05 21:12:25.102841: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-05-05 21:12:25.103248: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-05-05 21:12:25.103653: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-05-05 21:12:26.079262: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-05-05 21:12:26.079481: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-05-05 21:12:26.079642: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2024-05-05 21:12:26.079785: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5965 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Ti, pci bus id: 0000:2b:00.0, compute capability: 8.6
    
    
-------------------------------
participant:  1
-------------------------------
    
    
participant:  1
Window size (sec):  21.0
step (sec):  10.5
overlap:  True
perc. of overlap:  50.0
overlap duration (sec):  10.5
['gsr_chunks', 'ppg_chunks', 'val_chunks', 'aro_chunks', 'time_chunks', 'tag_chunks', 'video']
/home/marcos/Dropbox (Maestral)/c_sldl_1_2_49/functions.py:880: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!
You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.
A typical example is when you are setting values in a column of a DataFrame, like:

df["col"][row_indexer] = value

Use `df.loc[row_indexer, "col"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

55/77 [====================>.........] - ETA: 0s - loss: 0.0215 - mean_squared_error: 0.021557/77 [=====================>........] - ETA: 0s - loss: 0.0210 - mean_squared_error: 0.021059/77 [=====================>........] - ETA: 0s - loss: 0.0208 - mean_squared_error: 0.020861/77 [======================>.......] - ETA: 0s - loss: 0.0205 - mean_squared_error: 0.020563/77 [=======================>......] - ETA: 0s - loss: 0.0200 - mean_squared_error: 0.020065/77 [========================>.....] - ETA: 0s - loss: 0.0197 - mean_squared_error: 0.019767/77 [=========================>....] - ETA: 0s - loss: 0.0195 - mean_squared_error: 0.019569/77 [=========================>....] - ETA: 0s - loss: 0.0193 - mean_squared_error: 0.019371/77 [==========================>...] - ETA: 0s - loss: 0.0198 - mean_squared_error: 0.019873/77 [===========================>..] - ETA: 0s - loss: 0.0196 - mean_squared_error: 0.019675/77 [============================>.] - ETA: 0s - loss: 0.0193 - mean_squared_error: 0.019377/77 [==============================] - ETA: 0s - loss: 0.0189 - mean_squared_error: 0.018977/77 [==============================] - 2s 33ms/step - loss: 0.0189 - mean_squared_error: 0.0189 - val_loss: 0.0182 - val_mean_squared_error: 0.0182
Epoch 4/5
 1/77 [..............................] - ETA: 2s - loss: 0.0209 - mean_squared_error: 0.0209 3/77 [>.............................] - ETA: 2s - loss: 0.0376 - mean_squared_error: 0.0376 5/77 [>.............................] - ETA: 2s - loss: 0.0325 - mean_squared_error: 0.0325 7/77 [=>............................] - ETA: 2s - loss: 0.0289 - mean_squared_error: 0.0289 9/77 [==>...........................] - ETA: 2s - loss: 0.0239 - mean_squared_error: 0.023911/77 [===>..........................] - ETA: 1s - loss: 0.0257 - mean_squared_error: 0.025713/77 [====>.........................] - ETA: 1s - loss: 0.0227 - mean_squared_error: 0.022715/77 [====>.........................] - ETA: 1s - loss: 0.0243 - mean_squared_error: 0.024317/77 [=====>........................] - ETA: 1s - loss: 0.0217 - mean_squared_error: 0.021719/77 [======>.......................] - ETA: 1s - loss: 0.0198 - mean_squared_error: 0.019821/77 [=======>......................] - ETA: 1s - loss: 0.0185 - mean_squared_error: 0.018523/77 [=======>......................] - ETA: 1s - loss: 0.0176 - mean_squared_error: 0.017625/77 [========>.....................] - ETA: 1s - loss: 0.0168 - mean_squared_error: 0.016827/77 [=========>....................] - ETA: 1s - loss: 0.0157 - mean_squared_error: 0.015729/77 [==========>...................] - ETA: 1s - loss: 0.0170 - mean_squared_error: 0.017031/77 [===========>..................] - ETA: 1s - loss: 0.0182 - mean_squared_error: 0.018233/77 [===========>..................] - ETA: 1s - loss: 0.0194 - mean_squared_error: 0.019435/77 [============>.................] - ETA: 1s - loss: 0.0191 - mean_squared_error: 0.019137/77 [=============>................] - ETA: 1s - loss: 0.0188 - mean_squared_error: 0.018839/77 [==============>...............] - ETA: 1s - loss: 0.0184 - mean_squared_error: 0.018441/77 [==============>...............] - ETA: 1s - loss: 0.0180 - mean_squared_error: 0.018043/77 [===============>..............] - ETA: 1s - loss: 0.0175 - mean_squared_error: 0.017545/77 [================>.............] - ETA: 0s - loss: 0.0168 - mean_squared_error: 0.016847/77 [=================>............] - ETA: 0s - loss: 0.0174 - mean_squared_error: 0.017449/77 [==================>...........] - ETA: 0s - loss: 0.0193 - mean_squared_error: 0.019351/77 [==================>...........] - ETA: 0s - loss: 0.0187 - mean_squared_error: 0.018753/77 [===================>..........] - ETA: 0s - loss: 0.0194 - mean_squared_error: 0.019455/77 [====================>.........] - ETA: 0s - loss: 0.0195 - mean_squared_error: 0.019557/77 [=====================>........] - ETA: 0s - loss: 0.0192 - mean_squared_error: 0.019259/77 [=====================>........] - ETA: 0s - loss: 0.0189 - mean_squared_error: 0.018961/77 [======================>.......] - ETA: 0s - loss: 0.0185 - mean_squared_error: 0.018563/77 [=======================>......] - ETA: 0s - loss: 0.0183 - mean_squared_error: 0.018365/77 [========================>.....] - ETA: 0s - loss: 0.0186 - mean_squared_error: 0.018667/77 [=========================>....] - ETA: 0s - loss: 0.0190 - mean_squared_error: 0.019069/77 [=========================>....] - ETA: 0s - loss: 0.0187 - mean_squared_error: 0.018771/77 [==========================>...] - ETA: 0s - loss: 0.0192 - mean_squared_error: 0.019273/77 [===========================>..] - ETA: 0s - loss: 0.0190 - mean_squared_error: 0.019075/77 [============================>.] - ETA: 0s - loss: 0.0188 - mean_squared_error: 0.018877/77 [==============================] - ETA: 0s - loss: 0.0186 - mean_squared_error: 0.018677/77 [==============================] - 2s 32ms/step - loss: 0.0186 - mean_squared_error: 0.0186 - val_loss: 0.0192 - val_mean_squared_error: 0.0192
Epoch 5/5
 1/77 [..............................] - ETA: 2s - loss: 0.0085 - mean_squared_error: 0.0085 3/77 [>.............................] - ETA: 2s - loss: 0.0250 - mean_squared_error: 0.0250 5/77 [>.............................] - ETA: 2s - loss: 0.0201 - mean_squared_error: 0.0201 7/77 [=>............................] - ETA: 2s - loss: 0.0152 - mean_squared_error: 0.0152 9/77 [==>...........................] - ETA: 2s - loss: 0.0146 - mean_squared_error: 0.014611/77 [===>..........................] - ETA: 2s - loss: 0.0126 - mean_squared_error: 0.012613/77 [====>.........................] - ETA: 2s - loss: 0.0121 - mean_squared_error: 0.012115/77 [====>.........................] - ETA: 1s - loss: 0.0115 - mean_squared_error: 0.011517/77 [=====>........................] - ETA: 1s - loss: 0.0107 - mean_squared_error: 0.010719/77 [======>.......................] - ETA: 1s - loss: 0.0099 - mean_squared_error: 0.009921/77 [=======>......................] - ETA: 1s - loss: 0.0093 - mean_squared_error: 0.009323/77 [=======>......................] - ETA: 1s - loss: 0.0105 - mean_squared_error: 0.010525/77 [========>.....................] - ETA: 1s - loss: 0.0102 - mean_squared_error: 0.010227/77 [=========>....................] - ETA: 1s - loss: 0.0099 - mean_squared_error: 0.009929/77 [==========>...................] - ETA: 1s - loss: 0.0114 - mean_squared_error: 0.011431/77 [===========>..................] - ETA: 1s - loss: 0.0115 - mean_squared_error: 0.011533/77 [===========>..................] - ETA: 1s - loss: 0.0135 - mean_squared_error: 0.013535/77 [============>.................] - ETA: 1s - loss: 0.0132 - mean_squared_error: 0.013237/77 [=============>................] - ETA: 1s - loss: 0.0129 - mean_squared_error: 0.012939/77 [==============>...............] - ETA: 1s - loss: 0.0128 - mean_squared_error: 0.012841/77 [==============>...............] - ETA: 1s - loss: 0.0145 - mean_squared_error: 0.014543/77 [===============>..............] - ETA: 1s - loss: 0.0141 - mean_squared_error: 0.014145/77 [================>.............] - ETA: 0s - loss: 0.0137 - mean_squared_error: 0.013747/77 [=================>............] - ETA: 0s - loss: 0.0136 - mean_squared_error: 0.013649/77 [==================>...........] - ETA: 0s - loss: 0.0135 - mean_squared_error: 0.013551/77 [==================>...........] - ETA: 0s - loss: 0.0133 - mean_squared_error: 0.013353/77 [===================>..........] - ETA: 0s - loss: 0.0150 - mean_squared_error: 0.015055/77 [====================>.........] - ETA: 0s - loss: 0.0146 - mean_squared_error: 0.014657/77 [=====================>........] - ETA: 0s - loss: 0.0144 - mean_squared_error: 0.014459/77 [=====================>........] - ETA: 0s - loss: 0.0147 - mean_squared_error: 0.014761/77 [======================>.......] - ETA: 0s - loss: 0.0143 - mean_squared_error: 0.014363/77 [=======================>......] - ETA: 0s - loss: 0.0141 - mean_squared_error: 0.014165/77 [========================>.....] - ETA: 0s - loss: 0.0148 - mean_squared_error: 0.014867/77 [=========================>....] - ETA: 0s - loss: 0.0163 - mean_squared_error: 0.016369/77 [=========================>....] - ETA: 0s - loss: 0.0168 - mean_squared_error: 0.016871/77 [==========================>...] - ETA: 0s - loss: 0.0166 - mean_squared_error: 0.016673/77 [===========================>..] - ETA: 0s - loss: 0.0169 - mean_squared_error: 0.016975/77 [============================>.] - ETA: 0s - loss: 0.0170 - mean_squared_error: 0.017077/77 [==============================] - ETA: 0s - loss: 0.0172 - mean_squared_error: 0.017277/77 [==============================] - 2s 32ms/step - loss: 0.0172 - mean_squared_error: 0.0172 - val_loss: 0.0172 - val_mean_squared_error: 0.0172
(20992, 1, 5)
Model: "sequential_1199"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 1stConvL (Conv1D)           (None, 20992, 5)          105       
                                                                 
 1stPoolL (AveragePooling1D)  (None, 5248, 5)          0         
                                                                 
 2ndConvL (Conv1D)           (None, 5248, 6)           306       
                                                                 
 2ndPoolL (AveragePooling1D)  (None, 1312, 6)          0         
                                                                 
=================================================================
Total params: 411
Trainable params: 411
Non-trainable params: 0
_________________________________________________________________
Model: "valence_NN"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 inputGSR (InputLayer)          [(None, 20992, 1)]   0           []                               
                                                                                                  
 inputPPG (InputLayer)          [(None, 20992, 1)]   0           []                               
                                                                                                  
 sequential_1198 (Sequential)   (None, 1312, 6)      411         ['inputGSR[0][0]']               
                                                                                                  
 sequential_1199 (Sequential)   (None, 1312, 6)      411         ['inputPPG[0][0]']               
                                                                                                  
 concatenate_599 (Concatenate)  (None, 1312, 12)     0           ['sequential_1198[0][0]',        
                                                                  'sequential_1199[0][0]']        
                                                                                                  
 permute_599 (Permute)          (None, 12, 1312)     0           ['concatenate_599[0][0]']        
                                                                                                  
 flatten_599 (Flatten)          (None, 15744)        0           ['permute_599[0][0]']            
                                                                                                  
 dropout_599 (Dropout)          (None, 15744)        0           ['flatten_599[0][0]']            
                                                                                                  
 dense_599 (Dense)              (None, 1)            15745       ['dropout_599[0][0]']            
                                                                                                  
==================================================================================================
Total params: 16,567
Trainable params: 16,567
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/10
 1/77 [..............................] - ETA: 19s - loss: 0.8451 - binary_accuracy: 0.0000e+0011/77 [===>..........................] - ETA: 0s - loss: 0.8798 - binary_accuracy: 0.4545     20/77 [======>.......................] - ETA: 0s - loss: 0.9108 - binary_accuracy: 0.450029/77 [==========>...................] - ETA: 0s - loss: 0.8567 - binary_accuracy: 0.448339/77 [==============>...............] - ETA: 0s - loss: 0.8465 - binary_accuracy: 0.435948/77 [=================>............] - ETA: 0s - loss: 0.8169 - binary_accuracy: 0.437558/77 [=====================>........] - ETA: 0s - loss: 0.7802 - binary_accuracy: 0.482868/77 [=========================>....] - ETA: 0s - loss: 0.7191 - binary_accuracy: 0.544177/77 [==============================] - 1s 7ms/step - loss: 0.6659 - binary_accuracy: 0.5844 - val_loss: 0.2221 - val_binary_accuracy: 0.8889
Epoch 2/10
 1/77 [..............................] - ETA: 0s - loss: 3.1085 - binary_accuracy: 0.0000e+0014/77 [====>.........................] - ETA: 0s - loss: 1.0196 - binary_accuracy: 0.5714    27/77 [=========>....................] - ETA: 0s - loss: 0.9157 - binary_accuracy: 0.518538/77 [=============>................] - ETA: 0s - loss: 0.9045 - binary_accuracy: 0.447448/77 [=================>............] - ETA: 0s - loss: 0.8869 - binary_accuracy: 0.458360/77 [======================>.......] - ETA: 0s - loss: 0.8667 - binary_accuracy: 0.466775/77 [============================>.] - ETA: 0s - loss: 0.8223 - binary_accuracy: 0.520077/77 [==============================] - 0s 4ms/step - loss: 0.8022 - binary_accuracy: 0.5325 - val_loss: 0.2184 - val_binary_accuracy: 0.8889
Epoch 3/10
 1/77 [..............................] - ETA: 0s - loss: 3.2776 - binary_accuracy: 0.0000e+0017/77 [=====>........................] - ETA: 0s - loss: 1.0497 - binary_accuracy: 0.5294    32/77 [===========>..................] - ETA: 0s - loss: 0.9048 - binary_accuracy: 0.531247/77 [=================>............] - ETA: 0s - loss: 0.8092 - binary_accuracy: 0.574562/77 [=======================>......] - ETA: 0s - loss: 0.7724 - binary_accuracy: 0.596877/77 [==============================] - ETA: 0s - loss: 0.7354 - binary_accuracy: 0.623477/77 [==============================] - 0s 4ms/step - loss: 0.7354 - binary_accuracy: 0.6234 - val_loss: 0.4917 - val_binary_accuracy: 0.8889
Epoch 4/10
 1/77 [..............................] - ETA: 0s - loss: 0.5144 - binary_accuracy: 1.000016/77 [=====>........................] - ETA: 0s - loss: 0.7061 - binary_accuracy: 0.562532/77 [===========>..................] - ETA: 0s - loss: 0.6345 - binary_accuracy: 0.656247/77 [=================>............] - ETA: 0s - loss: 0.6950 - binary_accuracy: 0.638362/77 [=======================>......] - ETA: 0s - loss: 0.6747 - binary_accuracy: 0.661375/77 [============================>.] - ETA: 0s - loss: 0.6696 - binary_accuracy: 0.653377/77 [==============================] - 0s 4ms/step - loss: 0.6789 - binary_accuracy: 0.6494 - val_loss: 0.4468 - val_binary_accuracy: 0.8889
Epoch 5/10
 1/77 [..............................] - ETA: 0s - loss: 0.0834 - binary_accuracy: 1.000017/77 [=====>........................] - ETA: 0s - loss: 0.5671 - binary_accuracy: 0.764732/77 [===========>..................] - ETA: 0s - loss: 0.6039 - binary_accuracy: 0.687547/77 [=================>............] - ETA: 0s - loss: 0.5500 - binary_accuracy: 0.723459/77 [=====================>........] - ETA: 0s - loss: 0.5733 - binary_accuracy: 0.694972/77 [===========================>..] - ETA: 0s - loss: 0.6014 - binary_accuracy: 0.652877/77 [==============================] - 0s 4ms/step - loss: 0.5896 - binary_accuracy: 0.6753 - val_loss: 0.7970 - val_binary_accuracy: 0.2222
Epoch 6/10
 1/77 [..............................] - ETA: 0s - loss: 0.5761 - binary_accuracy: 1.000018/77 [======>.......................] - ETA: 0s - loss: 0.6029 - binary_accuracy: 0.722232/77 [===========>..................] - ETA: 0s - loss: 0.6394 - binary_accuracy: 0.718846/77 [================>.............] - ETA: 0s - loss: 0.6384 - binary_accuracy: 0.695761/77 [======================>.......] - ETA: 0s - loss: 0.6086 - binary_accuracy: 0.704976/77 [============================>.] - ETA: 0s - loss: 0.6099 - binary_accuracy: 0.684277/77 [==============================] - 0s 4ms/step - loss: 0.6062 - binary_accuracy: 0.6883 - val_loss: 0.5294 - val_binary_accuracy: 0.8889
Epoch 7/10
 1/77 [..............................] - ETA: 0s - loss: 0.1701 - binary_accuracy: 1.000017/77 [=====>........................] - ETA: 0s - loss: 0.2107 - binary_accuracy: 0.882434/77 [============>.................] - ETA: 0s - loss: 0.3269 - binary_accuracy: 0.852949/77 [==================>...........] - ETA: 0s - loss: 0.4318 - binary_accuracy: 0.795965/77 [========================>.....] - ETA: 0s - loss: 0.4954 - binary_accuracy: 0.784677/77 [==============================] - 0s 4ms/step - loss: 0.4906 - binary_accuracy: 0.8052 - val_loss: 1.0607 - val_binary_accuracy: 0.1111
Epoch 8/10
 1/77 [..............................] - ETA: 0s - loss: 0.2340 - binary_accuracy: 1.000016/77 [=====>........................] - ETA: 0s - loss: 0.6324 - binary_accuracy: 0.750031/77 [===========>..................] - ETA: 0s - loss: 0.5607 - binary_accuracy: 0.741945/77 [================>.............] - ETA: 0s - loss: 0.5434 - binary_accuracy: 0.755659/77 [=====================>........] - ETA: 0s - loss: 0.5288 - binary_accuracy: 0.745873/77 [===========================>..] - ETA: 0s - loss: 0.5174 - binary_accuracy: 0.739777/77 [==============================] - 0s 4ms/step - loss: 0.5071 - binary_accuracy: 0.7532 - val_loss: 0.5567 - val_binary_accuracy: 0.7778
Epoch 9/10
 1/77 [..............................] - ETA: 0s - loss: 0.4052 - binary_accuracy: 1.000017/77 [=====>........................] - ETA: 0s - loss: 0.5383 - binary_accuracy: 0.647132/77 [===========>..................] - ETA: 0s - loss: 0.4200 - binary_accuracy: 0.750045/77 [================>.............] - ETA: 0s - loss: 0.4564 - binary_accuracy: 0.733360/77 [======================>.......] - ETA: 0s - loss: 0.4624 - binary_accuracy: 0.716777/77 [==============================] - ETA: 0s - loss: 0.4894 - binary_accuracy: 0.701377/77 [==============================] - 0s 4ms/step - loss: 0.4894 - binary_accuracy: 0.7013 - val_loss: 0.6724 - val_binary_accuracy: 0.5556
Epoch 10/10
 1/77 [..............................] - ETA: 0s - loss: 0.1315 - binary_accuracy: 1.000018/77 [======>.......................] - ETA: 0s - loss: 0.3714 - binary_accuracy: 0.777834/77 [============>.................] - ETA: 0s - loss: 0.3943 - binary_accuracy: 0.794149/77 [==================>...........] - ETA: 0s - loss: 0.3863 - binary_accuracy: 0.816363/77 [=======================>......] - ETA: 0s - loss: 0.4457 - binary_accuracy: 0.793777/77 [==============================] - 0s 4ms/step - loss: 0.4324 - binary_accuracy: 0.8052 - val_loss: 0.9005 - val_binary_accuracy: 0.4444
1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 60ms/step
predicted [0.90108347 0.21326587 0.73988324 0.35691503 0.45211968 0.76845187
 0.8030177  0.8166856  0.7736061  0.1680523  0.32672736 0.5835511
 0.50175333 0.8835417  0.9705468  0.4957539  0.13301909 0.22563681
 0.61007965 0.41329557 0.8307844  0.80867285]
predicted [1 0 1 0 0 1 1 1 1 0 0 1 1 1 1 0 0 0 1 0 1 1]
expected [False False  True  True  True  True  True False False  True False  True
 False  True  True  True  True  True  True False False  True]
accuracy: 0.5
confusion matrix: 
[[3 5]
 [6 8]]
              precision    recall  f1-score   support

       False       0.33      0.38      0.35         8
        True       0.62      0.57      0.59        14

    accuracy                           0.50        22
   macro avg       0.47      0.47      0.47        22
weighted avg       0.51      0.50      0.51        22

macro avg f1-score: 0.47276688453159044
macro avg (UAR): 0.4732142857142857
Sensitivity:  0.375
Specificity:  0.5714285714285714
g-mean:  0.4629100498862757
-------- Model Performance ----------: 
accuracy:  [0.5        0.59090909 0.59090909 0.63636364 0.31818182 0.68181818
 0.59090909 0.5        0.59090909 0.5       ]
gmean:  [0.5        0.51754917 0.51754917 0.5976143  0.23145502 0.35355339
 0.51754917 0.51754917 0.56694671 0.46291005]
f1_score:  [0.49052632 0.54482759 0.54482759 0.60714286 0.28104575 0.51111111
 0.54482759 0.4989648  0.56862745 0.47276688]
UAR:  [0.5        0.54464286 0.54464286 0.60714286 0.27678571 0.5625
 0.54464286 0.52678571 0.57142857 0.47321429]
Cohen Kappa score:  [ 0.          0.09174312  0.09174312  0.21428571 -0.43478261  0.15384615
  0.09174312  0.04724409  0.13913043 -0.05217391]
arousal and valece = ok
------------- Evaluating model --------------
-------------------------------------
-------------------------------------
participant:  30
-------------------------------------
----- RESULTS ------
-------------------------------------
Window size (sec):  20.992
step (sec):  10.496
overlap:  True
perc. of overlap:  50.0
overlap duration (sec):  10.496
Number of windows / instances:  108
-rows: alg : KNN = 0; DT = 1; RF = 2; SVM = 3; GBM = 4; BDDAE = 5; DUMMY = 5
columns:
'val_cohen','val_uar', 'val_acc', 'val_gm',  'val_f1',  'aro_cohen','aro_uar', 'aro_acc', 'aro_gm',  'aro_f1'
-------------------------------------------------------------
  v_c   v_u   v_a   v_g   v_f1  a_c   a_u   a_a   a_g   a_f1
[[0.862 0.938 0.935 0.934 0.93  0.461 0.737 0.759 0.712 0.724]
 [0.734 0.877 0.882 0.858 0.871 0.477 0.743 0.779 0.746 0.735]
 [0.809 0.843 0.863 0.907 0.843 0.63  0.723 0.757 0.735 0.718]
 [0.432 0.695 0.77  0.583 0.687 0.    0.5   0.658 0.    0.397]
 [0.659 0.834 0.835 0.817 0.822 0.376 0.676 0.761 0.566 0.666]
 [0.034 0.515 0.55  0.478 0.506 0.034 0.515 0.605 0.32  0.48 ]
 [0.    0.5   0.62  0.    0.383 0.    0.5   0.658 0.    0.397]]
last participant performance loaded in numpy array
    
    
-------------------------------
LAST participant's saved data: 
30
-------------------------------
    
    
Saving performance metrics in csv files...
Performance metrics already saved in csv files
---------------------------
KNN performance:
[[ 0.60577713  0.80416667  0.80636364  0.79687702  0.80108586  0.36892773
   0.67986111  0.80636364  0.51608469  0.6662758 ]
 [ 0.51790978  0.76166667  0.75727273  0.74960926  0.75338883  0.54190988
   0.75892857  0.80727273  0.6880551   0.75583944]
 [ 0.58154208  0.78416667  0.81090909  0.72281592  0.77783522  0.26805124
   0.63666667  0.62909091  0.62143302  0.62473582]
 [ 0.47277309  0.73333333  0.74090909  0.7160888   0.72996725  0.27060259
   0.63988095  0.73        0.55469982  0.62764239]
 [ 0.49943743  0.74595238  0.78636364  0.63034286  0.72410476  0.55249345
   0.77666667  0.77818182  0.76432891  0.77209901]
 [ 0.47450111  0.73833333  0.73272727  0.70657814  0.72097375  0.62162211
   0.81166667  0.80818182  0.80492392  0.8067094 ]
 [ 0.34603067  0.67107143  0.70272727  0.64573243  0.66788462  0.40003228
   0.70166667  0.70363636  0.68685146  0.69561328]
 [ 0.77411646  0.875       0.90818182  0.85721508  0.88252101  0.71737508
   0.86511905  0.86090909  0.8564243   0.85568681]
 [ 0.21270629  0.60803571  0.73272727  0.3886983   0.57314148  0.14031002
   0.57083333  0.65727273  0.43154371  0.56000081]
 [ 0.30754203  0.655       0.65636364  0.62674355  0.64255411  0.34588431
   0.67083333  0.67636364  0.66232446  0.66987318]
 [ 0.27393757  0.63154762  0.68363636  0.54357444  0.61795868  0.42767663
   0.6997619   0.74909091  0.65312772  0.70099305]
 [ 0.72038298  0.85440476  0.87        0.84497972  0.85812729  0.60291074
   0.79345238  0.82636364  0.76394576  0.79479924]
 [ 0.54533749  0.77154762  0.77727273  0.76563695  0.77027334  0.22878724
   0.61357143  0.62818182  0.59149214  0.60727578]
 [ 0.00435059  0.4922619   0.59181818  0.31093053  0.48073772  0.47685429
   0.73833333  0.74090909  0.71487088  0.72828838]
 [ 0.13509566  0.57589286  0.66636364  0.43026697  0.55601074  0.46372599
   0.72678571  0.75        0.71090335  0.72556652]
 [ 0.21987518  0.60154762  0.64        0.55187455  0.59405193  0.51479197
   0.74821429  0.78363636  0.72926602  0.7528663 ]
 [ 0.48216396  0.74095238  0.74181818  0.72881813  0.73384865  0.52689469
   0.7547619   0.78545455  0.72908931  0.75781288]
 [ 0.23248639  0.60444444  0.86272727  0.27071068  0.59430242  0.59641974
   0.80154762  0.80454545  0.77555097  0.7882745 ]
 [ 0.35976621  0.68303571  0.74        0.63171897  0.66857825  0.48053789
   0.74083333  0.74181818  0.73236867  0.73664918]
 [ 0.33234218  0.67380952  0.73454545  0.57403746  0.65918301  0.21085924
   0.60892857  0.65727273  0.50859406  0.59446193]
 [-0.16555828  0.42569444  0.64909091  0.05        0.40645726  0.19711534
   0.6         0.59363636  0.5746783   0.58415029]
 [ 0.41138165  0.70333333  0.71        0.68512663  0.69878816  0.45820604
   0.72678571  0.76        0.70547965  0.72554487]
 [ 0.17410889  0.58666667  0.60818182  0.5322179   0.5759213   0.21016179
   0.59583333  0.71181818  0.45250664  0.59185224]
 [ 0.25100467  0.625       0.62909091  0.6013891   0.61503358  0.53833465
   0.765       0.77909091  0.73587169  0.75931124]
 [ 0.61654092  0.80333333  0.81454545  0.78639758  0.80273948  0.57839731
   0.79166667  0.78727273  0.77679173  0.78297591]
 [ 0.34420018  0.67166667  0.67545455  0.64790858  0.66188256  0.395671
   0.69666667  0.70272727  0.68815795  0.69453879]
 [ 0.60876592  0.78541667  0.85272727  0.74538182  0.79563609  0.57590379
   0.79        0.78636364  0.78310158  0.78453768]
 [ 0.27891925  0.64511905  0.66545455  0.60729534  0.62935967  0.5343934
   0.77        0.77818182  0.73433151  0.75344156]
 [-0.03314368  0.48785714  0.53909091  0.36173081  0.47125635  0.28136486
   0.64        0.65        0.60561095  0.62746087]
 [ 0.86180365  0.93809524  0.93545455  0.93449849  0.93026529  0.46063577
   0.73720238  0.75909091  0.71209026  0.72355006]]
KNN mean:
[0.38153658 0.68927844 0.73406061 0.61483987 0.67979562 0.43289504
 0.71504894 0.74109091 0.67548328 0.70829424]
---------------------------
---------------------------
DT performance:
[[0.63007539 0.8225     0.82454545 0.80612932 0.81945749 0.2546163
  0.63958333 0.72272727 0.47476116 0.60697712]
 [0.5396092  0.74833333 0.75545455 0.7546444  0.74221223 0.52441252
  0.76130952 0.77090909 0.75059058 0.75613983]
 [0.40737215 0.69154762 0.70363636 0.66188684 0.67620879 0.47437708
  0.68166667 0.68272727 0.68060371 0.67599761]
 [0.46139656 0.73833333 0.74272727 0.7019946  0.7377775  0.06693794
  0.53541667 0.60454545 0.42438706 0.53178571]
 [0.54072602 0.76964286 0.79454545 0.69407942 0.75334554 0.53114106
  0.74666667 0.74818182 0.77097626 0.74472805]
 [0.43437222 0.71166667 0.70454545 0.71096578 0.69245782 0.57539045
  0.82       0.81454545 0.79457452 0.81338384]
 [0.27622631 0.66595238 0.68454545 0.55299277 0.64294178 0.3392433
  0.66833333 0.66818182 0.64820133 0.66422078]
 [0.85580481 0.91458333 0.91727273 0.91760117 0.90220238 0.68980671
  0.87392857 0.88       0.81890039 0.87297286]
 [0.45513709 0.73630952 0.76818182 0.70028701 0.72021383 0.4305573
  0.67946429 0.72363636 0.71850132 0.67090605]
 [0.30100847 0.67       0.66818182 0.55905891 0.65187035 0.15036263
  0.61166667 0.61090909 0.58621482 0.60405983]
 [0.17702137 0.575      0.60181818 0.53240577 0.55804099 0.47380599
  0.79559524 0.81181818 0.73238482 0.79388126]
 [0.68761703 0.84178571 0.85       0.81351764 0.84270452 0.51292243
  0.76547619 0.77       0.75537167 0.75776224]
 [0.25136082 0.5525     0.56636364 0.62101573 0.5442316  0.21717129
  0.62809524 0.63727273 0.47349954 0.61440379]
 [0.14234861 0.57291667 0.62727273 0.4353659  0.56532482 0.41296234
  0.695      0.69545455 0.68041014 0.68691198]
 [0.1948406  0.58214286 0.65636364 0.50867228 0.57672619 0.25046532
  0.59464286 0.61818182 0.61930391 0.5863481 ]
 [0.38026316 0.72369048 0.72545455 0.69615332 0.70741745 0.47497701
  0.72589286 0.77727273 0.66839838 0.70138404]
 [0.60365558 0.79619048 0.80636364 0.80063691 0.79740953 0.57342988
  0.78309524 0.79545455 0.78938084 0.7820431 ]
 [0.16730271 0.60777778 0.83454545 0.32793996 0.60114244 0.42710254
  0.73892857 0.75909091 0.70786838 0.73281524]
 [0.46137638 0.76488095 0.81636364 0.81471558 0.74696736 0.51271962
  0.78083333 0.78727273 0.72865648 0.77318931]
 [0.41777883 0.74553571 0.77727273 0.69649729 0.72905328 0.22501632
  0.67380952 0.69545455 0.63305987 0.66585872]
 [0.15277233 0.51319444 0.67727273 0.39492249 0.51231074 0.16692086
  0.55       0.55636364 0.55269221 0.53505717]
 [0.324102   0.66333333 0.66363636 0.63060652 0.65554501 0.39430998
  0.69880952 0.70454545 0.7244447  0.68299756]
 [0.34044939 0.6375     0.64818182 0.61855145 0.61674964 0.25123189
  0.64166667 0.74909091 0.49311939 0.62936041]
 [0.33993898 0.69333333 0.68909091 0.63730996 0.68576118 0.3715055
  0.74       0.74181818 0.64861132 0.73429376]
 [0.40193242 0.72571429 0.73272727 0.73856022 0.71668803 0.53516902
  0.76666667 0.76909091 0.76810871 0.76381091]
 [0.4572123  0.70333333 0.70272727 0.68919919 0.69960761 0.4232839
  0.70583333 0.70454545 0.67117052 0.69549007]
 [0.5453181  0.74732143 0.79727273 0.76227678 0.7402073  0.56964255
  0.82166667 0.82181818 0.78961493 0.81716117]
 [0.1816033  0.55797619 0.57363636 0.47232738 0.54600455 0.55218857
  0.74154762 0.73909091 0.74522607 0.73008075]
 [0.19508153 0.60333333 0.64090909 0.53852042 0.59489621 0.26031422
  0.5875     0.60090909 0.56451996 0.57602092]
 [0.7337079  0.87714286 0.88181818 0.8577907  0.87092061 0.47714216
  0.74315476 0.77909091 0.74641507 0.73517664]]
DT mean:
[0.40191372 0.69844907 0.72775758 0.65488752 0.68821323 0.40397089
 0.70654167 0.72466667 0.67199894 0.69784063]
---------------------------
---------------------------
RF performance:
[[ 0.64177714  0.81083333  0.81545455  0.76952296  0.81011822  0.37930341
   0.71944444  0.80636364  0.64323271  0.70401648]
 [ 0.43105644  0.8         0.80363636  0.81719873  0.79627539  0.33061794
   0.78095238  0.81636364  0.71524162  0.78362   ]
 [ 0.4168742   0.77238095  0.78454545  0.67050147  0.76959207  0.5228049
   0.75333333  0.75        0.7343196   0.74692308]
 [ 0.58611744  0.75        0.75090909  0.7876744   0.74865579  0.07516256
   0.46785714  0.61272727  0.46420953  0.45364938]
 [ 0.46792067  0.75416667  0.78636364  0.69701961  0.74587246  0.55134555
   0.805       0.80636364  0.78194768  0.80194583]
 [ 0.45249779  0.68666667  0.68727273  0.64756014  0.67115718  0.50268329
   0.78        0.77909091  0.79219488  0.77791375]
 [ 0.34888496  0.72702381  0.74727273  0.58467972  0.71149615  0.35164588
   0.69333333  0.69454545  0.68425837  0.68880314]
 [ 0.87655953  0.93125     0.93636364  0.94580346  0.9260119   0.71376655
   0.84154762  0.85        0.78558962  0.83672688]
 [ 0.38145471  0.68452381  0.75181818  0.72108354  0.66957447  0.34622192
   0.65119048  0.70363636  0.65667295  0.63068711]
 [ 0.2740227   0.64833333  0.64727273  0.6319601   0.63705433  0.38388444
   0.7275      0.73181818  0.65936655  0.71945943]
 [ 0.55261199  0.66130952  0.69545455  0.60382386  0.64892372  0.56089656
   0.76202381  0.77636364  0.77850417  0.75380842]
 [ 0.72811432  0.83761905  0.85181818  0.87155378  0.83412824  0.41460298
   0.78952381  0.80636364  0.69242333  0.78799423]
 [ 0.46081154  0.68761905  0.69272727  0.6370365   0.68064699  0.26922856
   0.61440476  0.63        0.57302597  0.60712315]
 [ 0.14668981  0.55446429  0.60909091  0.38406825  0.5422479   0.47003123
   0.71666667  0.72454545  0.66523163  0.71282884]
 [ 0.36923867  0.65684524  0.74818182  0.52342     0.66447012  0.23577649
   0.7452381   0.76727273  0.75759506  0.74548909]
 [ 0.33562972  0.65785714  0.68454545  0.74740649  0.65081044  0.58811074
   0.84077381  0.85090909  0.75364403  0.82979396]
 [ 0.7699546   0.8825      0.88909091  0.8501635   0.88290113  0.59365674
   0.81011905  0.81545455  0.76766326  0.8046892 ]
 [ 0.17805364  0.63333333  0.83454545  0.15722929  0.63465084  0.51858644
   0.7552381   0.76909091  0.77629755  0.74507173]
 [ 0.56610306  0.82440476  0.84272727  0.64126235  0.80601594  0.62745821
   0.8025      0.80727273  0.77042527  0.79708847]
 [ 0.29041437  0.63511905  0.71363636  0.61561699  0.61538282  0.19857834
   0.58035714  0.60818182  0.57304749  0.56903361]
 [-0.03214839  0.49583333  0.66727273  0.30634962  0.46077006  0.20071419
   0.58666667  0.58363636  0.656651    0.57190199]
 [ 0.29332571  0.675       0.67363636  0.62043178  0.6652442   0.50413032
   0.7702381   0.79727273  0.74791869  0.76665571]
 [ 0.15032102  0.60107143  0.62818182  0.55111552  0.58567446  0.13990111
   0.57291667  0.69545455  0.50590127  0.5626564 ]
 [ 0.24258776  0.72833333  0.73272727  0.66641117  0.7202775   0.55339411
   0.72833333  0.73272727  0.74160403  0.72092297]
 [ 0.50621205  0.77333333  0.78363636  0.75277861  0.76930708  0.65212212
   0.78        0.77727273  0.80631607  0.77313686]
 [ 0.46460548  0.65166667  0.64818182  0.65971012  0.63854562  0.46843507
   0.7375      0.74181818  0.68582629  0.72184968]
 [ 0.60774077  0.7297619   0.79727273  0.71447939  0.73896807  0.56834332
   0.80333333  0.80181818  0.80035083  0.79424298]
 [-0.02865423  0.53321429  0.56363636  0.40789685  0.5126579   0.41407035
   0.72654762  0.73363636  0.74697584  0.71252123]
 [ 0.1450178   0.6125      0.65636364  0.62535901  0.60185705  0.32263477
   0.64916667  0.65636364  0.63726632  0.64557887]
 [ 0.80928258  0.84309524  0.86272727  0.90717104  0.84276224  0.63048659
   0.72261905  0.75727273  0.73487583  0.71843018]]
RF mean:
[0.41443593 0.70800198 0.74287879 0.65054294 0.69940168 0.43628649
 0.72381085 0.74612121 0.70295258 0.71615209]
---------------------------
---------------------------
SVM performance:
[[ 0.          0.5         0.55636364  0.          0.35735294  0.
   0.5         0.76909091  0.          0.4344152 ]
 [ 0.32739759  0.65833333  0.67545455  0.61038862  0.64530747  0.01155015
   0.50535714  0.63        0.05        0.40501634]
 [ 0.30113663  0.64        0.69272727  0.43481485  0.59029412  0.38883822
   0.69666667  0.69272727  0.67839456  0.68555916]
 [ 0.33796237  0.665       0.68272727  0.56782593  0.63578196  0.
   0.5         0.73181818  0.          0.42246302]
 [ 0.50813072  0.73535714  0.79545455  0.64415401  0.73100679  0.53817989
   0.77        0.76818182  0.74360163  0.75742258]
 [ 0.21601161  0.605       0.62090909  0.46705902  0.55378618  0.62020062
   0.81333333  0.80727273  0.80312943  0.80491064]
 [ 0.          0.5         0.62        0.          0.38251634  0.19350047
   0.59833333  0.60090909  0.53523051  0.56956349]
 [ 0.61051673  0.77083333  0.85272727  0.72811535  0.79638072  0.46481739
   0.71416667  0.76818182  0.64454249  0.70991246]
 [ 0.          0.5         0.70363636  0.          0.4127623   0.
   0.5         0.68545455  0.          0.40632955]
 [ 0.18217033  0.59166667  0.60181818  0.37990168  0.50689776  0.02142857
   0.51        0.56545455  0.04472136  0.37622549]
 [ 0.          0.5         0.63909091  0.          0.38978758  0.0893617
   0.5375      0.64727273  0.15        0.44937908]
 [ 0.11914894  0.55        0.65636364  0.2         0.47166667  0.
   0.5         0.62        0.          0.38251634]
 [ 0.04285714  0.52        0.60181818  0.08944272  0.40588235  0.
   0.5         0.57454545  0.          0.36454248]
 [ 0.          0.5         0.66727273  0.          0.3998968   0.27171809
   0.63166667  0.64636364  0.39356734  0.55529062]
 [ 0.          0.5         0.70363636  0.          0.4127623   0.
   0.5         0.63909091  0.          0.38978758]
 [ 0.          0.5         0.61090909  0.          0.37892157  0.
   0.5         0.65818182  0.          0.39668043]
 [ 0.          0.5         0.57454545  0.          0.36454248  0.
   0.5         0.60181818  0.          0.3753268 ]
 [ 0.          0.5         0.87090909  0.          0.46521303  0.
   0.5         0.59272727  0.          0.37173203]
 [ 0.          0.5         0.69454545  0.          0.40954592  0.
   0.5         0.54636364  0.          0.35318627]
 [ 0.          0.5         0.68545455  0.          0.40632955  0.
   0.5         0.62909091  0.          0.38611111]
 [ 0.          0.5         0.77818182  0.          0.43730994  0.
   0.5         0.52727273  0.          0.34497549]
 [ 0.25751856  0.63333333  0.62        0.56803361  0.5945116   0.
   0.5         0.64909091  0.          0.39346405]
 [ 0.          0.5         0.58363636  0.          0.36813725  0.
   0.5         0.74181818  0.          0.42573099]
 [ 0.          0.5         0.53636364  0.          0.34901961  0.43903063
   0.70916667  0.74090909  0.61130596  0.68852061]
 [ 0.          0.5         0.57454545  0.          0.36454248  0.43138771
   0.72        0.71090909  0.69168964  0.70113831]
 [ 0.          0.5         0.51818182  0.          0.34093137  0.36731405
   0.67333333  0.70545455  0.59392417  0.65380952]
 [ 0.          0.5         0.70363636  0.          0.4127623   0.58830601
   0.795       0.79363636  0.7899815   0.79136364]
 [ 0.          0.5         0.62        0.          0.38251634  0.1453617
   0.5625      0.64727273  0.22071068  0.48038399]
 [ 0.          0.5         0.62        0.          0.38251634 -0.03508772
   0.48333333  0.52818182  0.          0.34455882]
 [ 0.43227329  0.695       0.77        0.58269081  0.68744119  0.
   0.5         0.65818182  0.          0.39668043]]
SVM mean:
[0.1111708  0.55215079 0.6610303  0.17574755 0.46787744 0.15119692
 0.5740119  0.66257576 0.23169331 0.49389988]
---------------------------
---------------------------
GBM performance:
[[ 0.60082909  0.81583333  0.82454545  0.78650254  0.81424437  0.30533597
   0.62986111  0.81545455  0.40520773  0.62692466]
 [ 0.54058568  0.76666667  0.77727273  0.74088058  0.76586053  0.52713523
   0.76309524  0.80727273  0.6829145   0.76491838]
 [ 0.47363704  0.72583333  0.75818182  0.68189004  0.72282301  0.57190718
   0.78        0.77545455  0.7676245   0.77231907]
 [ 0.4554633   0.715       0.72090909  0.69771898  0.71088967 -0.03117409
   0.4875      0.71272727  0.          0.41597867]
 [ 0.5778627   0.77857143  0.82272727  0.69728664  0.76762309  0.54809952
   0.77333333  0.77727273  0.78046701  0.77053724]
 [ 0.42716367  0.735       0.72454545  0.68829365  0.70706016  0.5519119
   0.78        0.77        0.76331714  0.76603341]
 [ 0.25679319  0.62904762  0.70272727  0.48297195  0.6096205   0.38651483
   0.71333333  0.71363636  0.68958551  0.70800505]
 [ 0.8350501   0.93125     0.93636364  0.92405973  0.9260119   0.58979956
   0.78607143  0.81545455  0.77004027  0.78836358]
 [ 0.14259449  0.57232143  0.70545455  0.31172199  0.53233003 -0.00432119
   0.4889881   0.65818182  0.11118728  0.41982069]
 [ 0.14985742  0.57666667  0.57363636  0.52516051  0.55270216  0.05830635
   0.55833333  0.57272727  0.48182912  0.53539683]
 [ 0.15325276  0.57202381  0.65727273  0.38452378  0.5388457   0.5729045
   0.7622619   0.79545455  0.7528426   0.7683966 ]
 [ 0.70246114  0.83702381  0.86909091  0.80262218  0.84774115  0.48206977
   0.73761905  0.76727273  0.7257277   0.73362   ]
 [ 0.2569356   0.62202381  0.65545455  0.53071227  0.59576175  0.14255673
   0.56892857  0.60272727  0.48336001  0.55044109]
 [ 0.25373696  0.59940476  0.71363636  0.42505375  0.5718728   0.41966194
   0.71        0.71454545  0.65713984  0.6938217 ]
 [-0.03317013  0.48363095  0.66545455  0.05773503  0.42223082  0.14863323
   0.57559524  0.64727273  0.44393987  0.55470804]
 [ 0.10409943  0.535       0.61363636  0.23983103  0.4738651   0.38961931
   0.67738095  0.76818182  0.52628406  0.66352474]
 [ 0.60385313  0.79785714  0.81636364  0.77482666  0.79505398  0.42938285
   0.69107143  0.73090909  0.65869503  0.68421218]
 [ 0.01398467  0.50888889  0.85181818  0.06666667  0.48411445  0.51212323
   0.74857143  0.77727273  0.71475913  0.74590507]
 [ 0.51423699  0.75833333  0.80818182  0.65399292  0.73817909  0.59253571
   0.79166667  0.80545455  0.7648362   0.78737401]
 [ 0.28042934  0.62946429  0.73272727  0.49575713  0.62159756  0.0786456
   0.53869048  0.62        0.32918855  0.50276377]
 [ 0.10417423  0.54166667  0.79636364  0.12844571  0.50035088  0.06688477
   0.545       0.54727273  0.50269318  0.53186813]
 [ 0.30508831  0.65166667  0.65545455  0.63664631  0.64654151  0.33375448
   0.64047619  0.72272727  0.53488215  0.63418417]
 [ 0.13547265  0.57154762  0.61909091  0.41782366  0.53663226  0.17675439
   0.5875      0.77818182  0.28094011  0.5744883 ]
 [ 0.25364331  0.635       0.64090909  0.60636872  0.62384144  0.4779714
   0.71666667  0.72363636  0.70862957  0.70951604]
 [ 0.37449091  0.70166667  0.72090909  0.67396191  0.69859737  0.55014442
   0.78333333  0.78727273  0.74628451  0.77981047]
 [ 0.42369367  0.72333333  0.72181818  0.6538281   0.69540207  0.4541555
   0.73916667  0.74        0.69291896  0.72638833]
 [ 0.47580091  0.72083333  0.83363636  0.62051439  0.73584709  0.56941214
   0.77833333  0.77454545  0.76029707  0.76744811]
 [ 0.11851695  0.56488095  0.62        0.42789589  0.55291945  0.46625155
   0.71761905  0.74090909  0.6708122   0.71062771]
 [ 0.14726212  0.56607143  0.64727273  0.34150548  0.52389472  0.25857758
   0.61666667  0.63181818  0.59230359  0.60610223]
 [ 0.65905571  0.83369048  0.83454545  0.8168275   0.82187604  0.37599294
   0.67559524  0.76090909  0.56567763  0.6657311 ]]
GBM mean:
[0.34356184 0.67000661 0.734      0.54306752 0.65114436 0.36671824
 0.67875529 0.72848485 0.5854795  0.66530765]
---------------------------
---------------------------
BDDAE performance:
[[ 0.03012848  0.51583333  0.51818182  0.50283561  0.5098714  -0.03918433
   0.48411765  0.70454545  0.16508616  0.45872534]
 [ 0.17868444  0.59        0.59090909  0.58574623  0.587325    0.48357534
   0.74017857  0.76818182  0.71787846  0.73713933]
 [ 0.12149456  0.56025641  0.59545455  0.50128639  0.54649382  0.03636364
   0.51818182  0.51818182  0.49864717  0.5087661 ]
 [ 0.14667532  0.57416667  0.58181818  0.54309503  0.5620535   0.12213311
   0.55416667  0.7         0.37328132  0.54350889]
 [ 0.39361236  0.70178571  0.70909091  0.69231653  0.69159267  0.32727273
   0.66363636  0.66363636  0.64581232  0.6551292 ]
 [ 0.51534254  0.75666667  0.75909091  0.74655407  0.75342899  0.06363636
   0.53181818  0.53181818  0.49587014  0.51553134]
 [ 0.06179913  0.53214286  0.59545455  0.42707648  0.51302168 -0.03636364
   0.48181818  0.48181818  0.39857173  0.44992108]
 [ 0.31641939  0.64380952  0.72727273  0.59206065  0.65019002  0.3742412
   0.68931624  0.69545455  0.68088836  0.68407191]
 [ 0.45341557  0.70142857  0.79545455  0.6373028   0.71306604  0.4423969
   0.69857143  0.78636364  0.63582332  0.707485  ]
 [ 0.20909091  0.60454545  0.60454545  0.59004131  0.59773595  0.26079215
   0.62833333  0.64090909  0.59983381  0.6205577 ]
 [ 0.1631648   0.57589286  0.64090909  0.50149987  0.56357322  0.15902658
   0.57857143  0.62727273  0.52615762  0.56837204]
 [ 0.13371843  0.56428571  0.62272727  0.48590954  0.55540344  0.26268331
   0.63660714  0.65        0.62788636  0.62859212]
 [ 0.21166406  0.60555556  0.62272727  0.5885316   0.60175304  0.13819285
   0.56880342  0.57727273  0.55248611  0.56111892]
 [ 0.0818252   0.54047619  0.62272727  0.44164854  0.52899133  0.33205749
   0.6675      0.66363636  0.65635037  0.65911368]
 [-0.04257396  0.47761905  0.56818182  0.33788092  0.45954946  0.20977158
   0.60357143  0.64545455  0.56788478  0.59777836]
 [ 0.13343657  0.56367521  0.59545455  0.51222682  0.55079572  0.13655856
   0.55625     0.65        0.42364375  0.5312272 ]
 [ 0.6063017   0.80598291  0.80909091  0.79656344  0.80034193  0.09865971
   0.54316239  0.59545455  0.42168191  0.51467628]
 [ 0.49034488  0.72894737  0.89545455  0.64749003  0.74045735  0.07756467
   0.53846154  0.56363636  0.50422667  0.53134858]
 [ 0.2992763   0.64285714  0.7         0.61509359  0.64500736  0.33413766
   0.665       0.67272727  0.64984051  0.66131537]
 [ 0.12370546  0.56666667  0.62727273  0.49378326  0.55331756 -0.0501173
   0.47857143  0.55454545  0.31187656  0.44506709]
 [-0.01000059  0.49470588  0.67727273  0.26026989  0.47427005  0.13370354
   0.5675      0.56818182  0.55925963  0.56262009]
 [ 0.09090909  0.54545455  0.54545455  0.53655603  0.54107586  0.12912389
   0.56160714  0.62272727  0.47994478  0.55374172]
 [ 0.00326884  0.50042735  0.50454545  0.46330076  0.48094303  0.45321167
   0.70833333  0.81818182  0.61613406  0.71306575]
 [ 0.13239259  0.56583333  0.56818182  0.55956046  0.56300668  0.22050862
   0.60916667  0.61818182  0.58814475  0.60259676]
 [ 0.09777838  0.55        0.55909091  0.54232311  0.54632701  0.20909091
   0.60454545  0.60454545  0.59585535  0.60039334]
 [ 0.13636364  0.56818182  0.56818182  0.54623459  0.55731393  0.22206658
   0.60916667  0.62272727  0.58328658  0.60258968]
 [ 0.37264018  0.67619048  0.74545455  0.62198446  0.67318759  0.45454545
   0.72727273  0.72727273  0.70663769  0.71843846]
 [ 0.11144392  0.55267857  0.59090909  0.53121164  0.55256116  0.40945287
   0.6974359   0.72727273  0.66894707  0.69778101]
 [ 0.00522366  0.50357143  0.55909091  0.40555917  0.49281577  0.46238649
   0.73        0.73636364  0.71054764  0.7236012 ]
 [ 0.03427792  0.51517857  0.55        0.47826762  0.50646679  0.03382318
   0.51517857  0.60454545  0.31976292  0.48010484]]
BDDAE mean:
[0.18672746 0.59082719 0.635      0.53947368 0.58373125 0.21537706
 0.60522812 0.64469697 0.5427416  0.59447928]
---------------------------
---------------------------
DUMMY performance:
[[0.         0.5        0.55636364 0.         0.35735294 0.
  0.5        0.76909091 0.         0.4344152 ]
 [0.         0.5        0.53636364 0.         0.34901961 0.
  0.5        0.62909091 0.         0.38611111]
 [0.         0.5        0.57454545 0.         0.36454248 0.
  0.5        0.51818182 0.         0.34093137]
 [0.         0.5        0.53636364 0.         0.34901961 0.
  0.5        0.73181818 0.         0.42246302]
 [0.         0.5        0.62       0.         0.38251634 0.
  0.5        0.50909091 0.         0.33688725]
 [0.         0.5        0.52727273 0.         0.34497549 0.
  0.5        0.51818182 0.         0.34093137]
 [0.         0.5        0.62       0.         0.38251634 0.
  0.5        0.50909091 0.         0.33688725]
 [0.         0.5        0.68545455 0.         0.40632955 0.
  0.5        0.60181818 0.         0.3753268 ]
 [0.         0.5        0.70363636 0.         0.4127623  0.
  0.5        0.68545455 0.         0.40632955]
 [0.         0.5        0.50909091 0.         0.33688725 0.
  0.5        0.55636364 0.         0.35735294]
 [0.         0.5        0.63909091 0.         0.38978758 0.
  0.5        0.62       0.         0.38251634]
 [0.         0.5        0.62       0.         0.38251634 0.
  0.5        0.62       0.         0.38251634]
 [0.         0.5        0.58363636 0.         0.36813725 0.
  0.5        0.57454545 0.         0.36454248]
 [0.         0.5        0.66727273 0.         0.3998968  0.
  0.5        0.52727273 0.         0.34497549]
 [0.         0.5        0.70363636 0.         0.4127623  0.
  0.5        0.63909091 0.         0.38978758]
 [0.         0.5        0.61090909 0.         0.37892157 0.
  0.5        0.65818182 0.         0.39668043]
 [0.         0.5        0.57454545 0.         0.36454248 0.
  0.5        0.60181818 0.         0.3753268 ]
 [0.         0.5        0.87090909 0.         0.46521303 0.
  0.5        0.59272727 0.         0.37173203]
 [0.         0.5        0.69454545 0.         0.40954592 0.
  0.5        0.54636364 0.         0.35318627]
 [0.         0.5        0.68545455 0.         0.40632955 0.
  0.5        0.62909091 0.         0.38611111]
 [0.         0.5        0.77818182 0.         0.43730994 0.
  0.5        0.52727273 0.         0.34497549]
 [0.         0.5        0.46363636 0.         0.31666667 0.
  0.5        0.64909091 0.         0.39346405]
 [0.         0.5        0.58363636 0.         0.36813725 0.
  0.5        0.74181818 0.         0.42573099]
 [0.         0.5        0.53636364 0.         0.34901961 0.
  0.5        0.55636364 0.         0.35735294]
 [0.         0.5        0.57454545 0.         0.36454248 0.
  0.5        0.46363636 0.         0.31666667]
 [0.         0.5        0.51818182 0.         0.34093137 0.
  0.5        0.55636364 0.         0.35735294]
 [0.         0.5        0.70363636 0.         0.4127623  0.
  0.5        0.46363636 0.         0.31666667]
 [0.         0.5        0.62       0.         0.38251634 0.
  0.5        0.60181818 0.         0.3753268 ]
 [0.         0.5        0.62       0.         0.38251634 0.
  0.5        0.54636364 0.         0.35318627]
 [0.         0.5        0.62       0.         0.38251634 0.
  0.5        0.65818182 0.         0.39668043]]
DUMMY mean:
[0.         0.5        0.61790909 0.         0.38001645 0.
 0.5        0.59339394 0.         0.37074713]
---------------------------
Current folder: /home/marcos/Dropbox (Maestral)/c_sldl_1_2_49
-------------------------------------
----- RESULTS from .csv files ------
-------------------------------------
---------------------------
ALG Means: 
-rows: alg : KNN = 0; DT = 1; RF = 2; SVM = 3; GBM = 4; BDDAE = 5; DUMMY = 5
columns:
'val_cohen','val_uar', 'val_acc', 'val_gm',  'val_f1',  'aro_cohen','aro_uar', 'aro_acc', 'aro_gm',  'aro_f1'
-------------------------------------------------------------
  v_c   v_u   v_a   v_g   v_f1  a_c   a_u   a_a   a_g   a_f1
[[0.382 0.689 0.734 0.615 0.68  0.433 0.715 0.741 0.675 0.708]
 [0.402 0.698 0.728 0.655 0.688 0.404 0.707 0.725 0.672 0.698]
 [0.414 0.708 0.743 0.651 0.699 0.436 0.724 0.746 0.703 0.716]
 [0.111 0.552 0.661 0.176 0.468 0.151 0.574 0.663 0.232 0.494]
 [0.344 0.67  0.734 0.543 0.651 0.367 0.679 0.728 0.585 0.665]
 [0.187 0.591 0.635 0.539 0.584 0.215 0.605 0.645 0.543 0.594]
 [0.    0.5   0.618 0.    0.38  0.    0.5   0.593 0.    0.371]]
-------------------------------------------------------------
Standard Deviation of each metric:
[[0.233 0.115 0.094 0.19  0.12  0.148 0.074 0.066 0.104 0.076]
 [0.182 0.098 0.088 0.139 0.099 0.15  0.081 0.075 0.105 0.084]
 [0.226 0.101 0.088 0.17  0.107 0.161 0.087 0.07  0.086 0.089]
 [0.175 0.081 0.086 0.257 0.124 0.213 0.105 0.077 0.306 0.15 ]
 [0.219 0.111 0.089 0.222 0.125 0.195 0.095 0.073 0.197 0.108]
 [0.167 0.081 0.092 0.109 0.086 0.16  0.078 0.079 0.132 0.086]
 [0.    0.    0.085 0.    0.031 0.    0.    0.076 0.    0.03 ]]
-------------------------------------------------------------
std_dev/mean [percentage]:
[[ 61.  17.  13.  31.  18.  34.  10.   9.  15.  11.]
 [ 45.  14.  12.  21.  14.  37.  11.  10.  16.  12.]
 [ 55.  14.  12.  26.  15.  37.  12.   9.  12.  12.]
 [157.  15.  13. 146.  27. 141.  18.  12. 132.  30.]
 [ 64.  17.  12.  41.  19.  53.  14.  10.  34.  16.]
 [ 89.  14.  14.  20.  15.  74.  13.  12.  24.  14.]
 [  0.   0.  14.   0.   8.   0.   0.  13.   0.   8.]]
-------------------------------------
Current folder: /home/marcos/Dropbox (Maestral)/c_sldl_1_2_49
-------------------------------------
----- RESULTS ------
-------------------------------------
Window size (sec):  20.992
step (sec):  10.496
overlap:  True
perc. of overlap:  50.0
overlap duration (sec):  10.496
Number of windows / instances:  108
Elapsed time: 1472.1662638068199 minutes
Elapsed time: 24.53610439678033 hours
