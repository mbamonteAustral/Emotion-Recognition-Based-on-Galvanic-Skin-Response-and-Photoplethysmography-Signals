2024-04-10 17:37:25.025837: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-04-10 17:37:25.794651: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-04-10 17:37:27.341951: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
    
    
-------------------------------
participant:  1
-------------------------------
    
    
participant:  1
corriendo en PC gamer:
Window size (sec):  11.0
step (sec):  8.25
overlap:  True
perc. of overlap:  25.0
overlap duration (sec):  2.75
Nearest multiple of 16 to 11000 is: 11008
Nearest multiple of 16 to 8250 is: 8256
['gsr_chunks', 'ppg_chunks', 'val_chunks', 'aro_chunks', 'time_chunks', 'tag_chunks', 'video']
C:\Users\Javier\Dropbox\c_sldl_1_3_5\functions.py:880: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!
You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.
A typical example is when you are setting values in a column of a DataFrame, like:

df["col"][row_indexer] = value

Use `df.loc[row_indexer, "col"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.



[1m1/1[0m [32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ[0m[37m[0m [1m0s[0m 109ms/step
[1m1/1[0m [32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ[0m[37m[0m [1m0s[0m 109ms/step
predicted [0.74444234 0.25894925 0.5611397  0.91157436 0.8747328  0.81156605
 0.8466729  0.20761289 0.59258735 0.910568   0.89126986 0.8039355
 0.39085776 0.9157157  0.11001036 0.8960671  0.9014687  0.8478595
 0.8983304  0.8968645  0.23060173 0.48269793 0.56922036 0.1759841
 0.32598096 0.89152426 0.9374316  0.9379833  0.934039   0.8712939 ]
predicted [1 0 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 1]
expected [ True False  True  True  True  True  True False  True  True  True  True
  True  True False  True  True False  True  True  True  True  True False
 False  True  True  True  True  True]
accuracy: 0.8666666666666667
confusion matrix: 
[[ 5  1]
 [ 3 21]]
              precision    recall  f1-score   support

       False       0.62      0.83      0.71         6
        True       0.95      0.88      0.91        24

    accuracy                           0.87        30
   macro avg       0.79      0.85      0.81        30
weighted avg       0.89      0.87      0.87        30

macro avg f1-score: 0.8136645962732919
macro avg (UAR): 0.8541666666666667
Sensitivity:  0.8333333333333334
Specificity:  0.875
g-mean:  0.8539125638299666
-------- Model Performance ----------: 
accuracy:  [0.86666667 0.86666667 0.83333333 0.83333333 0.83333333 0.8
 0.76666667 0.73333333 0.9        0.86666667]
gmean:  [0.69221866 0.69221866 0.6770032  0.76376262 0.6770032  0.5527708
 0.64549722 0.52704628 0.70710678 0.85391256]
f1_score:  [0.76       0.76       0.72170686 0.75450082 0.72170686 0.64
 0.65630115 0.58333333 0.80392157 0.8136646 ]
UAR:  [0.72916667 0.72916667 0.70833333 0.77083333 0.70833333 0.625
 0.66666667 0.58333333 0.75       0.85416667]
Cohen Kappa score:  [0.52380952 0.52380952 0.44444444 0.50980392 0.44444444 0.28571429
 0.31372549 0.16666667 0.61538462 0.62962963]
arousal and valece = ok
------------- Evaluating model --------------
C:\Users\Javier\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.
  warnings.warn(
C:\Users\Javier\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(
C:\Users\Javier\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(
C:\Users\Javier\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Javier\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "C:\Users\Javier\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Javier\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Javier\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Javier\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Javier\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(
C:\Users\Javier\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Javier\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "C:\Users\Javier\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Javier\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Javier\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Javier\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Javier\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(
C:\Users\Javier\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(
C:\Users\Javier\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\sklearn\model_selection\_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: 
Traceback (most recent call last):
  File "C:\Users\Javier\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\sklearn\metrics\_scorer.py", line 137, in __call__
    score = scorer._score(
            ^^^^^^^^^^^^^^
  File "C:\Users\Javier\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Javier\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Javier\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Javier\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Javier\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(
C:\Users\Javier\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.
  warnings.warn(
C:\Users\Javier\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(
C:\Users\Javier\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)
C:\Users\Javier\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(
C:\Users\Javier\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)
C:\Users\Javier\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(
C:\Users\Javier\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)
C:\Users\Javier\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.
  warnings.warn(
-------------------------------------
-------------------------------------
participant:  30
-------------------------------------
----- RESULTS ------
-------------------------------------
Window size (sec):  11.008
step (sec):  8.256
overlap:  True
perc. of overlap:  25.0
overlap duration (sec):  2.752
Number of windows / instances:  149
-rows: alg : KNN = 0; DT = 1; RF = 2; SVM = 3; GBM = 4; BDDAE = 5; DUMMY = 5
columns:
'val_cohen','val_uar', 'val_acc', 'val_gm',  'val_f1',  'aro_cohen','aro_uar', 'aro_acc', 'aro_gm',  'aro_f1'
-------------------------------------------------------------
  v_c   v_u   v_a   v_g   v_f1  a_c   a_u   a_a   a_g   a_f1
[[0.718 0.867 0.907 0.858 0.859   nan 0.639 0.933 0.3   0.632]
 [0.436 0.75  0.86  0.752 0.764   nan 0.686 0.933 0.3   0.682]
 [0.569 0.812 0.9   0.803 0.828   nan 0.7   0.96  0.4   0.69 ]
 [0.    0.5   0.799 0.    0.444   nan 0.65  0.953 0.3   0.638]
 [0.328 0.642 0.846 0.412 0.639   nan 0.646 0.947 0.3   0.636]
 [0.446 0.712 0.83  0.679 0.722 0.    0.5   0.967 0.    0.492]
 [0.    0.5   0.799 0.    0.444   nan 0.65  0.953 0.3   0.638]]
last participant performance loaded in numpy array
    
    
-------------------------------
LAST participant's saved data: 
30
-------------------------------
    
    
Saving performance metrics in csv files...
Performance metrics already saved in csv files
---------------------------
KNN performance:
[[ 0.70980038  0.84015152  0.90571429  0.8228091   0.85348859  0.75365854
   0.86785714  0.96666667  0.77071068  0.87420179]
 [ 0.51144424  0.73636364  0.85952381  0.65812906  0.75085056  0.44525814
   0.71212121  0.82571429  0.66741343  0.71807049]
 [ 0.76735257  0.87424242  0.92571429  0.85931399  0.88210888  0.37553656
   0.69262821  0.85857143  0.53272459  0.68046096]
 [ 0.32426658  0.63977273  0.78571429  0.48834371  0.64274464 -0.01689895
   0.49258242  0.87952381  0.          0.46771575]
 [ 0.82040645  0.92878788  0.94        0.92082021  0.90968746  0.56637819
   0.80136364  0.79857143  0.79030936  0.77833323]
 [ 0.22285565  0.60113636  0.7647619   0.41031209  0.59291452  0.25404123
   0.61212121  0.79857143  0.43417874  0.6137833 ]
 [ 0.12754549  0.58214286  0.90619048  0.19258201  0.54970703  0.
   0.5         0.91285714  0.          0.47708903]
 [ 0.8413256   0.90340909  0.94619048  0.8960726   0.92021058  0.6217574
   0.82409091  0.83285714  0.82247301  0.80942679]
 [ 0.20737005  0.59615385  0.83952381  0.25236034  0.57815507  0.37633648
   0.68388889  0.73761905  0.64506496  0.68126206]
 [ 0.14624577  0.57660256  0.85190476  0.23472419  0.55710175  0.12320176
   0.55431818  0.68380952  0.44400621  0.54987551]
 [        nan  0.54285714  0.92666667  0.1         0.53078818  0.27939837
   0.63371212  0.76619048  0.4679868   0.62405528]
 [ 0.67596042  0.82980769  0.93238095  0.76572383  0.83389723  0.46312354
   0.75576923  0.84571429  0.67581998  0.7210357 ]
 [ 0.43952991  0.70032051  0.86571429  0.56657705  0.71121795  0.43246225
   0.71758242  0.94        0.46678757  0.70716621]
 [ 0.38342491  0.68044872  0.87904762  0.5135669   0.68042674 -0.00714286
   0.49642857  0.91952381  0.          0.47893633]
 [ 0.79495877  0.875       0.94619048  0.86028664  0.89666471  0.00126951
   0.49318182  0.70380952  0.20823881  0.48837808]
 [ 0.44297465  0.7         0.86619048  0.53739012  0.71055787  0.06659987
   0.53257576  0.69857143  0.29870782  0.52301853]
 [        nan         nan         nan         nan         nan         nan
          nan         nan         nan         nan]
 [ 0.41970899  0.72115385  0.85904762  0.55793973  0.69743911 -0.00714286
   0.49642857  0.91285714  0.          0.47708903]
 [ 0.41528006  0.68295455  0.85285714  0.50941116  0.68937952 -0.01689895
   0.48928571  0.91285714  0.          0.4769522 ]
 [ 0.09795978  0.54356061  0.6852381   0.39709433  0.53723741  0.27570103
   0.64        0.65809524  0.62200365  0.6343795 ]
 [ 0.34388803  0.64545455  0.83809524  0.45901609  0.65435043  0.44948658
   0.73295455  0.81095238  0.63217769  0.71558395]
 [ 0.2138413   0.59318182  0.75761905  0.45434122  0.60107063  0.64665476
   0.83772727  0.83904762  0.83147917  0.82027151]
 [ 0.33526619  0.67045455  0.73809524  0.62356181  0.6591284   0.31545049
   0.65192308  0.83190476  0.49456126  0.65408974]
 [ 0.81713191  0.90833333  0.93952381  0.9011249   0.90792547  0.47124157
   0.74507576  0.77952381  0.73158983  0.72620898]
 [        nan  0.58261905  0.92        0.1         0.52894089 -0.01689895
   0.49258242  0.87285714  0.          0.46586845]
 [ 0.71759259  0.86666667  0.90666667  0.85750373  0.85856625         nan
   0.63928571  0.93333333  0.3         0.63225233]]
KNN mean:
[0.4685274  0.71286304 0.86554286 0.55756019 0.7093824  0.2855239
 0.64381939 0.8288     0.43344934 0.63182019]
---------------------------
---------------------------
DT performance:
[[ 0.78155788  0.90189394  0.91238095  0.88874534  0.88712338  0.53911608
   0.8032967   0.93333333  0.7634355   0.74657859]
 [ 0.53203011  0.7780303   0.86666667  0.77947397  0.7791608   0.6189491
   0.82007576  0.87285714  0.81308964  0.82022784]
 [ 0.60676423  0.85265152  0.89095238  0.83574112  0.8455064   0.28264198
   0.63237179  0.8047619   0.47564203  0.63010969]
 [ 0.30577454  0.69227273  0.75809524  0.55987317  0.69055689  0.02549218
   0.49285714  0.8047619   0.1386473   0.50218714]
 [ 0.78803138  0.89962121  0.93952381  0.88783896  0.90125604  0.41337038
   0.68840909  0.71714286  0.69409278  0.6771651 ]
 [ 0.2537679   0.57992424  0.6847619   0.52892458  0.57588619  0.31461868
   0.6875      0.82        0.53836284  0.68714416]
 [ 0.37984901  0.71730769  0.9         0.48894442  0.65019918 -0.01655797
   0.59203297  0.87238095  0.34568265  0.55672112]
 [ 0.79573941  0.87007576  0.89285714  0.89313629  0.85491982  0.62643253
   0.79977273  0.83285714  0.78320766  0.79759881]
 [ 0.16329512  0.56826923  0.77142857  0.433503    0.56660952  0.31615429
   0.63333333  0.66380952  0.62445738  0.62867081]
 [ 0.29024888  0.60769231  0.83285714  0.20042837  0.59659629  0.37533876
   0.68659091  0.73857143  0.58711045  0.67502342]
 [        nan  0.675       0.91333333  0.29636241  0.63490134  0.19720175
   0.58106061  0.69238095  0.51070745  0.58069029]
 [ 0.51964705  0.80576923  0.89952381  0.70819525  0.80345584  0.26485571
   0.66442308  0.79190476  0.5132852   0.64827786]
 [ 0.27542512  0.68461538  0.79761905  0.54421175  0.65131213  0.35393031
   0.70631868  0.91904762  0.43386066  0.6694969 ]
 [ 0.33978379  0.64358974  0.83904762  0.53895468  0.64782886  0.11000774
   0.46785714  0.86619048  0.          0.46345803]
 [ 0.62194817  0.78878205  0.87904762  0.75820414  0.78132426  0.33286117
   0.72537879  0.79714286  0.71344625  0.71531242]
 [ 0.46240608  0.75448718  0.82619048  0.70714814  0.73389982  0.41937607
   0.75454545  0.81904762  0.66149169  0.74388795]
 [        nan         nan         nan         nan         nan         nan
          nan         nan         nan         nan]
 [ 0.45513838  0.73365385  0.83904762  0.7055145   0.72784456  0.21423211
   0.61703297  0.87952381  0.29636241  0.60011193]
 [ 0.27715865  0.66856061  0.77095238  0.59300783  0.65927393 -0.05124631
   0.47115385  0.87904762  0.09258201  0.46729506]
 [ 0.09424486  0.53825758  0.6247619   0.54402165  0.53197969  0.31603533
   0.66166667  0.67714286  0.64794967  0.66050845]
 [ 0.43807119  0.71136364  0.81190476  0.65095929  0.70207383  0.7699201
   0.85113636  0.89142857  0.86595063  0.85228788]
 [ 0.06566331  0.52386364  0.65714286  0.36270564  0.50475877  0.64068417
   0.81840909  0.8452381   0.81785077  0.8180922 ]
 [ 0.14531359  0.58727273  0.63047619  0.55181124  0.58046013  0.24219679
   0.59871795  0.7652381   0.39976841  0.58158129]
 [ 0.55031348  0.80606061  0.83761905  0.75700632  0.78297616  0.52154411
   0.77613636  0.84571429  0.76544818  0.78035206]
 [        nan  0.67190476  0.91333333  0.29636241  0.62642099  0.14452686
   0.6032967   0.79333333  0.34976178  0.56730891]
 [ 0.43617953  0.75        0.85952381  0.75215954  0.76369629         nan
   0.68571429  0.93333333  0.3         0.68226601]]
DT mean:
[0.41645007 0.7124368  0.8219619  0.61052936 0.69920084 0.33215341
 0.67276354 0.81824762 0.52528773 0.66209416]
---------------------------
---------------------------
RF performance:
[[ 0.70087767  0.85340909  0.90571429  0.91193064  0.85171078  0.51707317
   0.77857143  0.92666667  0.5634355   0.7714184 ]
 [ 0.54036123  0.80719697  0.88571429  0.75063326  0.81514876  0.76676989
   0.83257576  0.89952381  0.89616034  0.82567159]
 [ 0.7993154   0.86666667  0.93238095  0.82899296  0.8807201   0.13957941
   0.60128205  0.83190476  0.563733    0.59659381]
 [ 0.29352664  0.61545455  0.73857143  0.60111407  0.60853943 -0.00613071
   0.50989011  0.87238095  0.07071068  0.49879023]
 [ 0.81154401  0.93712121  0.95333333  0.89021939  0.93148767  0.5821541
   0.7775      0.81190476  0.82841373  0.77929072]
 [ 0.26487162  0.62007576  0.73857143  0.46488431  0.61599944  0.32759788
   0.64962121  0.81857143  0.44991382  0.64962786]
 [ 0.22754549  0.58901099  0.91952381  0.28894442  0.55340161  0.01325978
   0.52472527  0.87238095  0.17071068  0.4981772 ]
 [ 0.762856    0.87386364  0.91952381  0.89158828  0.88583456  0.63651075
   0.85977273  0.87952381  0.82016677  0.85413439]
 [ 0.02843072  0.53814103  0.79857143  0.40558004  0.53710256  0.35666744
   0.69944444  0.73809524  0.69147797  0.70290499]
 [ 0.20229843  0.58269231  0.82619048  0.37151008  0.58306512  0.38584551
   0.7075      0.79238095  0.57941419  0.70185666]
 [        nan  0.73571429  0.94        0.3         0.71718208  0.22325877
   0.56477273  0.69761905  0.54196254  0.55561341]
 [ 0.52558635  0.77660256  0.88571429  0.77990604  0.77429613  0.55608466
   0.78397436  0.87952381  0.67030993  0.78736474]
 [ 0.41289334  0.70865385  0.85952381  0.5729591   0.72996154  0.13222997
   0.63928571  0.92        0.33587324  0.64509214]
 [ 0.33960448  0.66346154  0.85904762  0.53238405  0.6611435  -0.00714286
   0.4782967   0.88571429  0.09636241  0.46941602]
 [ 0.67756807  0.77916667  0.89238095  0.76489279  0.79612251  0.29222736
   0.69886364  0.82619048  0.53578344  0.71882879]
 [ 0.53373016  0.83333333  0.89333333  0.58780609  0.83143645  0.43325509
   0.72727273  0.79190476  0.72204177  0.71059006]
 [        nan         nan         nan         nan         nan         nan
          nan         nan         nan         nan]
 [ 0.38119658  0.76314103  0.84571429  0.69278431  0.74712545 -0.04203967
   0.50686813  0.89285714  0.          0.50447911]
 [ 0.41921597  0.61060606  0.77142857  0.59141009  0.61106111  0.2
   0.59258242  0.93238095  0.          0.58223759]
 [ 0.04585915  0.48484848  0.65142857  0.36107549  0.45901561  0.27113022
   0.58944444  0.61809524  0.61469761  0.58466654]
 [ 0.53803594  0.69924242  0.83142857  0.50933376  0.71831616  0.71657453
   0.85568182  0.89904762  0.76532758  0.85890909]
 [ 0.27817761  0.63409091  0.76428571  0.45577361  0.63451812  0.62983983
   0.78886364  0.83238095  0.78638568  0.78132243]
 [ 0.14210184  0.585       0.67809524  0.61611156  0.5821276   0.18812576
   0.63108974  0.81142857  0.3867531   0.62081   ]
 [ 0.66513513  0.82045455  0.88571429  0.84891482  0.82656343  0.57269139
   0.78939394  0.8652381   0.79299513  0.80257629]
 [        nan  0.58619048  0.92666667  0.3         0.53078818  0.14222517
   0.59258242  0.89333333  0.17071068  0.57948262]
 [ 0.56911604  0.8125      0.9         0.80322413  0.82785738         nan
   0.7         0.96        0.4         0.68965517]]
RF mean:
[0.44173252 0.71106553 0.84811429 0.60487893 0.70842101 0.33449114
 0.67519422 0.8459619  0.49813359 0.67078039]
---------------------------
---------------------------
SVM performance:
[[0.         0.5        0.77190476 0.         0.43545299 0.
  0.5        0.91952381 0.         0.47893633]
 [0.         0.5        0.7852381  0.         0.4397265  0.
  0.5        0.77857143 0.         0.43758974]
 [0.3966967  0.66666667 0.85857143 0.47236146 0.67583761 0.
  0.5        0.84571429 0.         0.45805861]
 [0.         0.5        0.73142857 0.         0.4224359  0.
  0.5        0.89285714 0.         0.47154716]
 [0.73414729 0.82916667 0.92571429 0.7993819  0.86383708 0.44165531
  0.70840909 0.77285714 0.66112878 0.71000644]
 [0.         0.5        0.7452381  0.         0.42690598 0.
  0.5        0.79857143 0.         0.444     ]
 [0.         0.5        0.92619048 0.         0.48078362 0.
  0.5        0.91285714 0.         0.47708903]
 [0.26358683 0.60416667 0.81857143 0.34711971 0.59750427 0.
  0.5        0.7047619  0.         0.41320513]
 [0.         0.5        0.81904762 0.         0.4501221  0.
  0.5        0.66428571 0.         0.39913043]
 [0.         0.5        0.86571429 0.         0.46401099 0.
  0.5        0.73142857 0.         0.4224359 ]
 [       nan 0.55       0.94       0.1        0.53448276 0.
  0.5        0.7452381  0.         0.42690598]
 [0.         0.5        0.84571429 0.         0.45805861 0.
  0.5        0.82571429 0.         0.45210623]
 [0.         0.5        0.81238095 0.         0.44813797 0.
  0.5        0.91285714 0.         0.47708903]
 [0.         0.5        0.84571429 0.         0.45805861 0.
  0.5        0.92619048 0.         0.48078362]
 [0.         0.5        0.82571429 0.         0.45210623 0.
  0.5        0.77857143 0.         0.43758974]
 [0.         0.5        0.81238095 0.         0.44813797 0.
  0.5        0.75190476 0.         0.42904274]
 [       nan        nan        nan        nan        nan        nan
         nan        nan        nan        nan]
 [0.         0.5        0.81238095 0.         0.44813797 0.
  0.5        0.91952381 0.         0.47893633]
 [0.         0.5        0.7852381  0.         0.4397265  0.
  0.5        0.93285714 0.         0.48263091]
 [0.         0.5        0.73857143 0.         0.42476923 0.
  0.5        0.60428571 0.         0.37663043]
 [0.         0.5        0.79190476 0.         0.44186325 0.
  0.5        0.75190476 0.         0.42904274]
 [0.         0.5        0.77190476 0.         0.43545299 0.
  0.5        0.6847619  0.         0.40628205]
 [0.         0.5        0.71142857 0.         0.41551282 0.
  0.5        0.83904762 0.         0.45607448]
 [0.         0.5        0.77857143 0.         0.43758974 0.
  0.5        0.7652381  0.         0.43331624]
 [       nan 0.6        0.94666667 0.2        0.5862069  0.
  0.5        0.88619048 0.         0.46969987]
 [0.         0.5        0.79857143 0.         0.444             nan
  0.65       0.95333333 0.3        0.63793103]]
SVM mean:
[0.06062743 0.53       0.81859048 0.07675452 0.48515434 0.0184023
 0.51433636 0.8119619  0.03844515 0.46344241]
---------------------------
---------------------------
GBM performance:
[[ 0.59679065  0.79431818  0.8852381   0.73632216  0.81143281  0.55627178
   0.77142857  0.96        0.57071068  0.77273764]
 [ 0.32568168  0.62878788  0.83904762  0.40705894  0.63999841  0.66238894
   0.81174242  0.89238095  0.79251402  0.82286793]
 [ 0.71409331  0.82424242  0.9047619   0.8195978   0.84394596 -0.01111111
   0.49583333  0.83904762  0.          0.45592186]
 [ 0.02136465  0.51022727  0.71142857  0.19057296  0.46098025  0.06341463
   0.5         0.89285714  0.07071068  0.47154716]
 [ 0.72718482  0.84583333  0.92619048  0.80855853  0.86834639  0.52580252
   0.7425      0.81238095  0.70418878  0.75543389]
 [ 0.          0.49545455  0.73857143  0.          0.42459829  0.07777778
   0.54583333  0.81190476  0.11547005  0.52199145]
 [ 0.04444444  0.59285714  0.92666667  0.09258201  0.55551345 -0.0097561
   0.5         0.91285714  0.07071068  0.47708903]
 [ 0.81362841  0.9         0.94619048  0.87120998  0.91772567  0.45934431
   0.72931818  0.81190476  0.67857668  0.74557924]
 [-0.0097561   0.49615385  0.81238095  0.          0.44813797  0.31468326
   0.63944444  0.7447619   0.50095785  0.62561312]
 [ 0.          0.5         0.86571429  0.          0.46401099  0.11882523
   0.54545455  0.75190476  0.2         0.50701672]
 [        nan  0.55        0.94        0.1         0.53448276  0.03283582
   0.5125      0.75190476  0.05        0.44859829]
 [ 0.45014976  0.67948718  0.89285714  0.52482803  0.68686854  0.02280702
   0.50833333  0.81857143  0.05773503  0.47452503]
 [ 0.          0.5         0.81238095  0.          0.44813797  0.
   0.5         0.91285714  0.          0.47708903]
 [ 0.07301587  0.5125      0.84571429  0.05773503  0.47761416 -0.01428571
   0.49285714  0.91285714  0.          0.47708903]
 [ 0.52903091  0.74583333  0.89285714  0.62171963  0.75369353  0.1464972
   0.5655303   0.77809524  0.3712687   0.55492042]
 [ 0.36666667  0.6625      0.86        0.40165079  0.66025641  0.05373134
   0.52045455  0.75857143  0.1         0.47011966]
 [        nan         nan         nan         nan         nan         nan
          nan         nan         nan         nan]
 [ 0.36399943  0.64583333  0.85190476  0.4649501   0.67054131 -0.00714286
   0.49642857  0.91285714  0.          0.47708903]
 [ 0.21317179  0.58257576  0.8052381   0.33366143  0.57993125  0.
   0.5         0.93285714  0.          0.48263091]
 [ 0.03283582  0.5125      0.7452381   0.05        0.44646154  0.27706679
   0.63        0.67857143  0.57254106  0.62461457]
 [ 0.13829614  0.57045455  0.81142857  0.27848216  0.56090598  0.70353034
   0.82424242  0.90619048  0.79593262  0.84859311]
 [ 0.05495688  0.52765152  0.75809524  0.13590862  0.48762821  0.41751072
   0.69795455  0.79142857  0.58898674  0.70038365]
 [ 0.03462511  0.51181818  0.69809524  0.14239449  0.46153902  0.
   0.5         0.83904762  0.          0.45607448]
 [ 0.53060745  0.75833333  0.87904762  0.66786852  0.76564798  0.35185516
   0.65719697  0.8252381   0.47504967  0.65510948]
 [        nan  0.6         0.94666667  0.2         0.5862069   0.05365854
   0.52115385  0.88619048  0.07071068  0.50276866]
 [ 0.3278462   0.64166667  0.84619048  0.41222005  0.63907822         nan
   0.64642857  0.94666667  0.3         0.63608374]]
GBM mean:
[0.27602756 0.62356114 0.84567619 0.33269285 0.60774736 0.19982107
 0.5941854  0.84327619 0.28344256 0.57765949]
---------------------------
---------------------------
BDDAE performance:
[[ 0.16321676  0.56614907  0.77666667  0.32615619  0.551316    0.
   0.5         0.93333333  0.          0.48275862]
 [ 0.82575393  0.9375      0.94        0.93531923  0.91240618  0.48840486
   0.73291925  0.82666667  0.69272759  0.73777134]
 [ 0.20728716  0.575       0.82        0.35692276  0.57820228  0.14705882
   0.558       0.83666667  0.25269283  0.55021691]
 [ 0.1354944   0.55738636  0.73        0.36068598  0.54244743  0.03478261
   0.51481481  0.9         0.05665577  0.49358852]
 [ 0.69252175  0.85833333  0.90333333  0.83958272  0.84443077  0.3070985
   0.65        0.70666667  0.61764096  0.65036141]
 [ 0.12052806  0.56193182  0.71333333  0.32389213  0.52764274 -0.03255633
   0.4875      0.78        0.          0.4379915 ]
 [ 0.05116279  0.51964286  0.92666667  0.07071068  0.51421658 -0.02448513
   0.49074074  0.88333333  0.          0.46895079]
 [ 0.44204103  0.69254658  0.83333333  0.62144538  0.71194852  0.00229275
   0.50238095  0.61        0.39234502  0.49459375]
 [ 0.72015953  0.816       0.93333333  0.79174298  0.85866683  0.20163059
   0.5925      0.68        0.48863743  0.58318198]
 [-0.02417083  0.49038462  0.85        0.          0.45930532  0.0111996
   0.50340909  0.68        0.24729338  0.48008677]
 [ 0.03247508  0.51785714  0.92333333  0.06943651  0.50497472 -0.02470626
   0.49034091  0.71333333  0.03370999  0.42483659]
 [ 0.08452012  0.53        0.83        0.17707833  0.51472224 -0.00733835
   0.5         0.79333333  0.10222481  0.47395679]
 [ 0.52556741  0.74375     0.86        0.71125978  0.76131792  0.08947368
   0.53148148  0.90333333  0.11547005  0.52443609]
 [-0.01240867  0.496       0.81333333  0.0409878   0.45802249  0.
   0.5         0.93333333  0.          0.48275862]
 [ 0.4478278   0.7         0.87333333  0.60333339  0.71849543 -0.02247376
   0.49130435  0.75333333  0.          0.4294775 ]
 [ 0.33685065  0.63125     0.84        0.51183531  0.65321724  0.04326649
   0.51832298  0.75666667  0.1374854   0.47495126]
 [        nan         nan         nan         nan         nan         nan
          nan         nan         nan         nan]
 [ 0.38059718  0.65625     0.84        0.57030877  0.68129533 -0.01644518
   0.49285714  0.92        0.          0.47909645]
 [ 0.16519037  0.5625      0.81        0.27054933  0.55725103 -0.02109635
   0.49107143  0.91666667  0.          0.47818901]
 [ 0.05260518  0.52159091  0.66        0.40009591  0.51826661  0.37376515
   0.68472222  0.70333333  0.6714129   0.68395019]
 [ 0.0066427   0.5         0.75        0.17194061  0.48011751  0.17781294
   0.57919255  0.74333333  0.44610056  0.57457246]
 [ 0.03601207  0.51335404  0.75666667  0.14784351  0.47429657  0.03674241
   0.51746032  0.68        0.1931854   0.46869113]
 [ 0.25107347  0.62698413  0.68666667  0.57120006  0.61034313  0.14679345
   0.554       0.83        0.2832191   0.55523695]
 [ 0.57975018  0.77453416  0.86        0.7485386   0.78708178  0.20600019
   0.60403727  0.74333333  0.46106538  0.59024565]
 [ 0.04651163  0.51785714  0.92333333  0.07071068  0.51330913 -0.02974828
   0.48888889  0.88        0.          0.46801094]
 [ 0.44574325  0.7125      0.83        0.678854    0.72151352  0.
   0.5         0.96666667  0.          0.49152542]]
BDDAE mean:
[0.26851812 0.62317209 0.82733333 0.41481722 0.61819229 0.0834989
 0.53903778 0.80293333 0.20767466 0.51917747]
---------------------------
---------------------------
DUMMY performance:
[[0.         0.5        0.77190476 0.         0.43545299 0.
  0.5        0.91952381 0.         0.47893633]
 [0.         0.5        0.7852381  0.         0.4397265  0.
  0.5        0.77857143 0.         0.43758974]
 [0.         0.5        0.7852381  0.         0.4397265  0.
  0.5        0.84571429 0.         0.45805861]
 [0.         0.5        0.73142857 0.         0.4224359  0.
  0.5        0.89285714 0.         0.47154716]
 [0.         0.5        0.7852381  0.         0.4397265  0.
  0.5        0.67809524 0.         0.40397436]
 [0.         0.5        0.7452381  0.         0.42690598 0.
  0.5        0.79857143 0.         0.444     ]
 [0.         0.5        0.92619048 0.         0.48078362 0.
  0.5        0.91285714 0.         0.47708903]
 [0.         0.5        0.77190476 0.         0.43545299 0.
  0.5        0.7047619  0.         0.41320513]
 [0.         0.5        0.81904762 0.         0.4501221  0.
  0.5        0.66428571 0.         0.39913043]
 [0.         0.5        0.86571429 0.         0.46401099 0.
  0.5        0.73142857 0.         0.4224359 ]
 [       nan 0.55       0.94       0.1        0.53448276 0.
  0.5        0.7452381  0.         0.42690598]
 [0.         0.5        0.84571429 0.         0.45805861 0.
  0.5        0.82571429 0.         0.45210623]
 [0.         0.5        0.81238095 0.         0.44813797 0.
  0.5        0.91285714 0.         0.47708903]
 [0.         0.5        0.84571429 0.         0.45805861 0.
  0.5        0.92619048 0.         0.48078362]
 [0.         0.5        0.82571429 0.         0.45210623 0.
  0.5        0.77857143 0.         0.43758974]
 [0.         0.5        0.81238095 0.         0.44813797 0.
  0.5        0.75190476 0.         0.42904274]
 [       nan        nan        nan        nan        nan        nan
         nan        nan        nan        nan]
 [0.         0.5        0.81238095 0.         0.44813797 0.
  0.5        0.91952381 0.         0.47893633]
 [0.         0.5        0.7852381  0.         0.4397265  0.
  0.5        0.93285714 0.         0.48263091]
 [0.         0.5        0.73857143 0.         0.42476923 0.
  0.5        0.60428571 0.         0.37663043]
 [0.         0.5        0.79190476 0.         0.44186325 0.
  0.5        0.75190476 0.         0.42904274]
 [0.         0.5        0.77190476 0.         0.43545299 0.
  0.5        0.6847619  0.         0.40628205]
 [0.         0.5        0.71142857 0.         0.41551282 0.
  0.5        0.83904762 0.         0.45607448]
 [0.         0.5        0.77857143 0.         0.43758974 0.
  0.5        0.7652381  0.         0.43331624]
 [       nan 0.6        0.94666667 0.2        0.5862069  0.
  0.5        0.88619048 0.         0.46969987]
 [0.         0.5        0.79857143 0.         0.444             nan
  0.65       0.95333333 0.3        0.63793103]]
DUMMY mean:
[0.         0.506      0.80817143 0.012      0.45226342 0.
 0.506      0.80817143 0.012      0.45120112]
---------------------------
Current folder: C:\Users\Javier\Dropbox\c_sldl_1_3_5
-------------------------------------
----- RESULTS from .csv files ------
-------------------------------------
---------------------------
ALG Means: 
-rows: alg : KNN = 0; DT = 1; RF = 2; SVM = 3; GBM = 4; BDDAE = 5; DUMMY = 5
columns:
'val_cohen','val_uar', 'val_acc', 'val_gm',  'val_f1',  'aro_cohen','aro_uar', 'aro_acc', 'aro_gm',  'aro_f1'
-------------------------------------------------------------
  v_c   v_u   v_a   v_g   v_f1  a_c   a_u   a_a   a_g   a_f1
[[0.457 0.72  0.858 0.586 0.719 0.3   0.651 0.825 0.458 0.64 ]
 [0.416 0.714 0.812 0.633 0.703 0.347 0.68  0.82  0.544 0.669]
 [0.436 0.711 0.838 0.624 0.711 0.348 0.683 0.845 0.515 0.679]
 [0.063 0.527 0.808 0.074 0.48  0.02  0.509 0.805 0.03  0.457]
 [0.274 0.627 0.837 0.346 0.611 0.214 0.599 0.841 0.303 0.584]
 [0.269 0.623 0.827 0.415 0.618 0.083 0.539 0.803 0.208 0.519]
 [0.    0.5   0.796 0.    0.443 0.    0.5   0.801 0.    0.443]]
-------------------------------------------------------------
Standard Deviation of each metric:
[[0.243 0.121 0.072 0.22  0.127 0.242 0.125 0.085 0.293 0.126]
 [0.214 0.114 0.09  0.176 0.114 0.212 0.109 0.071 0.242 0.109]
 [0.233 0.123 0.081 0.185 0.129 0.245 0.116 0.069 0.281 0.12 ]
 [0.175 0.077 0.055 0.198 0.102 0.092 0.043 0.093 0.138 0.062]
 [0.272 0.128 0.07  0.296 0.156 0.238 0.113 0.072 0.293 0.131]
 [0.249 0.123 0.077 0.275 0.134 0.138 0.065 0.099 0.23  0.078]
 [0.    0.    0.047 0.    0.014 0.    0.    0.097 0.    0.03 ]]
-------------------------------------------------------------
std_dev/mean [percentage]:
[[ 53.  17.   8.  38.  18.  81.  19.  10.  64.  20.]
 [ 51.  16.  11.  28.  16.  61.  16.   9.  44.  16.]
 [ 53.  17.  10.  30.  18.  70.  17.   8.  55.  18.]
 [276.  15.   7. 269.  21. 458.   8.  12. 459.  14.]
 [ 99.  20.   8.  86.  26. 111.  19.   9.  97.  22.]
 [ 93.  20.   9.  66.  22. 165.  12.  12. 111.  15.]
 [  0.   0.   6.   0.   3.   0.   0.  12.   0.   7.]]
-------------------------------------
Current folder: C:\Users\Javier\Dropbox\c_sldl_1_3_5
-------------------------------------
----- RESULTS ------
-------------------------------------
Window size (sec):  11.008
step (sec):  8.256
overlap:  True
perc. of overlap:  25.0
overlap duration (sec):  2.752
Number of windows / instances:  149
Elapsed time: 526.2945053021114 minutes
Elapsed time: 8.771575088368522 hours
